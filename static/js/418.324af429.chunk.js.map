{"version":3,"file":"static/js/418.324af429.chunk.js","mappings":"6CAAIA,E,oBACAC,EAAO,KAyEXC,eAAeC,EAAaC,GAAqB,IAAhBC,EAAMC,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAG,KACxC,IACE,MAAMG,QA1CVP,eAAiCE,EAAKM,EAAUC,EAASC,GAAsB,IACzEC,EAD2DR,EAAMC,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAC,KAQtE,GALEO,EADY,MAAVR,QACUS,MAAMV,SAENU,MAAMV,EAAKC,IAGpBQ,EAAIE,GACP,MAAM,IAAIC,MAAM,6BAA+BZ,EAAM,KAGvD,MACMa,EAAKP,EADAG,EAAIK,QAAQC,IAAI,mBAGrBC,EAASP,EAAIQ,KAAKC,YAClBC,EAAS,GACf,IAAIC,EAAQ,EAEZ,OAAa,CACX,MAAM,KAAEC,EAAI,MAAEC,SAAgBN,EAAOO,OACrC,GAAIF,EACF,MAEFF,EAAOK,KAAKF,GACZF,GAASE,EAAMnB,OACfI,EAAQM,EAAIO,EACd,CAEA,IAAIK,EAAS,IAAIC,WAAWN,GACxBO,EAAQ,EACZ,IAAK,MAAMC,KAAKT,EACdM,EAAOI,IAAID,EAAGD,GACdA,GAASC,EAAEzB,OAIb,OADAK,EAAOK,EAAIO,GACJK,CACT,CAIsBK,CAChB9B,EACC+B,IACCC,YAAY,CACVC,KAAM,qBAAuBC,OAAOlC,GACpCmC,SAAU,QACVnC,IAAKkC,OAAOlC,GACZoC,YAAaF,OAAOH,GACpBM,IAAK,iBAAmBH,OAAOH,GAAM,YAEhC/B,GAET,CAACa,EAAIyB,KACHN,YAAY,CACVC,KAAM,qBAAuBC,OAAOlC,GACpCmC,SAAU,WACVnC,IAAKkC,OAAOlC,GACZuC,iBAAkBL,OAAOI,GACzBD,IAAK,wBAA0BH,OAAOI,GAAS,aAGnD,CAACzB,EAAIO,KACHY,YAAY,CACVC,KAAM,qBAAuBC,OAAOlC,GACpCmC,SAAU,WACVnC,IAAKkC,OAAOlC,GACZqC,IAAK,iBAAmBH,OAAOd,GAAS,aAG5CnB,GAGF,OAAOI,CACT,CAAE,MAAOmC,GASP,IAAIC,EAPJT,YAAY,CACVC,KAAM,qBAAuBC,OAAOlC,GACpCmC,SAAU,QACVnC,IAAKkC,OAAOlC,GACZoC,YAAa,MAKbK,EADY,MAAVxC,EACIS,MAAMV,GAENU,MAAMV,EAAKC,GAGnB,IAAIQ,QAAYgC,EAChB,IAAKhC,EAAIE,GACP,MAAM,IAAIC,MAAM,uBAAyBZ,EAAM,MAAQS,EAAIiC,OAAS,KAEtE,IAAIC,QAAelC,EAAImC,cAOvB,OALAZ,YAAY,CACVC,KAAM,qBAAuBC,OAAOlC,GACpCmC,SAAU,WACVnC,IAAKkC,OAAOlC,KAEP,IAAI0B,WAAWiB,EACxB,CACF,CAEO7C,eAAeiB,EAAIf,GAAoC,IAA/BC,EAAMC,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAG,KAAM2C,EAAK3C,UAAAC,OAAA,QAAAC,IAAAF,UAAA,IAAAA,UAAA,GAGjD,SAFML,GAEDgD,EAAO,CACV,IACIC,EADQlD,EAAYmD,OAAOC,YAAY,CAAC,aAAc,YAC/BC,YAAY,aAEvC,IAAIC,EAAa,IAAIC,QAAQ,CAACC,EAASC,KACrC,IAAIC,EAAUR,EAAe/B,IAAIf,GACjCsD,EAAQC,UAAYC,SACKpD,IAAnBkD,EAAQP,OACVK,EAAQE,EAAQP,OAAOU,SAEvBL,EAAQ,OAGZE,EAAQI,QAAUF,IAChBH,EAAO,mCAADM,OAAoC3D,EAAG,MAAA2D,OAAKH,EAAMI,OAAOC,eAI/DC,QAAcZ,EAClB,GAAc,OAAVY,EACF,OAAOA,CAEX,CAEA,IAAInB,QAAe5C,EAAaC,EAAKC,GASrC,IAAI8D,EAAQnE,EAAYmD,OAAOC,YAAY,CAAC,aAAc,aAKtDgB,EAAM,IAAIb,QAAQ,CAACC,EAASC,KAC9BU,EAAME,WAAcT,IAClBJ,EAAQ,OAEVW,EAAML,QAAWF,IACfH,EAAO,IAAIzC,MAAM,gCAAD+C,OAAiC3D,EAAG,qBAAA2D,OAAoBH,EAAMI,OAAOC,gBAIrFf,EAAiBiB,EAAMd,YAAY,aACnCiB,EAAS,IAAIf,QAAQ,CAACC,EAASC,KACjC,IAAIc,EAAarB,EAAesB,IAAI,CAAEpE,IAAKA,EAAKyD,QAASd,IACzDwB,EAAWZ,UAAYC,IACrBJ,GAAQ,IAEVe,EAAWT,QAAUF,IACnBH,EAAO,IAAIzC,MAAM,mBAAD+C,OAAoB3D,EAAG,qBAAA2D,OAAoBH,EAAMI,OAAOC,gBAO5E,aAFMK,QACAF,EACCrB,CACT,C,uBCvMA,MAAM0B,EAAQ,2CACdvE,eAAewE,EAActE,GAC3B,IAAI2C,QAAe4B,EAAcF,EAAQ,IAAMG,mBAAmBxE,IAClE,OAAO,IAAI0B,WAAWiB,EACxB,CA2BO,SAAS8B,EAAeC,EAAQC,GACrC,GAAKD,EAIL,GAAIE,MAAMC,QAAQH,GAChB,IAAK,MAAMI,KAAWJ,EACpBD,EAAeK,EAASH,QAErB,GAAID,EAAOK,aAAeC,OAC/B,IAAK,MAAOC,EAAKH,KAAYE,OAAOE,QAAQR,GAC1CD,EAAeK,EAASH,QAErB,GAAIQ,YAAYC,OAAOV,GAAS,CACrC,KAAMA,EAAO/B,kBAAkBwC,aAC7B,KAAM,qDAERR,EAAMnD,KAAKkD,EAAO/B,OACpB,CACF,CAEO,SAAS0C,EAAYC,GAC1BtD,YAAY,CACVC,KAAK,GAAD0B,OAAK2B,EAAI,WAEjB,CAEO,SAASC,EAAYD,EAAME,GAChC,GAAmB,oBAARA,EACTxD,YAAY,CACVC,KAAK,GAAD0B,OAAK2B,EAAI,gBAEV,CACL,IAAIG,EAAe,GACnBhB,EAAee,EAAMC,GACrBzD,YACE,CACEC,KAAK,GAAD0B,OAAK2B,EAAI,SACbI,KAAMF,GAERC,EAEJ,CACF,CAEO,SAASE,EAAU1D,EAAM2D,EAAKC,GACnC7D,YAAY,CACVC,KAAK,GAAD0B,OAAK1B,EAAI,UACbyD,KAAM,CACJI,OAAQF,EAAIG,WACZF,MAAOA,IAGb,CA0QO,SAASG,EAAcC,GAC5B,OAAOrB,MAAMC,QAAQoB,IAAQd,YAAYC,OAAOa,EAClD,CAEO,SAASC,EACdD,GAEC,IACGxF,GAFJ,IAAE0F,GAAM,EAAK,OAAEC,GAAS,EAAK,QAAEC,EAAU,MAAMnG,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAG,CAAC,EAGnD,GAAI8F,EAAcC,GAAM,CACtBxF,EAAM6F,EAAAA,GAAsBL,GAC5B,MAAMM,EAAS,IAAIC,IAAIP,GACvBxF,EAAgB,WAAI8F,EAAOE,KAEtBF,EAAOE,MAAQ,GAAML,IAAQ3F,EAAY,OAAI,IAAI8F,GAAQG,QAC1DP,IAAK1F,EAAW,MAAIwF,GAGJ,eAAhBxF,EAAU,MAAsB8F,EAAOE,MAAQ,KAAIhG,EAAU,KAAI,SAE9C,kBAAZ4F,GAAwBA,aAAmBnE,UACpDzB,EAAU,KAAI4F,EAClB,CAEA,OAAO5F,CACT,CAEO,SAASkG,EAAoBC,EAASC,EAAOC,GAKhD,IAAIC,EAJCD,QAA6B1G,IAAf0G,IACfA,EAAa,kBAIjB,CAGI,IACIE,EAYAC,EAbAC,GAAa,EAEjB,GAAIJ,EAAWK,MAAM,UACjBH,EAAU,YACP,GAAIF,EAAWK,MAAM,SACxBH,EAAU,cACP,KAAIF,EAAWK,MAAM,cAIxB,KAAM,sBAAwBL,EAAa,IAH3CE,EAAU,WACVE,GAAa,CAGjB,CAGA,GAAIJ,EAAWK,MAAM,WACjBF,EAAUL,EAAQQ,QAAQP,EAAO,CAAEG,QAASA,EAASK,MAAM,SACxD,GAAIP,EAAWK,MAAM,SACxBF,EAAUL,EAAQU,IAAIT,EAAO,CAAEG,QAASA,EAASK,MAAM,SACpD,GAAIP,EAAWK,MAAM,SACxBF,EAAUL,EAAQW,UAAUV,EAAO,CAAEG,QAASA,EAASK,MAAM,QAC1D,KAAIP,EAAWK,MAAM,aAGxB,KAAM,sBAAwBL,EAAa,IAF3CG,EAAUL,EAAQY,cAAcX,EAAO,CAAEG,QAASA,EAASK,MAAM,GAGrE,CAGAN,EAAW,IAAIU,WAAWR,EAAQ9G,QAClC,IAAK,IAAIuH,EAAI,EAAGA,EAAIX,EAAS5G,OAAQuH,IACjCX,EAASW,GAAKA,EAEdR,EACAH,EAASL,KAAK,CAACiB,EAAGC,IAAOX,EAAQU,GAAKV,EAAQW,IAE9Cb,EAASL,KAAK,CAACiB,EAAGC,IAAOX,EAAQW,GAAKX,EAAQU,GAEtD,CAGA,IAAIE,EAAU,SAASC,GAEnB,IADA,IAAIC,EAAQ,IAAIC,aAAaF,EAAM3H,QAC1BuH,EAAI,EAAGA,EAAIX,EAAS5G,OAAQuH,IACjCK,EAAML,GAAKI,EAAMf,EAASW,IAE9B,OAAOK,CACX,EAEIE,EAAYJ,EAAQjB,EAAQsB,KAAKrB,EAAO,CAAEQ,MAAM,KAChDc,EAAgBN,EAAQjB,EAAQwB,SAASvB,EAAO,CAAEQ,MAAM,KACxDgB,EAAWR,EAAQjB,EAAQW,UAAUV,EAAO,CAAEG,QAAS,OAAQK,MAAM,KACrEiB,EAAeT,EAAQjB,EAAQY,cAAcX,EAAO,CAAEG,QAAS,OAAQK,MAAM,KAEjF,MAAO,CACH,SAAYN,EACZ,MAASkB,EACT,SAAYE,EACZ,IAAOE,EACP,eAAkBC,EAE1B,CAvbAhC,EAAAA,GAA0BiC,YAAYjE,GACtCkE,EAAAA,GAAsBlE,GACtBgC,EAAAA,GAA8BiC,YAAYjE,GAE1CkE,EAAAA,GAAwB1I,MAAO2I,EAAM9G,EAAO+G,KAC1C,IAAI1I,EAAMwI,EAAAA,KAA2B,IAAMC,EACvCE,EAAOtE,EAAQ,IAAMG,mBAAmBxE,GAC5C,GAAa,MAAT2B,GAAwB,MAAP+G,EAAa,CAChC,IAAI/F,QAAe4B,EAAcoE,GACjC,OAAO,IAAIC,SAASjG,EACtB,CACE,OAAOjC,MAAMiI,EAAO,UAAYzG,OAAOP,GAAS,QAAUO,OAAOwG,MAIrEF,EAAAA,GAAmB1I,UACjB,IAAIE,EAAMwI,EAAAA,KAAsB,IAAMC,EAClC9F,QAAe4B,EAAcF,EAAQ,IAAMG,mBAAmBxE,IAClE,OAAO,IAAI4I,SAASjG,KAGtBkG,EAAAA,GAAsBC,eAAexE,GACrCgC,EAAAA,GAAuC,cAAIuC,EAAAA,GAC3CvC,EAAAA,GAAgC,OAAIuC,EAAAA,G,QCgE7B,MAAME,EAAO,wBAyDQ,GAAApF,OAAMoF,EAAI,cACR,GAAApF,OAAMoF,EAAI,eC9InB,GAAApF,OAAMoF,EAAI,cD2HxB,MC1HDC,EAAiB,GAAArF,OAAMoF,EAAI,eAEjC,IAAIE,EAAa,KACbC,EAAa,CAAC,EACdC,EAAqB,CAAC,EACtBC,EAAU,KACVC,EAAqB,CAAC,EACtBC,EAAyB,KACzBC,EAA2B,KAC3BC,EAAuB,KAE3B,SAASC,EAAcC,GAAwB,IACzC3G,EADuB4G,EAAOzJ,UAAAC,OAAA,QAAAC,IAAAF,UAAA,IAAAA,UAAA,GAElC,GAAoB,SAAhBwJ,EAAKE,OACP7G,EAAS,IAAIuD,EAAAA,GAAkBoD,EAAKG,SAC/B,GAAoB,yBAAhBH,EAAKE,OACd7G,EAAS,IAAIuD,EAAAA,GAAkCoD,EAAKI,SAC/C,IAAoB,qBAAhBJ,EAAKE,OAQd,MAAM,IAAIhJ,MAAM,mBAAqB8I,EAAKE,OAAS,KARN,CAC7C,IAAIG,EAAU,IAAIzD,EAAAA,GAAkBoD,EAAKK,SAEvChH,EADE2G,EAAKM,UACE,IAAI1D,EAAAA,GAA8BoD,EAAKO,QAASF,GAEhD,IAAIzD,EAAAA,GAA6BoD,EAAKO,QAASF,EAE5D,CAEA,CAIA,OAHIJ,GACF5G,EAAOmH,WAAWR,EAAKS,SAElBpH,CACT,CAEA,SAASqH,EAAgBpD,EAAS0C,GAEhC,IAAIW,EAAgB,CAAC,EACrB,IAAK,MAAMC,KAAKtD,EAAQuD,MAAMC,cAAe,CAC3C,MAAMC,EAAOzD,EAAQuD,MAAMG,OAAOJ,GAC9BtE,EAAcyE,KAChBJ,EAAcC,GAAKpE,EAAeuE,EAAM,CAAEtE,KAAK,EAAME,QAASiE,IAClE,CACA,IAAIK,EAAW,CACbJ,MAAO,CACLK,QAASP,EACTQ,cAAe7D,EAAQuD,MAAMO,iBAIjC,GACkB,yBAAhBpB,EAAKE,QACW,qBAAhBF,EAAKE,QAGL,GADAe,EAA4B,kBAAI,CAAC,EAC7B,sBAAuB3D,EACzB,IAAK,MAAOsD,EAAGS,KAAM/F,OAAOE,QAAQ8B,EAAQgE,mBAAoB,CAC9D,IAAIC,EAAe,CAAC,EACpB,IAAK,MAAMX,KAAKS,EAAEP,cAAe,CAC/B,MAAMC,EAAOM,EAAEL,OAAOJ,GAClBtE,EAAcyE,KAChBQ,EAAaX,GAAKpE,EAAeuE,EAAM,CAAEtE,KAAK,EAAME,QAASiE,IAEjE,CACAK,EAA4B,kBAAEL,GAAK,CACjCM,QAASK,EACTC,iBAAkBH,EAAED,eACpBK,SAAUvG,MAAMC,QAAQkG,EAAEK,YAE9B,MAEG,CACLT,EAAuB,aAAI,CAAC,EAC5B,IAAIM,EAAe,CAAC,EACpB,IAAK,MAAMX,KAAKtD,EAAsB,aAAEwD,cAAe,CACrD,MAAMC,EAAOzD,EAAsB,aAAE0D,OAAOJ,GACxCtE,EAAcyE,KAChBQ,EAAaX,GAAKpE,EAAeuE,EAAM,CAAEtE,KAAK,EAAME,QAASiE,IAEjE,CACAK,EAAuB,aAAI,CACzBC,QAASK,EACTC,iBAAkBlE,EAAsB,aAAE8D,eAC1CK,SAAUvG,MAAMC,QAAQmC,EAAsB,aAAEoE,YAEpD,CAYA,MAVoB,SAAhB1B,EAAKE,OACPe,EAA0B,gBAAI3D,EAAQqE,gBAEtB,yBAAhB3B,EAAKE,QACW,qBAAhBF,EAAKE,SAELe,EAA+B,qBAAI3D,EAAQsE,sBAG7CX,EAASY,wBAA0BvE,EAAQuE,wBACpCZ,CACT,CAEA,SAASa,EAA4BC,EAAYC,GAC/C,IAAIC,EAWJ,OAVMF,KAAcpC,IAClBsC,EAAM,IAAIrF,EAAAA,GACRsF,IACAF,EAAeG,IAAIC,SAGrBH,EAAII,aACJ1C,EAAmBoC,GAAcE,GAG5BtC,EAAmBoC,EAC5B,CAEA,MAAMO,EAAiBP,IACrB,IAAmC,IAA/BA,EAAWQ,QAAQ,OAAe,CACpC,IAAIC,EAAST,EAAWU,MAAM,OAC9B,OAAO/C,EAAQmB,MAAMG,OAAOwB,EAAO,IAAIxB,OAAOwB,EAAO,GACvD,CACA,OAAO9C,EAAQmB,MAAMG,OAAOe,IAGxBG,EAAYA,IACTxC,EAAQgD,OAKjB,IAAIC,EACJC,UAAY,SAAUjK,GACpB,MAAM,KAAEJ,EAAI,QAAEwB,GAAYpB,EAAIkK,KAI9B,IAAI1G,GAAQ,EACZ,GAAa,SAAT5D,EAAiB,CACnB4D,GAAQ,EACR,IAAI2G,EAAWC,KAAKC,MAAuC,EAAhCC,UAAUC,oBAA2B,GAC5DC,EAAYvG,EAAAA,GAAkB,CAAEwG,gBAAiBN,IAEjDO,EAAaF,EAAUG,KAAK,IACvB1G,EAAAA,MAGTyG,EAAWC,KAAMpL,IACfqH,EAAarH,EACbI,YAAY,CACVC,KAAMA,EACNI,IAAK,sCAIT,IAAI4K,GHnKO,OAATpN,IACFA,EAAO,IAAIsD,QAAQ,CAACC,EAASC,MAE3BzD,EAAcsN,UAAUC,KAAK,cAAe,IAEhCC,gBAAmBC,IAC7B,IAAIC,EAAoBD,EAAEzJ,OAAOb,OAIjC,IACEuK,EAAkBC,kBAAkB,YACtC,CAAE,MAAOF,GAAI,CAEbC,EAAkBE,kBAAkB,YAAa,CAAEC,QAAS,SAG9D7N,EAAY2D,UAAY,KACtBH,EAAQ,OAGVxD,EAAY8D,QAAU,KACpBL,EAAO,wCAKNxD,GGyILoN,EACGD,KAAMvL,IACLO,YAAY,CACVC,KAAM,oBACNyD,KAAMjE,EACNY,IAAK,uCAGRqL,MAAOlL,IACNmL,QAAQnL,MAAMA,GACdR,YAAY,CACVC,KAAM,oBACNI,IAAK,4CAIXgK,EAASlJ,QAAQgD,IAAI,CAAC0G,EAAWE,EAAYE,KAG1CD,KAAK,KACJhL,YAAY,CACVC,KAAMA,EACNI,IAAK,kCAGRqL,MAAO9H,IACN+H,QAAQnL,MAAMoD,GACdD,EAAU1D,EAAM2D,EAAKC,IAG3B,MAAO,GAAa,YAAT5D,EACT4D,GAAQ,EACRwG,EACGW,KAAKlN,UACJ,IACI8N,EADSnK,EAAQoK,OACFD,MAEnB,GAAc,OAAVA,EAAgB,CAElB,IAAIE,EAAU,CAAC,EACf,IAAK,MAAOxD,EAAGS,KAAM/F,OAAOE,QAAQ0I,GAC9B,QAAS7C,GAAKA,EAAEgD,OAAO7E,IACzBA,EAAW6B,EAAEgD,KAAKC,eACX9E,EAAWoB,IAEpBwD,EAAQxD,GAAKb,EAAcsB,GAAG,GAC9B+C,EAAQxD,GAAGJ,WAAWa,EAAEZ,SAG1B,IAAK,MAAOG,EAAGS,KAAM/F,OAAOE,QAAQ4I,GAAU,CAC5C1E,QAAgB2B,EAAEkD,OAELL,EAAMtD,GAAnB,IAEI4D,EAAc,SAClB7I,EAAY6I,GAGZ,IAAIC,EAAkB,CAAC,EACvB,IAAK,MAAM7D,KAAKlB,EAAQmB,MAAMC,cAAe,CAC3C,IAAIC,EAAOrB,EAAQmB,MAAMG,OAAOJ,GAChC,GAAItE,EAAcyE,GAAO,CACvB,MAAM2D,EAAQlI,EAAeuE,EAAM,CACjCtE,KAAK,EACLC,QAAQ,EACRC,QAASiE,IAEX6D,EAAgB7D,GAAK8D,CACvB,CACF,CAEA,IAAIC,EAAmB,CACrBC,YAAaH,EACbI,MAAO,CAAC,EACRC,UAAWpF,EAAQmB,MAAMO,eACzB2D,UAAW,CAAC,GAGd,IAAK,MAAOnE,EAAGS,KAAM/F,OAAOE,QAAQkE,EAAQsF,UAAW,CACrDL,EAAwB,MAAE/D,GAAK,CAAC,EAChC+D,EAA4B,UAAE/D,GAAKS,EAAED,eACrC,IAAK,MAAM7E,KAAO8E,EAAEP,cAAe,CACjC,IAAIC,EAAOM,EAAEL,OAAOzE,GAChBD,EAAcyE,KAChB4D,EAAwB,MAAE/D,GAAGrE,GAAOwE,EAExC,CAEIM,EAAEK,aACJiD,EAAwB,MAAE/D,GAAa,SAAIS,EAAEK,WAEjD,CACA7F,EAAY2I,EAAaG,GAEzB,IAAIM,EAAa,YACjBtJ,EAAYsJ,GACZ,IAAIC,EAAkB,CAAC,EAEvB,IAAK,MAAOtE,EAAGS,KAAM/F,OAAOE,QAAQkE,EAAQyF,oBAClB,QAApBvE,EAAEwE,gBACJF,EAAgBtE,GAAK,CACnB1I,EAAGmJ,EAAE,GAAGe,QACRiD,EAAGhE,EAAE,GAAGe,UAKdvG,EAAYoJ,EAAYC,GAEpBtF,GACFA,EAAuB0F,OAGzB1F,EAAyB,IAAIhD,EAAAA,GAC3B8C,EAAQgD,OAEZ,CACF,IAEDsB,MAAO9H,IACN+H,QAAQnL,MAAMoD,GACdD,EAAU1D,EAAM2D,EAAKC,UAGpB,GAAa,oBAAT5D,EACToK,EACGW,KAAKlN,UACJ,IAAI4F,EAAO,CAAC,EACZ,IAEE,IAAIoI,EAAU,CAAC,EACX9G,EAAU,CAAC,EACf,IAAK,MAAOsD,EAAGS,KAAM/F,OAAOE,QAAQzB,EAAQoK,OAAOD,OACjD,GAAI,QAAS7C,EACLA,EAAEgD,OAAO7E,IACbA,EAAW6B,EAAEgD,KAAOtE,EAAcsB,GAClC5B,EAAmB4B,EAAEgD,WAAa7E,EAAW6B,EAAEgD,KAAK/G,WAEtD8G,EAAQxD,GAAKpB,EAAW6B,EAAEgD,KAC1B/G,EAAQsD,GAAKF,EAAgBjB,EAAmB4B,EAAEgD,KAAMhD,OACnD,CACL,IAAIkE,EAAcxF,EAAcsB,GAChC+C,EAAQxD,GAAK2E,EACbjI,EAAQsD,GAAKF,EAAgB0D,EAAQxD,GAAIS,EAC3C,CAGFrF,EAAKhD,OAAS,UACdgD,EAAKwJ,QAAUlI,CACjB,CAAE,MAAOqG,GACPM,QAAQnL,MAAM6K,GACd3H,EAAKhD,OAAS,QACdgD,EAAKI,OAASuH,EAAEtH,UAClB,CAEA/D,YAAY,CACVC,KAAM,uBACNyD,KAAMA,EACNrD,IAAK,oCAGRqL,MAAO9H,IACN+H,QAAQnL,MAAMoD,GACdD,EAAU1D,EAAM2D,EAAKC,UAIpB,GAAa,0BAAT5D,EACToK,EACGW,KAAMpL,IACL,IAAIuN,EAAY1L,EAAQ0L,UACpBC,EAAW3L,EAAQ2L,SACnB3D,EAAahI,EAAQgI,WAErBC,EAAiB2D,EAAAA,GAAsBrD,EAAcP,IAGrD6D,EADM9D,EAA4BC,EAAYC,GAChC6D,cAChB7D,EAAe8D,OAAOvD,QAAQxI,EAAQgM,MACtC/D,EAAe8D,OAAOvD,QAAQxI,EAAQiM,QAEpChK,EAAOiB,EACT2I,EAAQ1I,QAAQwI,GAChBE,EAAQG,KACRN,GAGF,IAAIQ,EAAgB,GACpBlL,EAAeiB,EAAMiK,GACrB3N,YACE,CACEC,KAAM,wBACNyD,KAAMA,EACNrD,IAAK,yCAEPsN,KAGHjC,MAAO9H,IACN+H,QAAQnL,MAAMoD,GACdD,EAAU1D,EAAM2D,EAAKC,UAEpB,GAAa,4BAAT5D,EACToK,EACGW,KAAMpL,IACL,IAAIuN,EAAY1L,EAAQ0L,UAKpBzJ,EAAOiB,EAJD2C,EAAuBiG,cAC/B9L,EAAQgM,KACRhM,EAAQiM,OAGK,QAAEjM,EAAQ2L,UACvB3L,EAAQgM,KACRN,GAGF,IAAIQ,EAAgB,GACpBlL,EAAeiB,EAAMiK,GACrB3N,YACE,CACEC,KAAM,0BACNyD,KAAMA,EACNrD,IAAK,2CAEPsN,KAGHjC,MAAO9H,IACN+H,QAAQnL,MAAMoD,GACdD,EAAU1D,EAAM2D,EAAKC,UAIpB,GAAa,yBAAT5D,EACToK,EACGW,KAAMpL,IACL,IAAIgO,EAAUnM,EAAQmM,QAClBT,EAAY1L,EAAQ0L,UACpBC,EAAW3L,EAAQ2L,SACnB3D,EAAahI,EAAQgI,WAErBC,EAAiB2D,EAAAA,GAAsBrD,EAAcP,IAKrD/F,EAAOiB,EAJD6E,EAA4BC,EAAYC,GAEhCmE,eAAeT,GAI/B1D,EAAe8D,OAAOvD,QAAQ2D,GAC9BT,GAGF,IAAIQ,EAAgB,GACpBlL,EAAeiB,EAAMiK,GACrB3N,YACE,CACEC,KAAM,uBACNyD,KAAMA,EACNrD,IAAK,iCAEPsN,KAGHjC,MAAO9H,IACN+H,QAAQnL,MAAMoD,GACdD,EAAU1D,EAAM2D,EAAKC,UAEpB,GAAa,sBAAT5D,EACToK,EACGW,KAAMpL,IACL,IAAIkO,EAAUrM,EAAQsM,KAClBX,EAAW3L,EAAQ2L,SAEvB,IAAIY,EAAM5G,EAAQgD,OAAOrL,IAAIqO,GAAUa,IAAIH,GAE3C9N,YACE,CACEC,KAAM,oBACNyD,KAAM,CACJqK,KAAMD,EACNI,KAAMF,GAER3N,IAAK,qCAEP,CAAC2N,EAAIrN,WAGR+K,MAAO9H,IACN+H,QAAQnL,MAAMoD,GACdD,EAAU1D,EAAM2D,EAAKC,UAEpB,GAAa,yBAAT5D,EACToK,EACGW,KAAMpL,IACL0H,EAAuB6G,aAAa1M,EAAQ5C,GAAI4C,EAAQ2M,WACxDpO,YAAY,CACVC,KAAM,uBACNI,IAAK,2CAGRqL,MAAO9H,IACN+H,QAAQnL,MAAMoD,GACdD,EAAU1D,EAAM2D,EAAKC,UAEpB,GAAa,2BAAT5D,EACToK,EACGW,KAAMpL,IACL,IAAIuN,EAAY1L,EAAQ0L,UAKpBzJ,EAAOiB,EAHG2C,EAAuBuG,aAAapM,EAAQmM,SACxDnM,EAAQ2L,UAE8B,EAAGD,GAE3C,IAAIQ,EAAgB,GACpBlL,EAAeiB,EAAMiK,GACrB3N,YACE,CACEC,KAAM,+BACNyD,KAAMA,EACNrD,IAAK,iCAEPsN,KAGHjC,MAAO9H,IACN+H,QAAQnL,MAAMoD,GACdD,EAAU1D,EAAM2D,EAAKC,UAEpB,GAAa,wBAAT5D,EACToK,EACGW,KAAMpL,IACL0H,EAAuB+G,gBAAgB5M,EAAQ5C,MAEhD6M,MAAO9H,IACN+H,QAAQnL,MAAMoD,GACdD,EAAU1D,EAAM2D,EAAKC,UAEpB,GAAa,kBAAT5D,EACToK,EACGW,KAAMpL,IACL,IACIoO,EAAKvO,EADL6O,EAAQ7M,EAAQgI,WAMpB,GAHAuE,EAAMhE,EAAcsE,GAGhBnL,YAAYC,OAAO4K,GACrBvO,EAAS,CACPQ,KAAM,QACNsO,OAAQP,EAAIlE,aAET,CACL,IAAI0E,EAAY,GACZC,EAAW,CAAC,EACZC,EAAU,IAAIjJ,WAAWuI,EAAI7P,QACjC6P,EAAIW,IAAI,CAAC/O,EAAG8F,KACJ9F,KAAK6O,IACTA,EAAS7O,GAAK4O,EAAUrQ,OACxBqQ,EAAUhP,KAAKI,IAEjB8O,EAAQhJ,GAAK+I,EAAS7O,KAGxBH,EAAS,CACPQ,KAAM,SACN2O,MAAOF,EACPlB,OAAQgB,EAEZ,CAEA,IAAIK,EAAY,GAChBpM,EAAehD,EAAQoP,GACvB7O,YACE,CACEC,KAAM,gBACNyD,KAAM,CACJ+F,WAAY6E,EACZC,OAAQ9O,GAEVY,IAAK,gCAEPwO,KAGHnD,MAAO9H,IACN+H,QAAQnL,MAAMoD,GACdD,EAAU1D,EAAM2D,EAAKC,UAEpB,GAAa,6BAAT5D,EACToK,EACGW,KAAKlN,UACJ,IAEI4F,GAFA,WAAE+F,EAAU,UAAE0D,EAAS,QAAES,EAAO,SAAER,GAAa3L,EAC/CmN,EAAQzB,EAAUlD,QAAQ,KAG9B,GAAIjD,IAAsByC,EAAY,CACpC,IAAIqF,EACFxH,EAAuBuG,aAAaD,GAASR,GAE/C7F,EAAyBwH,QAAQ/D,KAAMpL,IACrC8D,EAAO6D,EAAyByH,kBAC9BF,EACA,EACA3B,EAAUrD,MAAM,EAAG8E,GACnBzB,EAAUrD,MAAM8E,EAAQ,IAE1BrL,EAAY,2BAA4BG,IAE5C,KAAO,CACL,IAAIgG,EAAiB2D,EAAAA,GAAsBrD,EAAcP,IAErDqF,EADMtF,EAA4BC,EAAYC,GAC3BmE,eAAeT,GAEtC7F,EAAyBwH,QAAQ/D,KAAMpL,IACrC8D,EAAO6D,EAAyByH,kBAC9BF,EACApF,EAAe8D,OAAOvD,QAAQ2D,GAC9BT,EAAUrD,MAAM,EAAG8E,GACnBzB,EAAUrD,MAAM8E,EAAQ,IAE1BrL,EAAY,2BAA4BG,IAE5C,IAEDgI,MAAO9H,IACN+H,QAAQnL,MAAMoD,GACdD,EAAU1D,EAAM2D,EAAKC,UAEpB,GAAa,+BAAT5D,EACToK,EACGW,KAAKlN,UACJ,IAEI4F,GAFA,WAAE+F,EAAU,UAAE0D,EAAS,KAAEM,EAAI,MAAEC,EAAK,SAAEN,GAAa3L,EACnDmN,EAAQzB,EAAUlD,QAAQ,KAE9B,GAAIjD,IAAsByC,EAAY,CACpC,IAAIqF,EAAexH,EAAuBiG,cAAcE,EAAMC,GAE9DnG,EAAyBwH,QAAQ/D,KAAMpL,IACrC8D,EAAO6D,EAAyByH,kBAC9BF,EAAalK,QAAQwI,GACrB,EACAD,EAAUrD,MAAM,EAAG8E,GACnBzB,EAAUrD,MAAM8E,EAAQ,IAE1BrL,EAAY,6BAA8BG,IAE9C,KAAO,CACL,IAAIgG,EAAiB2D,EAAAA,GAAsBrD,EAAcP,IAGrD6D,EAFM9D,EAA4BC,EAAYC,GAEhC6D,cAChB7D,EAAe8D,OAAOvD,QAAQxI,EAAQgM,MACtC/D,EAAe8D,OAAOvD,QAAQxI,EAAQiM,QAGxCnG,EAAyBwH,QAAQ/D,KAAMpL,IACrC8D,EAAO6D,EAAyByH,kBAC9B1B,EAAQ1I,QAAQwI,GAChBE,EAAQG,KACRN,EAAUrD,MAAM,EAAG8E,GACnBzB,EAAUrD,MAAM8E,EAAQ,IAE1BrL,EAAY,6BAA8BG,IAE9C,IAEDgI,MAAO9H,IACN+H,QAAQnL,MAAMoD,GACdD,EAAU1D,EAAM2D,EAAKC,UAEpB,GAAa,qBAAT5D,EACToK,EACGW,KAAMpL,IACL,IAAI,MAAEgP,GAAUnN,EAGhB8B,EAAY,mBADDgE,EAAyB0H,qBAAqBL,MAG1DlD,MAAO9H,IACN+H,QAAQnL,MAAMoD,GACdD,EAAU1D,EAAM2D,EAAKC,UAEpB,GAAa,0BAAT5D,EACToK,EACGW,KAAMpL,IACL,IAII0N,EAAS4B,GAJT,MAAEN,EAAK,QAAEhB,EAAO,WAAEnE,EAAU,SAAE2D,EAAQ,UAAED,GAAc1L,EAEtDiC,EAAO6D,EAAyB4H,uBAAuBP,GAI3D,GAAI5H,IAAsByC,EACxB6D,EAAUhG,EAAuBuG,aAAapM,EAAQmM,SACpDnM,EAAQ2L,UAEV8B,EAAcvK,EACZ2I,EACA,EACA7L,EAAQ0L,eAEL,CACL,IAAIzD,EAAiB2D,EAAAA,GAAsBrD,EAAcP,IAGzD6D,EAFU9D,EAA4BC,EAAYC,GAEpCmE,eAAeT,GAG7B8B,EAAcvK,EACZ2I,EACA5D,EAAe8D,OAAOvD,QAAQ2D,GAC9BT,EAEJ,CAEA,IAAIuB,EAAUQ,EAAYnK,SACvB4J,IAAI,CAAC/O,EAAG8F,IAAOhC,EAAK0L,SAASxP,GAAK8F,GAAK,KACvC2J,OAAQzP,IAAa,MAAPA,GAEb0P,EAAuB,CAAC,EAC5B,IAAK,MAAOhH,EAAGS,KAAM/F,OAAOE,QAAQgM,GAClCI,EAAqBhH,GAAKS,EACvB4F,IAAI,CAAC/O,EAAG8F,IAAOgJ,EAAQU,SAAS1J,GAAK9F,GAAK,KAC1CyP,OAAQzP,IAAa,MAAPA,GAGnB2D,EAAY,wBAAyB+L,KAEtC5D,MAAO9H,IACN+H,QAAQnL,MAAMoD,GACdD,EAAU1D,EAAM2D,EAAKC,UAEpB,GAAa,yBAAT5D,EACToK,EAAOW,KAAKlN,UACV,IAAI,SAAEsP,GAAa3L,EAEf8F,GACFA,EAAyByF,OAG3BzF,EAA2B,IAAIjD,EAAAA,GAC7B8C,EAAQsF,SAASU,GACjB,CAAEmC,WAAYnI,EAAQgD,OAAOrL,IAAIqO,KAGnC7F,EAAyBwH,QAAQ/D,KAAMpL,IACrC,IAAI4P,EAAcjI,EAAyBkI,yBACvCC,EAAOnI,EAAyBoI,kBAUpCpM,EAAY,yBATD,CACTiM,YAAaA,EACbE,KAAM,CACJE,MAAOF,EAAKE,MACZC,aAAcH,EAAKG,aACnBC,MAAOJ,EAAKI,MAAMhG,QAClB0F,YAAaE,EAAKF,YAAY1F,oBAMjC,GAAa,0BAAT7J,EAAkC,CAC3C,IAAI,WAAEwJ,EAAU,QAAEmE,EAAO,SAAER,GAAa3L,EACpCV,EAAS,CAAEgP,cAAe,CAAC,GAC3BC,EAAU,KACd,GAAIhJ,IAAsByC,EACxBuG,EAAU1I,EAAuBuG,aAAaD,OACzC,CACL,IACIjE,EAAMH,EAA4BC,EADjB4D,EAAAA,GAAsBrD,EAAcP,KAEzDuG,EAAUrG,EAAIkE,cAChB,CACgB,OAAZmC,GAAoB5C,KAAY4C,IACL,OAAzBxI,IACFA,EAAuB,IAAIlD,EAAAA,GACzB8C,EAAQsF,SAASU,KAGrB5F,EACGuH,QACA/D,KAAK,KACJjK,EAASyG,EAAqByI,cAAcD,EAAQ5C,IACpD7J,EAAY,wBAAyBxC,KAEtC2K,MAAO9H,IACN+H,QAAQnL,MAAMoD,GACdD,EAAU1D,EAAM2D,EAAKC,KAG7B,MACE8H,QAAQnL,MAAM,4BACdmD,EAAU1D,EAAM,mBAAoB4D,EAExC,C,GCvvBIqM,EAA2B,CAAC,EAGhC,SAASC,EAAoBC,GAE5B,IAAIC,EAAeH,EAAyBE,GAC5C,QAAqBhS,IAAjBiS,EACH,OAAOA,EAAaC,QAGrB,IAAIC,EAASL,EAAyBE,GAAY,CACjDvR,GAAIuR,EACJ/F,QAAQ,EACRiG,QAAS,CAAC,GAUX,OANAE,EAAoBJ,GAAUK,KAAKF,EAAOD,QAASC,EAAQA,EAAOD,QAASH,GAG3EI,EAAOlG,QAAS,EAGTkG,EAAOD,OACf,CAGAH,EAAoBO,EAAIF,EAGxBL,EAAoBvQ,EAAI,KAGvB,IAAI+Q,EAAsBR,EAAoBS,OAAExS,EAAW,CAAC,IAAI,IAAI,KAAM,IAAO+R,EAAoB,OAErG,OADAQ,EAAsBR,EAAoBS,EAAED,I,MCnC7C,IAAIE,EAAW,GACfV,EAAoBS,EAAI,CAAC7P,EAAQ+P,EAAUC,EAAIC,KAC9C,IAAGF,EAAH,CAMA,IAAIG,EAAeC,IACnB,IAASxL,EAAI,EAAGA,EAAImL,EAAS1S,OAAQuH,IAAK,CAGzC,IAFA,IAAKoL,EAAUC,EAAIC,GAAYH,EAASnL,GACpCyL,GAAY,EACPC,EAAI,EAAGA,EAAIN,EAAS3S,OAAQiT,MACpB,EAAXJ,GAAsBC,GAAgBD,IAAahO,OAAOqO,KAAKlB,EAAoBS,GAAGU,MAAOrO,GAASkN,EAAoBS,EAAE3N,GAAK6N,EAASM,KAC9IN,EAASS,OAAOH,IAAK,IAErBD,GAAY,EACTH,EAAWC,IAAcA,EAAeD,IAG7C,GAAGG,EAAW,CACbN,EAASU,OAAO7L,IAAK,GACrB,IAAI8L,EAAIT,SACE3S,IAANoT,IAAiBzQ,EAASyQ,EAC/B,CACD,CACA,OAAOzQ,CAnBP,CAJCiQ,EAAWA,GAAY,EACvB,IAAI,IAAItL,EAAImL,EAAS1S,OAAQuH,EAAI,GAAKmL,EAASnL,EAAI,GAAG,GAAKsL,EAAUtL,IAAKmL,EAASnL,GAAKmL,EAASnL,EAAI,GACrGmL,EAASnL,GAAK,CAACoL,EAAUC,EAAIC,G,KCJ/Bb,EAAoBsB,EAAI,CAACnB,EAASoB,KACjC,IAAI,IAAIzO,KAAOyO,EACXvB,EAAoBwB,EAAED,EAAYzO,KAASkN,EAAoBwB,EAAErB,EAASrN,IAC5ED,OAAO4O,eAAetB,EAASrN,EAAK,CAAE4O,YAAY,EAAM9S,IAAK2S,EAAWzO,MCJ3EkN,EAAoBxK,EAAI,CAAC,EAGzBwK,EAAoB9E,EAAKyG,GACjB3Q,QAAQgD,IAAInB,OAAOqO,KAAKlB,EAAoBxK,GAAGoM,OAAO,CAACC,EAAU/O,KACvEkN,EAAoBxK,EAAE1C,GAAK6O,EAASE,GAC7BA,GACL,KCNJ7B,EAAoB8B,EAAKH,GAEjB,aAAeA,EAAU,IAAM,CAAC,IAAM,WAAW,IAAM,WAAW,IAAM,WAAW,IAAM,WAAW,IAAM,WAAW,IAAM,YAAYA,GAAW,YCF1J3B,EAAoB+B,SAAYJ,MCDhC3B,EAAoBgC,EAAI,WACvB,GAA0B,kBAAfC,WAAyB,OAAOA,WAC3C,IACC,OAAOC,MAAQ,IAAIC,SAAS,cAAb,EAChB,CAAE,MAAOjH,GACR,GAAsB,kBAAXkH,OAAqB,OAAOA,MACxC,CACA,CAPuB,GCAxBpC,EAAoBwB,EAAI,CAACa,EAAKC,IAAUzP,OAAO0P,UAAUC,eAAelC,KAAK+B,EAAKC,GCAlFtC,EAAoByC,IAAOrC,IAC1BA,EAAOsC,MAAQ,GACVtC,EAAOuC,WAAUvC,EAAOuC,SAAW,IACjCvC,GCHRJ,EAAoB4C,EAAI,S,MCAxB5C,EAAoB6C,EAAIC,KAAKC,SAAW,aAIxC,IAAIC,EAAkB,CACrB,IAAK,GAgBNhD,EAAoBxK,EAAED,EAAI,CAACoM,EAASE,KAE/BmB,EAAgBrB,IAElBsB,cAAcjD,EAAoB4C,EAAI5C,EAAoB8B,EAAEH,KAK/D,IAAIuB,EAAqBJ,KAAuB,iBAAIA,KAAuB,kBAAK,GAC5EK,EAA6BD,EAAmB7T,KAAK+T,KAAKF,GAC9DA,EAAmB7T,KAvBC+K,IACnB,IAAKuG,EAAU0C,EAAaC,GAAWlJ,EACvC,IAAI,IAAI6F,KAAYoD,EAChBrD,EAAoBwB,EAAE6B,EAAapD,KACrCD,EAAoBO,EAAEN,GAAYoD,EAAYpD,IAIhD,IADGqD,GAASA,EAAQtD,GACdW,EAAS3S,QACdgV,EAAgBrC,EAAS4C,OAAS,EACnCJ,EAA2B/I,G,WCnB5B,IAAIoJ,EAAOxD,EAAoBvQ,EAC/BuQ,EAAoBvQ,EAAI,IAChBuB,QAAQgD,IAAI,CAAC,IAAI,IAAI,KAAKwK,IAAIwB,EAAoB9E,EAAG8E,IAAsBnF,KAAK2I,E,KCD9DxD,EAAoBvQ,G","sources":["workers/DownloadsDBHandler.js","workers/helpers.js","utils/utils.js","workers/explorer.worker.js","../webpack/bootstrap","../webpack/runtime/chunk loaded","../webpack/runtime/define property getters","../webpack/runtime/ensure chunk","../webpack/runtime/get javascript chunk filename","../webpack/runtime/get mini-css chunk filename","../webpack/runtime/global","../webpack/runtime/hasOwnProperty shorthand","../webpack/runtime/node module decorator","../webpack/runtime/publicPath","../webpack/runtime/importScripts chunk loading","../webpack/runtime/startup chunk dependencies","../webpack/startup"],"sourcesContent":["var DownloadsDB;\nvar init = null;\n\nexport function initialize() {\n  if (init === null) {\n    init = new Promise((resolve, reject) => {\n      // initialize database on worker creation\n      DownloadsDB = indexedDB.open(\"DownloadsDB\", 3);\n\n      DownloadsDB.onupgradeneeded = (e) => {\n        var DownloadsDBClient = e.target.result;\n\n        // Currently purging all existing stores when the version is updated.\n        // At some point we may add a more sophisticated upgrade mechanism.\n        try {\n          DownloadsDBClient.deleteObjectStore(\"downloads\");\n        } catch (e) {}\n\n        DownloadsDBClient.createObjectStore(\"downloads\", { keyPath: \"url\" });\n      };\n\n      DownloadsDB.onsuccess = () => {\n        resolve(null);\n      };\n\n      DownloadsDB.onerror = () => {\n        reject(\"failed to initialize DownloadsDB\");\n      };\n    });\n  }\n\n  return init;\n}\n\nasync function fetchWithProgress(url, startFun, iterFun, endFun, params=null) {\n  let res;\n  if (params == null) {\n    res = await fetch(url);\n  } else {\n    res = await fetch(url, params);\n  }\n\n  if (!res.ok) {\n    throw new Error(\"oops, failed to download '\" + url + \"'\");\n  }\n\n  const cl = res.headers.get(\"content-length\"); // WARNING: this might be NULL!\n  const id = startFun(cl);\n\n  const reader = res.body.getReader();\n  const chunks = [];\n  let total = 0;\n\n  while (true) {\n    const { done, value } = await reader.read();\n    if (done) {\n      break;\n    }\n    chunks.push(value);\n    total += value.length;\n    iterFun(id, total);\n  }\n\n  let output = new Uint8Array(total);\n  let start = 0;\n  for (const x of chunks) {\n    output.set(x, start);\n    start += x.length;\n  }\n\n  endFun(id, total);\n  return output;\n}\n\nasync function fetchWrapper(url, params = null) {\n  try {\n    const out = await fetchWithProgress(\n      url,\n      (cl) => {\n        postMessage({\n          type: `DOWNLOAD for url: ` + String(url),\n          download: \"START\",\n          url: String(url),\n          total_bytes: String(cl),\n          msg: \"Total size is \" + String(cl) + \" bytes!\",\n        });\n        return url;\n      },\n      (id, sofar) => {\n        postMessage({\n          type: `DOWNLOAD for url: ` + String(url),\n          download: \"PROGRESS\",\n          url: String(url),\n          downloaded_bytes: String(sofar),\n          msg: \"Progress so far, got \" + String(sofar) + \" bytes!\",\n        });\n      },\n      (id, total) => {\n        postMessage({\n          type: `DOWNLOAD for url: ` + String(url),\n          download: \"COMPLETE\",\n          url: String(url),\n          msg: \"Finished, got \" + String(total) + \" bytes!\",\n        });\n      },\n      params\n    );\n\n    return out;\n  } catch (error) {\n    // console.log(\"oops error\", error)\n    postMessage({\n      type: `DOWNLOAD for url: ` + String(url),\n      download: \"START\",\n      url: String(url),\n      total_bytes: 100,\n    });\n\n    let req;\n    if (params == null) {\n      req = fetch(url);\n    } else {\n      req = fetch(url, params);\n    }\n\n    var res = await req;\n    if (!res.ok) {\n      throw new Error(\"failed to download '\" + url + \"' (\" + res.status + \")\");\n    }\n    var buffer = await res.arrayBuffer();\n\n    postMessage({\n      type: `DOWNLOAD for url: ` + String(url),\n      download: \"COMPLETE\",\n      url: String(url),\n    });\n    return new Uint8Array(buffer);\n  }\n}\n\nexport async function get(url, params = null, force = false) {\n  await init;\n\n  if (!force) {\n    let trans = DownloadsDB.result.transaction([\"downloads\"], \"readonly\");\n    let download_store = trans.objectStore(\"downloads\");\n\n    var data_check = new Promise((resolve, reject) => {\n      var already = download_store.get(url);\n      already.onsuccess = event => {\n        if (already.result !== undefined) {\n          resolve(already.result.payload);\n        } else {\n          resolve(null);\n        }\n      };\n      already.onerror = event => {\n        reject(`failed to query DownloadsDB for ${url}: ${event.target.errorCode}`);\n      };\n    });\n\n    var found = await data_check;\n    if (found !== null) {\n      return found;\n    }\n  }\n\n  var buffer = await fetchWrapper(url, params)\n\n  // Technically, this isn't quite right, because we need to close the read\n  // transaction before opening the write transaction; multiple queries to\n  // the same URL from different workers could cause multiple downloads if\n  // they each miss each other's read check. But oh well; the auto-commit\n  // of IDB transactions means that it's hard to do any better. (Specifically,\n  // we can't do an async fetch while the transaction is still open, because\n  // it just closes before the fetch is done.)\n  let trans = DownloadsDB.result.transaction([\"downloads\"], \"readwrite\");\n\n  // The Promise's function should evaluate immediately\n  // (see https://stackoverflow.com/questions/35177230/are-promises-lazily-evaluated) \n  // so the callbacks should be attached to the transaction before we return to the event loop.\n  let fin = new Promise((resolve, reject) => {\n    trans.oncomplete = (event) => {\n      resolve(null);\n    };\n    trans.onerror = (event) => {\n      reject(new Error(`transaction error for saving ${url} in DownloadsDB: ${event.target.errorCode}`));\n    };\n  });\n\n  let download_store = trans.objectStore(\"downloads\");\n  let saving = new Promise((resolve, reject) => {\n    var putrequest = download_store.put({ url: url, payload: buffer });\n    putrequest.onsuccess = event => {\n      resolve(true);\n    };\n    putrequest.onerror = event => {\n      reject(new Error(`failed to cache ${url} in DownloadsDB: ${event.target.errorCode}`));\n    };\n  });\n\n  // Stack all awaits here, AFTER event handlers have been attached.\n  await saving;\n  await fin;\n  return buffer;\n}\n\nexport async function remove(url) {\n  await init;\n  let trans = DownloadsDB.result.transaction([\"downloads\"], \"readwrite\");\n  let fin = new Promise((resolve, reject) => {\n    trans.oncomplete = (event) => {\n      resolve(null);\n    };\n    trans.onerror = (event) => {\n      reject(new Error(`transaction error for removing ${url} in DownloadsDB: ${event.target.errorCode}`));\n    };\n  });\n\n  let download_store = trans.objectStore(\"downloads\")\n  let removal = new Promise((resolve, reject) => {\n    let request = download_store.delete(url);\n    request.onsuccess = event => {\n      resolve(true);\n    };\n    request.onerror = event => {\n      reject(new Error(`failed to remove ${url} from DownloadsDB: ${event.target.errorCode}`));\n    };\n  });\n\n  // Only await after attaching event handlers.\n  await removal;\n  await fin;\n  return;\n}\n","import * as bakana from \"bakana\";\nimport * as gesel from \"gesel\";\nimport * as remotes from \"bakana-remotes\";\nimport * as downloads from \"./DownloadsDBHandler.js\";\n\n// Evade CORS problems and enable caching.\nconst proxy = \"https://cors-proxy.aaron-lun.workers.dev\";\nasync function proxyAndCache(url) {\n  let buffer = await downloads.get(proxy + \"/\" + encodeURIComponent(url));\n  return new Uint8Array(buffer);\n}\n\nbakana.CellLabellingState.setDownload(proxyAndCache);\ngesel.setGeneDownload(proxyAndCache);\nbakana.RnaQualityControlState.setDownload(proxyAndCache);\n\ngesel.referenceDownload(async (file, start, end) => {\n  let url = gesel.referenceBaseUrl() + \"/\" + file;\n  let full = proxy + \"/\" + encodeURIComponent(url);\n  if (start == null && end == null) {\n    let buffer = await downloads.get(full);\n    return new Response(buffer);\n  } else {\n    return fetch(full + \"?start=\" + String(start) + \"&end=\" + String(end));\n  }\n});\n\ngesel.geneDownload(async (file) => {\n  let url = gesel.geneBaseUrl() + \"/\" + file;\n  let buffer = await downloads.get(proxy + \"/\" + encodeURIComponent(url));\n  return new Response(buffer);\n});\n\nremotes.GypsumDataset.setDownloadFun(proxyAndCache);\nbakana.availableReaders[\"ExperimentHub\"] = remotes.GypsumDataset;\nbakana.availableReaders[\"gypsum\"] = remotes.GypsumDataset;\n\nexport function extractBuffers(object, store) {\n  if (!object) {\n    return;\n  }\n\n  if (Array.isArray(object)) {\n    for (const element of object) {\n      extractBuffers(element, store);\n    }\n  } else if (object.constructor == Object) {\n    for (const [key, element] of Object.entries(object)) {\n      extractBuffers(element, store);\n    }\n  } else if (ArrayBuffer.isView(object)) {\n    if (!(object.buffer instanceof ArrayBuffer)) {\n      throw \"only ArrayBuffers should be in the message payload\";\n    }\n    store.push(object.buffer);\n  }\n}\n\nexport function postAttempt(step) {\n  postMessage({\n    type: `${step}_START`,\n  });\n}\n\nexport function postSuccess(step, info) {\n  if (typeof info == \"undefined\") {\n    postMessage({\n      type: `${step}_CACHE`,\n    });\n  } else {\n    var transferable = [];\n    extractBuffers(info, transferable);\n    postMessage(\n      {\n        type: `${step}_DATA`,\n        resp: info,\n      },\n      transferable\n    );\n  }\n}\n\nexport function postError(type, err, fatal) {\n  postMessage({\n    type: `${type}_ERROR`,\n    resp: {\n      reason: err.toString(),\n      fatal: fatal,\n    },\n  });\n}\n\nexport function splitMetricsByBlock(metrics, blockLevels, blockIds) {\n  var output = {};\n  var blocks = blockIds.slice();\n  for (var b = 0; b < blockLevels.length; b++) {\n    let current = {};\n    for (const [key, val] of Object.entries(metrics)) {\n      current[key] = val.slice().filter((x, i) => blocks[i] == b);\n    }\n    output[blockLevels[b]] = current;\n  }\n  return output;\n}\n\nexport function splitThresholdsByBlock(thresholds, blockLevels) {\n  var output = {};\n  for (const x of blockLevels) {\n    output[x] = {};\n  }\n\n  for (const [key, val] of Object.entries(thresholds)) {\n    for (var b = 0; b < blockLevels.length; b++) {\n      output[blockLevels[b]][key] = val[b];\n    }\n  }\n\n  return output;\n}\n\nexport async function fetchStepSummary(state, step) {\n  // do not send any response to UI if they have not changed\n  if (!state[step].changed) {\n    return undefined;\n  }\n\n  if (step === \"inputs\") {\n    let output = {};\n\n    let ngenes = {};\n    for (const a of state[step].fetchCountMatrix().available()) {\n      ngenes[a] = state[step].fetchCountMatrix().get(a).numberOfRows();\n    }\n\n    let gene_info = {};\n    for (const [k, v] of Object.entries(\n      state[step].fetchFeatureAnnotations()\n    )) {\n      let info = {};\n      for (const c of v.columnNames()) {\n        let col = v.column(c);\n        if (Array.isArray(col)) {\n          info[c] = col;\n        }\n      }\n\n      if (Array.isArray(v.rowNames())) {\n        info[\"rownames\"] = v.rowNames();\n      }\n\n      gene_info[k] = info;\n    }\n\n    let cell_info = {};\n    for (const c of state[step].fetchCellAnnotations().columnNames()) {\n      let col = state[step].fetchCellAnnotations().column(c);\n      if (isArrayOrView(col)) {\n        const ksumm = describeColumn(col, {\n          all: false,\n          unique: true,\n          colname: c,\n        });\n        cell_info[c] = ksumm;\n      }\n    }\n\n    var blocks = state[step].fetchBlockLevels();\n    if (blocks !== null) {\n      const col = state[step].fetchBlock().slice();\n      if (isArrayOrView(col)) {\n        const ksumm = describeColumn(col, {\n          all: false,\n          unique: true,\n          colname: \"__batch__\",\n        });\n        cell_info[\"__batch__\"] = ksumm;\n      }\n    }\n\n    output = {\n      num_cells: state[step].fetchCountMatrix().numberOfColumns(),\n      num_genes: ngenes,\n      genes: gene_info,\n      annotations: cell_info,\n    };\n\n    return output;\n  } else if (step === \"rna_quality_control\") {\n    let metrics = {\n      sums: state[step].fetchMetrics().sum(),\n      detected: state[step].fetchMetrics().detected(),\n      proportion: state[step].fetchMetrics().subsetProportion(0),\n    };\n\n    let output = {};\n    var blocks = state[\"inputs\"].fetchBlockLevels();\n\n    if (blocks === null) {\n      blocks = [\"default\"];\n      output.data = { default: metrics };\n    } else {\n      let bids = state[\"inputs\"].fetchBlock();\n      output.data = splitMetricsByBlock(metrics, blocks, bids);\n    }\n\n    let listed = {\n      sums: state[step].fetchFilters().sum(),\n      detected: state[step].fetchFilters().detected(),\n      proportion: state[step].fetchFilters().subsetProportion(0),\n    };\n    output.thresholds = splitThresholdsByBlock(listed, blocks);\n\n    return output;\n  } else if (step === \"adt_quality_control\") {\n    let metrics = {\n      sums: state[step].fetchMetrics().sum(),\n      detected: state[step].fetchMetrics().detected(),\n      proportion: state[step].fetchMetrics().subsetSum(0),\n    };\n\n    var output = {};\n    var blocks = state[\"inputs\"].fetchBlockLevels();\n    if (blocks === null) {\n      blocks = [\"default\"];\n      output.data = { default: metrics };\n    } else {\n      let bids = state[\"inputs\"].fetchBlock();\n      output.data = splitMetricsByBlock(metrics, blocks, bids);\n    }\n\n    let listed = {\n      detected: state[step].fetchFilters().detected(),\n      proportion: state[step].fetchFilters().subsetSum(0),\n    };\n    output.thresholds = splitThresholdsByBlock(listed, blocks);\n\n    // We don't use sums for filtering but we do report it in the metrics,\n    // so we just add some NaNs to the thresholds for consistency.\n    for (const [k, v] of Object.entries(output.thresholds)) {\n      v.sums = NaN;\n    }\n\n    return output;\n  } else if (step === \"crispr_quality_control\") {\n    let metrics = {\n      sums: state[step].fetchMetrics().sum(),\n      detected: state[step].fetchMetrics().detected(),\n      proportion: state[step].fetchMetrics().maxProportion(),\n    };\n\n    let output = {};\n    var blocks = state[\"inputs\"].fetchBlockLevels();\n    if (blocks === null) {\n      blocks = [\"default\"];\n      output.data = { default: metrics };\n    } else {\n      let bids = state[\"inputs\"].fetchBlock();\n      output.data = splitMetricsByBlock(metrics, blocks, bids);\n    }\n\n    let listed = {\n      count: state[step].fetchFilters().maxValue(0),\n    };\n    output.thresholds = splitThresholdsByBlock(listed, blocks);\n\n    return output;\n  } else if (step === \"cell_filtering\") {\n    let remaining = 0,\n      keep_vec = null;\n    const keepBuff = state[step].fetchKeep();\n    if (keepBuff) {\n      keepBuff.forEach((x) => {\n        remaining += (x != 0);\n      });\n      keep_vec = keepBuff.slice();\n    } else {\n      remaining = state.inputs.fetchCountMatrix().numberOfColumns();\n    }\n    let output = { retained: remaining, keep: keep_vec };\n    return output;\n  } else if (step === \"rna_normalization\") {\n    return {};\n  } else if (step === \"adt_normalization\") {\n    return {};\n  } else if (step === \"crispr_normalization\") {\n    return {};\n  } else if (step === \"feature_selection\") {\n    let output = {\n      means: state[step].fetchResults().means(),\n      vars: state[step].fetchResults().variances(),\n      fitted: state[step].fetchResults().fitted(),\n      resids: state[step].fetchResults().residuals(),\n    };\n    return output;\n  } else if (\n    step === \"rna_pca\" ||\n    step === \"adt_pca\" ||\n    step === \"crispr_pca\"\n  ) {\n    let pcs = state[step].fetchPCs();\n    var var_exp = pcs.varianceExplained();\n    var total_var = pcs.totalVariance();\n    var_exp.forEach((x, i) => {\n      var_exp[i] = x / total_var;\n    });\n    return {\n      var_exp: var_exp,\n    };\n  } else if (step === \"combine_embeddings\") {\n    return {};\n  } else if (step === \"batch_correction\") {\n    return {};\n  } else if (step === \"neighbor_index\") {\n    return {};\n  } else if (step === \"tsne\" || step === \"umap\") {\n    return await state[step].fetchResults();\n  } else if (step === \"kmeans_cluster\") {\n    return {};\n  } else if (step === \"snn_graph_cluster\") {\n    return {};\n  } else if (step === \"choose_clustering\") {\n    var clusters = state[step].fetchClusters();\n    return { clusters: clusters.slice() };\n  } else if (step === \"marker_detection\") {\n    return {};\n  } else if (step === \"cell_labelling\") {\n    let markers = state.marker_detection.fetchResults();\n    if (\"RNA\" in markers) {\n      let results = state[step].computeLabels(markers.RNA);\n      // for (const [k, v] of Object.entries(results.per_reference)) { // TODO: return scores.\n      //   results.per_reference[k] = v.map(x => x.best);\n      // }\n      // if (\"integrated\" in results) {\n      //   results.integrated = results.integrated.map(x => x.best);\n      // }\n      return results;\n    } else {\n      return { per_reference: {} };\n    }\n  } else if (step === \"custom_selections\") {\n    return {};\n  } else if (step === \"feature_set_enrichment\") {\n    let collections = state.feature_set_enrichment.fetchCollectionDetails();\n    let sets = state.feature_set_enrichment.fetchSetDetails();\n    return {\n      collections: collections,\n      sets: {\n        names: sets.names,\n        descriptions: sets.descriptions,\n        sizes: sets.sizes.slice(),\n        collections: sets.collections.slice(),\n      },\n    };\n  }\n}\n\nexport function isArrayOrView(col) {\n  return Array.isArray(col) || ArrayBuffer.isView(col);\n}\n\nexport function describeColumn(\n  col,\n  { all = false, unique = false, colname = null } = {}\n) {\n  let res;\n  if (isArrayOrView(col)) {\n    res = bakana.summarizeArray(col);\n    const uqVals = new Set(col);\n    res[\"num_unique\"] = uqVals.size;\n\n    if ((uqVals.size <= 50) & unique) res[\"values\"] = [...uqVals].sort();\n    if (all) res[\"_all_\"] = col;\n\n    // if type is continous and unique values is less than 50, type is both\n    if (res[\"type\"] === \"continuous\" && uqVals.size <= 50) res[\"type\"] = \"both\";\n\n    if (typeof colname === \"string\" || colname instanceof String)\n      res[\"name\"] = colname;\n  }\n\n  return res;\n}\n\nexport function formatMarkerResults(results, group, rankEffect) {\n    if (!rankEffect || rankEffect === undefined) {\n        rankEffect = \"cohen-min-rank\";\n    }\n\n    var ordering;\n    {\n        // Choosing the ranking statistic. Do NOT do any Wasm allocations\n        // until 'ranking' is fully consumed!\n        let increasing = false;\n        let summary; \n        if (rankEffect.match(/-mean$/)) {\n            summary = \"mean\";\n        } else if (rankEffect.match(/-min$/)) {\n            summary = \"minimum\";\n        } else if (rankEffect.match(/-min-rank$/)) {\n            summary = \"min-rank\";\n            increasing = true;\n        } else {\n            throw \"unknown rank type '\" + rankEffect + \"'\";\n        }\n\n        let ranking;\n        if (rankEffect.match(/^cohen-/)) {\n            ranking = results.cohensD(group, { summary: summary, copy: false });\n        } else if (rankEffect.match(/^auc-/)) {\n            ranking = results.auc(group, { summary: summary, copy: false });\n        } else if (rankEffect.match(/^lfc-/)) {\n            ranking = results.deltaMean(group, { summary: summary, copy: false });\n        } else if (rankEffect.match(/^delta-d-/)) {\n            ranking = results.deltaDetected(group, { summary: summary, copy: false });\n        } else {\n            throw \"unknown rank type '\" + rankEffect + \"'\";\n        }\n  \n        // Computing the ordering based on the ranking statistic.\n        ordering = new Int32Array(ranking.length);\n        for (var i = 0; i < ordering.length; i++) {\n            ordering[i] = i;\n        }\n        if (increasing) {\n            ordering.sort((f, s) => (ranking[f] - ranking[s]));\n        } else {\n            ordering.sort((f, s) => (ranking[s] - ranking[f]));\n        }\n    }\n  \n    // Apply that ordering to each statistic of interest.\n    var reorder = function(stats) {\n        var thing = new Float64Array(stats.length);\n        for (var i = 0; i < ordering.length; i++) {\n            thing[i] = stats[ordering[i]];\n        }\n        return thing;\n    };\n  \n    var stat_mean = reorder(results.mean(group, { copy: false }));\n    var stat_detected = reorder(results.detected(group, { copy: false }));\n    var stat_lfc = reorder(results.deltaMean(group, { summary: \"mean\", copy: false }));\n    var stat_delta_d = reorder(results.deltaDetected(group, { summary: \"mean\", copy: false }));\n\n    return {\n        \"ordering\": ordering,\n        \"means\": stat_mean,\n        \"detected\": stat_detected,\n        \"lfc\": stat_lfc,\n        \"delta_detected\": stat_delta_d\n    };\n}\n","import { randomColor } from \"randomcolor\";\n\nexport const getColors = (data) => {\n  const palette = {\n    1: [\"#1b9e77\"],\n    2: [\"#1b9e77\", \"#d95f02\"],\n    3: [\"#1b9e77\", \"#d95f02\", \"#7570b3\"],\n    4: [\"#1b9e77\", \"#d95f02\", \"#7570b3\", \"#e7298a\"],\n    5: [\"#1b9e77\", \"#d95f02\", \"#7570b3\", \"#e7298a\", \"#66a61e\"],\n    6: [\"#1b9e77\", \"#d95f02\", \"#7570b3\", \"#e7298a\", \"#66a61e\", \"#e6ab02\"],\n    7: [\n      \"#1b9e77\",\n      \"#d95f02\",\n      \"#7570b3\",\n      \"#e7298a\",\n      \"#66a61e\",\n      \"#e6ab02\",\n      \"#a6761d\",\n    ],\n    8: [\n      \"#1b9e77\",\n      \"#d95f02\",\n      \"#7570b3\",\n      \"#e7298a\",\n      \"#66a61e\",\n      \"#e6ab02\",\n      \"#a6761d\",\n      \"#666666\",\n    ],\n    9: [\n      \"#a6cee3\",\n      \"#1f78b4\",\n      \"#b2df8a\",\n      \"#33a02c\",\n      \"#fb9a99\",\n      \"#e31a1c\",\n      \"#fdbf6f\",\n      \"#ff7f00\",\n      \"#cab2d6\",\n    ],\n    10: [\n      \"#a6cee3\",\n      \"#1f78b4\",\n      \"#b2df8a\",\n      \"#33a02c\",\n      \"#fb9a99\",\n      \"#e31a1c\",\n      \"#fdbf6f\",\n      \"#ff7f00\",\n      \"#cab2d6\",\n      \"#6a3d9a\",\n    ],\n    11: [\n      \"#a6cee3\",\n      \"#1f78b4\",\n      \"#b2df8a\",\n      \"#33a02c\",\n      \"#fb9a99\",\n      \"#e31a1c\",\n      \"#fdbf6f\",\n      \"#ff7f00\",\n      \"#cab2d6\",\n      \"#6a3d9a\",\n      \"#ffff99\",\n    ],\n    12: [\n      \"#a6cee3\",\n      \"#1f78b4\",\n      \"#b2df8a\",\n      \"#33a02c\",\n      \"#fb9a99\",\n      \"#e31a1c\",\n      \"#fdbf6f\",\n      \"#ff7f00\",\n      \"#cab2d6\",\n      \"#6a3d9a\",\n      \"#ffff99\",\n      \"#b15928\",\n    ],\n  };\n\n  let cluster_count = Math.max(...data) + 1;\n  let cluster_colors = null;\n  if (cluster_count > Object.keys(palette).length) {\n    cluster_colors = randomColor({\n      luminosity: \"dark\",\n      count: cluster_count + 1,\n    });\n  } else {\n    cluster_colors = palette[cluster_count.toString()];\n  }\n\n  return cluster_colors;\n};\n\nexport function isObject(object) {\n  return typeof object === \"object\" && Array.isArray(object) === false;\n}\n\nexport const code = \"K@ðœ‚a#$c3ll\";\n\n// this function is from https://developer.mozilla.org/en-US/docs/Glossary/Base64\nexport function utf8_to_b64(str) {\n  return window.btoa(unescape(encodeURIComponent(str)));\n}\n\nexport function generateUID(resource) {\n  let base = `${resource.format}`;\n  switch (resource.format) {\n    case \"SummarizedExperiment\":\n      base += `::${resource.rds.name}::${resource.rds.lastModified}::${resource.rds.size}`;\n      return utf8_to_b64(base);\n    case \"MatrixMarket\":\n      for (let key of [\"genes\", \"mtx\", \"annotations\"]) {\n        if (resource[key]) {\n          base += `::${resource[key].name}::${resource[key].lastModified}::${resource[key].size}`;\n        }\n      }\n      return utf8_to_b64(base);\n    case \"10X\":\n    case \"H5AD\":\n      base += `::${resource.h5.name}::${resource.h5.lastModified}::${resource.h5.size}`;\n      return utf8_to_b64(base);\n    case \"ExperimentHub\":\n      base += `::${resource.id}`;\n      return utf8_to_b64(base);\n    case \"ZippedArtifactdb\":\n      base += `::${resource.zipname}::${resource.zipfile}`;\n      return utf8_to_b64(base);\n    case \"ZippedADB\":\n      base += `::${resource.zipname}::${resource.zipfile}`;\n      return utf8_to_b64(base);\n    default:\n      throw Error(`format: ${resource.format} does not exist`);\n      break;\n  }\n}\n\nexport const MODALITIES = [\"RNA\", \"ADT\", \"CRISPR\"];\n\nexport const getMinMax = (arr) => {\n  var max = -Number.MAX_VALUE,\n    min = Number.MAX_VALUE;\n  arr.forEach(function (x) {\n    if (max < x) {\n      max = x;\n    }\n    if (min > x) {\n      min = x;\n    }\n  });\n  return [min, max];\n};\n\nexport const defaultColor = \"#5F6B7C\";\n\nexport const default_cluster = `${code}::CLUSTERS`;\nexport const default_selection = `${code}::SELECTION`;\n\nexport const getComputedCols = (cols) => {\n  return Object.keys(cols)\n    .filter(\n      (x) =>\n        cols[x].name === default_cluster ||\n        ((cols[x].name.startsWith(code) || cols[x].name === \"__batch__\") &&\n          cols[x].type !== \"continuous\" &&\n          (cols[x][\"type\"] === \"both\" ||\n            (cols[x][\"type\"] === \"categorical\" &&\n              cols[x][\"truncated\"] === false)))\n    )\n    .filter((x) => !cols[x].name.replace(`${code}::`, \"\").startsWith(\"QC\"));\n};\n\nexport const showComputedSection = (cols, custom) => {\n  return getComputedCols(cols).length > 0 || Object.keys(custom).length > 0;\n};\n\nexport const getSuppliedCols = (cols) => {\n  return Object.keys(cols).filter(\n    (x) =>\n      !cols[x].name.startsWith(code) &&\n      cols[x].name !== \"__batch__\" &&\n      cols[x].type !== \"continuous\" &&\n      (cols[x][\"type\"] === \"both\" ||\n        (cols[x][\"type\"] === \"categorical\" && cols[x][\"truncated\"] === false))\n  );\n};\n\nexport const resetApp = () => {\n  window.location.reload();\n};\n","import * as bakana from \"bakana\";\nimport * as scran from \"scran.js\";\nimport * as downloads from \"./DownloadsDBHandler.js\";\nimport {\n  extractBuffers,\n  postAttempt,\n  postSuccess,\n  postError,\n  describeColumn,\n  isArrayOrView,\n  formatMarkerResults,\n} from \"./helpers.js\";\nimport { code } from \"../utils/utils.js\";\n/***************************************/\n\nconst default_cluster = `${code}::CLUSTERS`;\nconst default_selection = `${code}::SELECTION`;\n\nlet superstate = null;\nlet preflights = {};\nlet preflights_summary = {};\nlet dataset = null;\nlet cache_anno_markers = {};\nlet custom_selection_state = null;\nlet feature_set_enrich_state = null;\nlet cell_labelling_state = null;\n\nfunction createDataset(args, setOpts = false) {\n  let result;\n  if (args.format === \"H5AD\") {\n    result = new bakana.H5adResult(args.h5);\n  } else if (args.format === \"SummarizedExperiment\") {\n    result = new bakana.SummarizedExperimentResult(args.rds);\n  } else if (args.format === \"ZippedArtifactdb\") {\n    let zipfile = new bakana.SimpleFile(args.zipfile);\n    if (args.ziplegacy) {\n      result = new bakana.ZippedArtifactdbResult(args.zipname, zipfile);\n    } else {\n      result = new bakana.ZippedAlabasterResult(args.zipname, zipfile);\n    }\n  } else {\n    throw new Error(\"unknown format '\" + args.format + \"'\");\n  }\n  if (setOpts) {\n    result.setOptions(args.options);\n  }\n  return result;\n}\n\nfunction summarizeResult(summary, args) {\n  // TODO: figure out a way to deal with nested objects later\n  let cells_summary = {};\n  for (const k of summary.cells.columnNames()) {\n    const kcol = summary.cells.column(k);\n    if (isArrayOrView(kcol))\n      cells_summary[k] = describeColumn(kcol, { all: true, colname: k });\n  }\n  let tmp_meta = {\n    cells: {\n      columns: cells_summary,\n      numberOfCells: summary.cells.numberOfRows(),\n    },\n  };\n\n  if (\n    args.format === \"SummarizedExperiment\" ||\n    args.format === \"ZippedArtifactdb\"\n  ) {\n    tmp_meta[\"modality_features\"] = {};\n    if (\"modality_features\" in summary) {\n      for (const [k, v] of Object.entries(summary.modality_features)) {\n        let tmod_summary = {};\n        for (const k of v.columnNames()) {\n          const kcol = v.column(k);\n          if (isArrayOrView(kcol)) {\n            tmod_summary[k] = describeColumn(kcol, { all: true, colname: k });\n          }\n        }\n        tmp_meta[\"modality_features\"][k] = {\n          columns: tmod_summary,\n          numberOfFeatures: v.numberOfRows(),\n          rownames: Array.isArray(v.rowNames()),\n        };\n      }\n    }\n  } else {\n    tmp_meta[\"all_features\"] = {};\n    let tmod_summary = {};\n    for (const k of summary[\"all_features\"].columnNames()) {\n      const kcol = summary[\"all_features\"].column(k);\n      if (isArrayOrView(kcol)) {\n        tmod_summary[k] = describeColumn(kcol, { all: true, colname: k });\n      }\n    }\n    tmp_meta[\"all_features\"] = {\n      columns: tmod_summary,\n      numberOfFeatures: summary[\"all_features\"].numberOfRows(),\n      rownames: Array.isArray(summary[\"all_features\"].rowNames()),\n    };\n  }\n\n  if (args.format === \"H5AD\") {\n    tmp_meta[\"all_assay_names\"] = summary.all_assay_names;\n  } else if (\n    args.format === \"SummarizedExperiment\" ||\n    args.format === \"ZippedArtifactdb\"\n  ) {\n    tmp_meta[\"modality_assay_names\"] = summary.modality_assay_names;\n  }\n\n  tmp_meta.reduced_dimension_names = summary.reduced_dimension_names;\n  return tmp_meta;\n}\n\nfunction getMarkerStandAloneForAnnot(annotation, annotation_vec) {\n  let mds;\n  if (!(annotation in cache_anno_markers)) {\n    mds = new bakana.MarkerDetectionStandalone(\n      getMatrix(),\n      annotation_vec.ids.slice()\n    );\n\n    mds.computeAll();\n    cache_anno_markers[annotation] = mds;\n  }\n\n  return cache_anno_markers[annotation];\n}\n\nconst getAnnotation = (annotation) => {\n  if (annotation.indexOf(\":::\") !== -1) {\n    let splits = annotation.split(\":::\");\n    return dataset.cells.column(splits[0]).column(splits[1]);\n  }\n  return dataset.cells.column(annotation);\n};\n\nconst getMatrix = () => {\n  return dataset.matrix;\n};\n\n/***************************************/\n\nvar loaded;\nonmessage = function (msg) {\n  const { type, payload } = msg.data;\n\n  // console.log(\"EXPLORE WORKER::RCV::\", type, payload);\n\n  let fatal = false;\n  if (type === \"INIT\") {\n    fatal = true;\n    let nthreads = Math.round((navigator.hardwareConcurrency * 2) / 3);\n    let back_init = bakana.initialize({ numberOfThreads: nthreads });\n\n    let state_init = back_init.then(() => {\n      return bakana.createAnalysis();\n    });\n\n    state_init.then((x) => {\n      superstate = x;\n      postMessage({\n        type: type,\n        msg: \"Success: analysis state created\",\n      });\n    });\n\n    let down_init = downloads.initialize();\n    down_init\n      .then((output) => {\n        postMessage({\n          type: \"DownloadsDB_store\",\n          resp: output,\n          msg: \"Success: DownloadsDB initialized\",\n        });\n      })\n      .catch((error) => {\n        console.error(error);\n        postMessage({\n          type: \"DownloadsDB_ERROR\",\n          msg: \"Error: Cannot initialize DownloadsDB\",\n        });\n      });\n\n    loaded = Promise.all([back_init, state_init, down_init]);\n\n    loaded\n      .then(() => {\n        postMessage({\n          type: type,\n          msg: \"Success: bakana initialized\",\n        });\n      })\n      .catch((err) => {\n        console.error(err);\n        postError(type, err, fatal);\n      });\n    /**************** EXPLORE AN ANALYSIS *******************/\n  } else if (type === \"EXPLORE\") {\n    fatal = true;\n    loaded\n      .then(async (x) => {\n        let inputs = payload.inputs;\n        let files = inputs.files;\n\n        if (files !== null) {\n          // Extracting existing datasets from the preflights.\n          let current = {};\n          for (const [k, v] of Object.entries(files)) {\n            if (\"uid\" in v && v.uid in preflights) {\n              preflights[v.uid].clear();\n              delete preflights[k];\n            }\n            current[k] = createDataset(v, true);\n            current[k].setOptions(v.options);\n          }\n\n          for (const [k, v] of Object.entries(current)) {\n            dataset = await v.load();\n\n            let finput = files[k];\n\n            let step_inputs = \"inputs\";\n            postAttempt(step_inputs);\n\n            // extract cell annotations\n            let annotation_keys = {};\n            for (const k of dataset.cells.columnNames()) {\n              let kcol = dataset.cells.column(k);\n              if (isArrayOrView(kcol)) {\n                const ksumm = describeColumn(kcol, {\n                  all: false,\n                  unique: true,\n                  colname: k,\n                });\n                annotation_keys[k] = ksumm;\n              }\n            }\n\n            let step_inputs_resp = {\n              annotations: annotation_keys,\n              genes: {},\n              num_cells: dataset.cells.numberOfRows(),\n              num_genes: {},\n            };\n\n            for (const [k, v] of Object.entries(dataset.features)) {\n              step_inputs_resp[\"genes\"][k] = {};\n              step_inputs_resp[\"num_genes\"][k] = v.numberOfRows();\n              for (const col of v.columnNames()) {\n                let kcol = v.column(col);\n                if (isArrayOrView(kcol)) {\n                  step_inputs_resp[\"genes\"][k][col] = kcol;\n                }\n              }\n\n              if (v.rowNames()) {\n                step_inputs_resp[\"genes\"][k][\"rowNames\"] = v.rowNames();\n              }\n            }\n            postSuccess(step_inputs, step_inputs_resp);\n\n            let step_embed = \"embedding\";\n            postAttempt(step_embed);\n            let step_embed_resp = {};\n\n            for (const [k, v] of Object.entries(dataset.reduced_dimensions)) {\n              if (k.toLowerCase() !== \"pca\") {\n                step_embed_resp[k] = {\n                  x: v[0].slice(),\n                  y: v[1].slice(),\n                };\n              }\n            }\n\n            postSuccess(step_embed, step_embed_resp);\n\n            if (custom_selection_state) {\n              custom_selection_state.free();\n            }\n\n            custom_selection_state = new bakana.CustomSelectionsStandalone(\n              dataset.matrix\n            );\n          }\n        }\n      })\n      .catch((err) => {\n        console.error(err);\n        postError(type, err, fatal);\n      });\n    /**************** LOADING EXISTING ANALYSES *******************/\n  } else if (type === \"PREFLIGHT_INPUT\") {\n    loaded\n      .then(async (x) => {\n        let resp = {};\n        try {\n          // Registering the UIDs of each new dataset.\n          let current = {};\n          let summary = {};\n          for (const [k, v] of Object.entries(payload.inputs.files)) {\n            if (\"uid\" in v) {\n              if (!(v.uid in preflights)) {\n                preflights[v.uid] = createDataset(v);\n                preflights_summary[v.uid] = await preflights[v.uid].summary();\n              }\n              current[k] = preflights[v.uid];\n              summary[k] = summarizeResult(preflights_summary[v.uid], v);\n            } else {\n              let tmp_dataset = createDataset(v);\n              current[k] = tmp_dataset;\n              summary[k] = summarizeResult(current[k], v);\n            }\n          }\n\n          resp.status = \"SUCCESS\";\n          resp.details = summary;\n        } catch (e) {\n          console.error(e);\n          resp.status = \"ERROR\";\n          resp.reason = e.toString();\n        }\n\n        postMessage({\n          type: \"PREFLIGHT_INPUT_DATA\",\n          resp: resp,\n          msg: \"Success: PREFLIGHT_INPUT done\",\n        });\n      })\n      .catch((err) => {\n        console.error(err);\n        postError(type, err, fatal);\n      });\n\n    /**************** VERSUS MODE *******************/\n  } else if (type === \"computeVersusClusters\") {\n    loaded\n      .then((x) => {\n        let rank_type = payload.rank_type;\n        let modality = payload.modality;\n        let annotation = payload.annotation;\n\n        let annotation_vec = scran.convertToFactor(getAnnotation(annotation));\n\n        let mds = getMarkerStandAloneForAnnot(annotation, annotation_vec);\n        let raw_res = mds.computeVersus(\n          annotation_vec.levels.indexOf(payload.left),\n          annotation_vec.levels.indexOf(payload.right)\n        );\n        let resp = formatMarkerResults(\n          raw_res.results[modality],\n          raw_res.left,\n          rank_type\n        );\n\n        var transferrable = [];\n        extractBuffers(resp, transferrable);\n        postMessage(\n          {\n            type: \"computeVersusClusters\",\n            resp: resp,\n            msg: \"Success: COMPUTE_VERSUS_CLUSTERS done\",\n          },\n          transferrable\n        );\n      })\n      .catch((err) => {\n        console.error(err);\n        postError(type, err, fatal);\n      });\n  } else if (type === \"computeVersusSelections\") {\n    loaded\n      .then((x) => {\n        let rank_type = payload.rank_type;\n        let res = custom_selection_state.computeVersus(\n          payload.left,\n          payload.right\n        );\n        let resp = formatMarkerResults(\n          res[\"results\"][payload.modality],\n          payload.left,\n          rank_type\n        );\n\n        var transferrable = [];\n        extractBuffers(resp, transferrable);\n        postMessage(\n          {\n            type: \"computeVersusSelections\",\n            resp: resp,\n            msg: \"Success: COMPUTE_VERSUS_SELECTIONS done\",\n          },\n          transferrable\n        );\n      })\n      .catch((err) => {\n        console.error(err);\n        postError(type, err, fatal);\n      });\n\n    //   /**************** OTHER EVENTS FROM UI *******************/\n  } else if (type === \"getMarkersForCluster\") {\n    loaded\n      .then((x) => {\n        let cluster = payload.cluster;\n        let rank_type = payload.rank_type;\n        let modality = payload.modality;\n        let annotation = payload.annotation;\n\n        let annotation_vec = scran.convertToFactor(getAnnotation(annotation));\n        let mds = getMarkerStandAloneForAnnot(annotation, annotation_vec);\n\n        let raw_res = mds.fetchResults()[modality];\n\n        let resp = formatMarkerResults(\n          raw_res,\n          annotation_vec.levels.indexOf(cluster),\n          rank_type\n        );\n\n        var transferrable = [];\n        extractBuffers(resp, transferrable);\n        postMessage(\n          {\n            type: \"setMarkersForCluster\",\n            resp: resp,\n            msg: \"Success: GET_MARKER_GENE done\",\n          },\n          transferrable\n        );\n      })\n      .catch((err) => {\n        console.error(err);\n        postError(type, err, fatal);\n      });\n  } else if (type === \"getGeneExpression\") {\n    loaded\n      .then((x) => {\n        let row_idx = payload.gene;\n        let modality = payload.modality;\n\n        var vec = dataset.matrix.get(modality).row(row_idx);\n\n        postMessage(\n          {\n            type: \"setGeneExpression\",\n            resp: {\n              gene: row_idx,\n              expr: vec,\n            },\n            msg: \"Success: GET_GENE_EXPRESSION done\",\n          },\n          [vec.buffer]\n        );\n      })\n      .catch((err) => {\n        console.error(err);\n        postError(type, err, fatal);\n      });\n  } else if (type === \"computeCustomMarkers\") {\n    loaded\n      .then((x) => {\n        custom_selection_state.addSelection(payload.id, payload.selection);\n        postMessage({\n          type: \"computeCustomMarkers\",\n          msg: \"Success: COMPUTE_CUSTOM_MARKERS done\",\n        });\n      })\n      .catch((err) => {\n        console.error(err);\n        postError(type, err, fatal);\n      });\n  } else if (type === \"getMarkersForSelection\") {\n    loaded\n      .then((x) => {\n        let rank_type = payload.rank_type;\n\n        let raw_res = custom_selection_state.fetchResults(payload.cluster)[\n          payload.modality\n        ];\n        let resp = formatMarkerResults(raw_res, 1, rank_type);\n\n        var transferrable = [];\n        extractBuffers(resp, transferrable);\n        postMessage(\n          {\n            type: \"setMarkersForCustomSelection\",\n            resp: resp,\n            msg: \"Success: GET_MARKER_GENE done\",\n          },\n          transferrable\n        );\n      })\n      .catch((err) => {\n        console.error(err);\n        postError(type, err, fatal);\n      });\n  } else if (type === \"removeCustomMarkers\") {\n    loaded\n      .then((x) => {\n        custom_selection_state.removeSelection(payload.id);\n      })\n      .catch((err) => {\n        console.error(err);\n        postError(type, err, fatal);\n      });\n  } else if (type === \"getAnnotation\") {\n    loaded\n      .then((x) => {\n        let annot = payload.annotation;\n        let vec, output;\n\n        vec = getAnnotation(annot);\n        // dataset.cells.column(annot);\n\n        if (ArrayBuffer.isView(vec)) {\n          output = {\n            type: \"array\",\n            values: vec.slice(),\n          };\n        } else {\n          let uniq_vals = [];\n          let uniq_map = {};\n          let indices = new Int32Array(vec.length);\n          vec.map((x, i) => {\n            if (!(x in uniq_map)) {\n              uniq_map[x] = uniq_vals.length;\n              uniq_vals.push(x);\n            }\n            indices[i] = uniq_map[x];\n          });\n\n          output = {\n            type: \"factor\",\n            index: indices,\n            levels: uniq_vals,\n          };\n        }\n\n        let extracted = [];\n        extractBuffers(output, extracted);\n        postMessage(\n          {\n            type: \"setAnnotation\",\n            resp: {\n              annotation: annot,\n              values: output,\n            },\n            msg: \"Success: GET_ANNOTATION done\",\n          },\n          extracted\n        );\n      })\n      .catch((err) => {\n        console.error(err);\n        postError(type, err, fatal);\n      });\n  } else if (type === \"computeFeaturesetSummary\") {\n    loaded\n      .then(async (x) => {\n        let { annotation, rank_type, cluster, modality } = payload;\n        let index = rank_type.indexOf(\"-\");\n        let resp;\n\n        if (default_selection === annotation) {\n          let anno_markers =\n            custom_selection_state.fetchResults(cluster)[modality];\n\n          feature_set_enrich_state.ready().then((x) => {\n            resp = feature_set_enrich_state.computeEnrichment(\n              anno_markers,\n              1,\n              rank_type.slice(0, index),\n              rank_type.slice(index + 1)\n            );\n            postSuccess(\"computeFeaturesetSummary\", resp);\n          });\n        } else {\n          let annotation_vec = scran.convertToFactor(getAnnotation(annotation));\n          let mds = getMarkerStandAloneForAnnot(annotation, annotation_vec);\n          let anno_markers = mds.fetchResults()[modality];\n\n          feature_set_enrich_state.ready().then((x) => {\n            resp = feature_set_enrich_state.computeEnrichment(\n              anno_markers,\n              annotation_vec.levels.indexOf(cluster),\n              rank_type.slice(0, index),\n              rank_type.slice(index + 1)\n            );\n            postSuccess(\"computeFeaturesetSummary\", resp);\n          });\n        }\n      })\n      .catch((err) => {\n        console.error(err);\n        postError(type, err, fatal);\n      });\n  } else if (type === \"computeFeaturesetVSSummary\") {\n    loaded\n      .then(async (x) => {\n        let { annotation, rank_type, left, right, modality } = payload;\n        let index = rank_type.indexOf(\"-\");\n        let resp;\n        if (default_selection === annotation) {\n          let anno_markers = custom_selection_state.computeVersus(left, right);\n\n          feature_set_enrich_state.ready().then((x) => {\n            resp = feature_set_enrich_state.computeEnrichment(\n              anno_markers.results[modality],\n              0,\n              rank_type.slice(0, index),\n              rank_type.slice(index + 1)\n            );\n            postSuccess(\"computeFeaturesetVSSummary\", resp);\n          });\n        } else {\n          let annotation_vec = scran.convertToFactor(getAnnotation(annotation));\n          let mds = getMarkerStandAloneForAnnot(annotation, annotation_vec);\n\n          let raw_res = mds.computeVersus(\n            annotation_vec.levels.indexOf(payload.left),\n            annotation_vec.levels.indexOf(payload.right)\n          );\n\n          feature_set_enrich_state.ready().then((x) => {\n            resp = feature_set_enrich_state.computeEnrichment(\n              raw_res.results[modality],\n              raw_res.left,\n              rank_type.slice(0, index),\n              rank_type.slice(index + 1)\n            );\n            postSuccess(\"computeFeaturesetVSSummary\", resp);\n          });\n        }\n      })\n      .catch((err) => {\n        console.error(err);\n        postError(type, err, fatal);\n      });\n  } else if (type === \"getFeatureScores\") {\n    loaded\n      .then((x) => {\n        let { index } = payload;\n\n        let resp = feature_set_enrich_state.computePerCellScores(index);\n        postSuccess(\"setFeatureScores\", resp);\n      })\n      .catch((err) => {\n        console.error(err);\n        postError(type, err, fatal);\n      });\n  } else if (type === \"getFeatureGeneIndices\") {\n    loaded\n      .then((x) => {\n        let { index, cluster, annotation, modality, rank_type } = payload;\n\n        let resp = feature_set_enrich_state.fetchFeatureSetIndices(index);\n\n        let raw_res, marker_resp;\n\n        if (default_selection === annotation) {\n          raw_res = custom_selection_state.fetchResults(payload.cluster)[\n            payload.modality\n          ];\n          marker_resp = formatMarkerResults(\n            raw_res,\n            1,\n            payload.rank_type\n          );\n        } else {\n          let annotation_vec = scran.convertToFactor(getAnnotation(annotation));\n          let mds = getMarkerStandAloneForAnnot(annotation, annotation_vec);\n\n          raw_res = mds.fetchResults()[modality];\n          // cache_anno_markers[annotation][modality];\n\n          marker_resp = formatMarkerResults(\n            raw_res,\n            annotation_vec.levels.indexOf(cluster),\n            rank_type\n          );\n        }\n\n        let indices = marker_resp.ordering\n          .map((x, i) => (resp.includes(x) ? i : -100))\n          .filter((x) => x !== -100);\n\n        let filtered_marker_resp = {};\n        for (const [k, v] of Object.entries(marker_resp)) {\n          filtered_marker_resp[k] = v\n            .map((x, i) => (indices.includes(i) ? x : -100))\n            .filter((x) => x !== -100);\n        }\n\n        postSuccess(\"setFeatureGeneIndices\", filtered_marker_resp);\n      })\n      .catch((err) => {\n        console.error(err);\n        postError(type, err, fatal);\n      });\n  } else if (type === \"initFeaturesetEnrich\") {\n    loaded.then(async (x) => {\n      let { modality } = payload;\n\n      if (feature_set_enrich_state) {\n        feature_set_enrich_state.free();\n      }\n\n      feature_set_enrich_state = new bakana.FeatureSetEnrichmentStandalone(\n        dataset.features[modality],\n        { normalized: dataset.matrix.get(modality) }\n      );\n\n      feature_set_enrich_state.ready().then((x) => {\n        let collections = feature_set_enrich_state.fetchCollectionDetails();\n        let sets = feature_set_enrich_state.fetchSetDetails();\n        let resp = {\n          collections: collections,\n          sets: {\n            names: sets.names,\n            descriptions: sets.descriptions,\n            sizes: sets.sizes.slice(),\n            collections: sets.collections.slice(),\n          },\n        };\n        postSuccess(\"feature_set_enrichment\", resp);\n      });\n    });\n  } else if (type === \"computeCellAnnotation\") {\n    let { annotation, cluster, modality } = payload;\n    let result = { per_reference: {} };\n    let markers = null;\n    if (default_selection === annotation) {\n      markers = custom_selection_state.fetchResults(cluster);\n    } else {\n      let annotation_vec = scran.convertToFactor(getAnnotation(annotation));\n      let mds = getMarkerStandAloneForAnnot(annotation, annotation_vec);\n      markers = mds.fetchResults();\n    }\n    if (markers !== null && modality in markers) {\n      if (cell_labelling_state === null) {\n        cell_labelling_state = new bakana.CellLabellingStandalone(\n          dataset.features[modality]\n        );\n      }\n      cell_labelling_state\n        .ready()\n        .then(() => {\n          result = cell_labelling_state.computeLabels(markers[modality]);\n          postSuccess(\"computeCellAnnotation\", result);\n        })\n        .catch((err) => {\n          console.error(err);\n          postError(type, err, fatal);\n        });\n    }\n  } else {\n    console.error(\"MIM:::msg type incorrect\");\n    postError(type, \"Type not defined\", fatal);\n  }\n};\n","// The module cache\nvar __webpack_module_cache__ = {};\n\n// The require function\nfunction __webpack_require__(moduleId) {\n\t// Check if module is in cache\n\tvar cachedModule = __webpack_module_cache__[moduleId];\n\tif (cachedModule !== undefined) {\n\t\treturn cachedModule.exports;\n\t}\n\t// Create a new module (and put it into the cache)\n\tvar module = __webpack_module_cache__[moduleId] = {\n\t\tid: moduleId,\n\t\tloaded: false,\n\t\texports: {}\n\t};\n\n\t// Execute the module function\n\t__webpack_modules__[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n\t// Flag the module as loaded\n\tmodule.loaded = true;\n\n\t// Return the exports of the module\n\treturn module.exports;\n}\n\n// expose the modules object (__webpack_modules__)\n__webpack_require__.m = __webpack_modules__;\n\n// the startup function\n__webpack_require__.x = () => {\n\t// Load entry module and return exports\n\t// This entry module depends on other loaded chunks and execution need to be delayed\n\tvar __webpack_exports__ = __webpack_require__.O(undefined, [691,985,522], () => (__webpack_require__(2418)))\n\t__webpack_exports__ = __webpack_require__.O(__webpack_exports__);\n\treturn __webpack_exports__;\n};\n\n","var deferred = [];\n__webpack_require__.O = (result, chunkIds, fn, priority) => {\n\tif(chunkIds) {\n\t\tpriority = priority || 0;\n\t\tfor(var i = deferred.length; i > 0 && deferred[i - 1][2] > priority; i--) deferred[i] = deferred[i - 1];\n\t\tdeferred[i] = [chunkIds, fn, priority];\n\t\treturn;\n\t}\n\tvar notFulfilled = Infinity;\n\tfor (var i = 0; i < deferred.length; i++) {\n\t\tvar [chunkIds, fn, priority] = deferred[i];\n\t\tvar fulfilled = true;\n\t\tfor (var j = 0; j < chunkIds.length; j++) {\n\t\t\tif ((priority & 1 === 0 || notFulfilled >= priority) && Object.keys(__webpack_require__.O).every((key) => (__webpack_require__.O[key](chunkIds[j])))) {\n\t\t\t\tchunkIds.splice(j--, 1);\n\t\t\t} else {\n\t\t\t\tfulfilled = false;\n\t\t\t\tif(priority < notFulfilled) notFulfilled = priority;\n\t\t\t}\n\t\t}\n\t\tif(fulfilled) {\n\t\t\tdeferred.splice(i--, 1)\n\t\t\tvar r = fn();\n\t\t\tif (r !== undefined) result = r;\n\t\t}\n\t}\n\treturn result;\n};","// define getter functions for harmony exports\n__webpack_require__.d = (exports, definition) => {\n\tfor(var key in definition) {\n\t\tif(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {\n\t\t\tObject.defineProperty(exports, key, { enumerable: true, get: definition[key] });\n\t\t}\n\t}\n};","__webpack_require__.f = {};\n// This file contains only the entry chunk.\n// The chunk loading function for additional chunks\n__webpack_require__.e = (chunkId) => {\n\treturn Promise.all(Object.keys(__webpack_require__.f).reduce((promises, key) => {\n\t\t__webpack_require__.f[key](chunkId, promises);\n\t\treturn promises;\n\t}, []));\n};","// This function allow to reference async chunks and chunks that the entrypoint depends on\n__webpack_require__.u = (chunkId) => {\n\t// return url for filenames based on template\n\treturn \"static/js/\" + chunkId + \".\" + {\"120\":\"568b3440\",\"343\":\"07177662\",\"522\":\"44959ef0\",\"691\":\"9a33b0ff\",\"814\":\"bc231a0d\",\"985\":\"b0e597fb\"}[chunkId] + \".chunk.js\";\n};","// This function allow to reference async chunks and chunks that the entrypoint depends on\n__webpack_require__.miniCssF = (chunkId) => {\n\t// return url for filenames based on template\n\treturn undefined;\n};","__webpack_require__.g = (function() {\n\tif (typeof globalThis === 'object') return globalThis;\n\ttry {\n\t\treturn this || new Function('return this')();\n\t} catch (e) {\n\t\tif (typeof window === 'object') return window;\n\t}\n})();","__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))","__webpack_require__.nmd = (module) => {\n\tmodule.paths = [];\n\tif (!module.children) module.children = [];\n\treturn module;\n};","__webpack_require__.p = \"/kana/\";","__webpack_require__.b = self.location + \"/../../../\";\n\n// object to store loaded chunks\n// \"1\" means \"already loaded\"\nvar installedChunks = {\n\t418: 1\n};\n\n// importScripts chunk loading\nvar installChunk = (data) => {\n\tvar [chunkIds, moreModules, runtime] = data;\n\tfor(var moduleId in moreModules) {\n\t\tif(__webpack_require__.o(moreModules, moduleId)) {\n\t\t\t__webpack_require__.m[moduleId] = moreModules[moduleId];\n\t\t}\n\t}\n\tif(runtime) runtime(__webpack_require__);\n\twhile(chunkIds.length)\n\t\tinstalledChunks[chunkIds.pop()] = 1;\n\tparentChunkLoadingFunction(data);\n};\n__webpack_require__.f.i = (chunkId, promises) => {\n\t// \"1\" is the signal for \"already loaded\"\n\tif(!installedChunks[chunkId]) {\n\t\tif(true) { // all chunks have JS\n\t\t\timportScripts(__webpack_require__.p + __webpack_require__.u(chunkId));\n\t\t}\n\t}\n};\n\nvar chunkLoadingGlobal = self[\"webpackChunkkana\"] = self[\"webpackChunkkana\"] || [];\nvar parentChunkLoadingFunction = chunkLoadingGlobal.push.bind(chunkLoadingGlobal);\nchunkLoadingGlobal.push = installChunk;\n\n// no HMR\n\n// no HMR manifest","var next = __webpack_require__.x;\n__webpack_require__.x = () => {\n\treturn Promise.all([691,985,522].map(__webpack_require__.e, __webpack_require__)).then(next);\n};","// run startup\nvar __webpack_exports__ = __webpack_require__.x();\n"],"names":["DownloadsDB","init","async","fetchWrapper","url","params","arguments","length","undefined","out","startFun","iterFun","endFun","res","fetch","ok","Error","id","headers","get","reader","body","getReader","chunks","total","done","value","read","push","output","Uint8Array","start","x","set","fetchWithProgress","cl","postMessage","type","String","download","total_bytes","msg","sofar","downloaded_bytes","error","req","status","buffer","arrayBuffer","force","download_store","result","transaction","objectStore","data_check","Promise","resolve","reject","already","onsuccess","event","payload","onerror","concat","target","errorCode","found","trans","fin","oncomplete","saving","putrequest","put","proxy","proxyAndCache","downloads","encodeURIComponent","extractBuffers","object","store","Array","isArray","element","constructor","Object","key","entries","ArrayBuffer","isView","postAttempt","step","postSuccess","info","transferable","resp","postError","err","fatal","reason","toString","isArrayOrView","col","describeColumn","all","unique","colname","bakana","uqVals","Set","size","sort","formatMarkerResults","results","group","rankEffect","ordering","summary","ranking","increasing","match","cohensD","copy","auc","deltaMean","deltaDetected","Int32Array","i","f","s","reorder","stats","thing","Float64Array","stat_mean","mean","stat_detected","detected","stat_lfc","stat_delta_d","setDownload","gesel","file","end","full","Response","remotes","setDownloadFun","code","default_selection","superstate","preflights","preflights_summary","dataset","cache_anno_markers","custom_selection_state","feature_set_enrich_state","cell_labelling_state","createDataset","args","setOpts","format","h5","rds","zipfile","ziplegacy","zipname","setOptions","options","summarizeResult","cells_summary","k","cells","columnNames","kcol","column","tmp_meta","columns","numberOfCells","numberOfRows","v","modality_features","tmod_summary","numberOfFeatures","rownames","rowNames","all_assay_names","modality_assay_names","reduced_dimension_names","getMarkerStandAloneForAnnot","annotation","annotation_vec","mds","getMatrix","ids","slice","computeAll","getAnnotation","indexOf","splits","split","matrix","loaded","onmessage","data","nthreads","Math","round","navigator","hardwareConcurrency","back_init","numberOfThreads","state_init","then","down_init","indexedDB","open","onupgradeneeded","e","DownloadsDBClient","deleteObjectStore","createObjectStore","keyPath","catch","console","files","inputs","current","uid","clear","load","step_inputs","annotation_keys","ksumm","step_inputs_resp","annotations","genes","num_cells","num_genes","features","step_embed","step_embed_resp","reduced_dimensions","toLowerCase","y","free","tmp_dataset","details","rank_type","modality","scran","raw_res","computeVersus","levels","left","right","transferrable","cluster","fetchResults","row_idx","gene","vec","row","expr","addSelection","selection","removeSelection","annot","values","uniq_vals","uniq_map","indices","map","index","extracted","anno_markers","ready","computeEnrichment","computePerCellScores","marker_resp","fetchFeatureSetIndices","includes","filter","filtered_marker_resp","normalized","collections","fetchCollectionDetails","sets","fetchSetDetails","names","descriptions","sizes","per_reference","markers","computeLabels","__webpack_module_cache__","__webpack_require__","moduleId","cachedModule","exports","module","__webpack_modules__","call","m","__webpack_exports__","O","deferred","chunkIds","fn","priority","notFulfilled","Infinity","fulfilled","j","keys","every","splice","r","d","definition","o","defineProperty","enumerable","chunkId","reduce","promises","u","miniCssF","g","globalThis","this","Function","window","obj","prop","prototype","hasOwnProperty","nmd","paths","children","p","b","self","location","installedChunks","importScripts","chunkLoadingGlobal","parentChunkLoadingFunction","bind","moreModules","runtime","pop","next"],"sourceRoot":""}