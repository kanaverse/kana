{"version":3,"file":"static/js/418.ad0cf717.chunk.js","mappings":"6CAAIA,E,oBACAC,EAAO,KAyEXC,eAAeC,EAAaC,GAAqB,IAAhBC,EAAMC,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAG,KACxC,IACE,MAAMG,QA1CVP,eAAiCE,EAAKM,EAAUC,EAASC,GAAsB,IACzEC,EAD2DR,EAAMC,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAC,KAQtE,GALEO,EADY,MAAVR,QACUS,MAAMV,SAENU,MAAMV,EAAKC,IAGpBQ,EAAIE,GACP,MAAM,IAAIC,MAAM,6BAA+BZ,EAAM,KAGvD,MACMa,EAAKP,EADAG,EAAIK,QAAQC,IAAI,mBAGrBC,EAASP,EAAIQ,KAAKC,YAClBC,EAAS,GACf,IAAIC,EAAQ,EAEZ,OAAa,CACX,MAAM,KAAEC,EAAI,MAAEC,SAAgBN,EAAOO,OACrC,GAAIF,EACF,MAEFF,EAAOK,KAAKF,GACZF,GAASE,EAAMnB,OACfI,EAAQM,EAAIO,EACd,CAEA,IAAIK,EAAS,IAAIC,WAAWN,GACxBO,EAAQ,EACZ,IAAK,MAAMC,KAAKT,EACdM,EAAOI,IAAID,EAAGD,GACdA,GAASC,EAAEzB,OAIb,OADAK,EAAOK,EAAIO,GACJK,CACT,CAIsBK,CAChB9B,EACC+B,IACCC,YAAY,CACVC,KAAM,qBAAuBC,OAAOlC,GACpCmC,SAAU,QACVnC,IAAKkC,OAAOlC,GACZoC,YAAaF,OAAOH,GACpBM,IAAK,iBAAmBH,OAAOH,GAAM,YAEhC/B,GAET,CAACa,EAAIyB,KACHN,YAAY,CACVC,KAAM,qBAAuBC,OAAOlC,GACpCmC,SAAU,WACVnC,IAAKkC,OAAOlC,GACZuC,iBAAkBL,OAAOI,GACzBD,IAAK,wBAA0BH,OAAOI,GAAS,aAGnD,CAACzB,EAAIO,KACHY,YAAY,CACVC,KAAM,qBAAuBC,OAAOlC,GACpCmC,SAAU,WACVnC,IAAKkC,OAAOlC,GACZqC,IAAK,iBAAmBH,OAAOd,GAAS,aAG5CnB,GAGF,OAAOI,CACT,CAAE,MAAOmC,GASP,IAAIC,EAPJT,YAAY,CACVC,KAAM,qBAAuBC,OAAOlC,GACpCmC,SAAU,QACVnC,IAAKkC,OAAOlC,GACZoC,YAAa,MAKbK,EADY,MAAVxC,EACIS,MAAMV,GAENU,MAAMV,EAAKC,GAGnB,IAAIQ,QAAYgC,EAChB,IAAKhC,EAAIE,GACP,MAAM,IAAIC,MAAM,uBAAyBZ,EAAM,MAAQS,EAAIiC,OAAS,KAEtE,IAAIC,QAAelC,EAAImC,cAOvB,OALAZ,YAAY,CACVC,KAAM,qBAAuBC,OAAOlC,GACpCmC,SAAU,WACVnC,IAAKkC,OAAOlC,KAEP,IAAI0B,WAAWiB,EACxB,CACF,CAEO7C,eAAeiB,EAAIf,GAAoC,IAA/BC,EAAMC,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAG,KAAM2C,EAAK3C,UAAAC,OAAA,QAAAC,IAAAF,UAAA,IAAAA,UAAA,GAGjD,SAFML,GAEDgD,EAAO,CACV,IACIC,EADQlD,EAAYmD,OAAOC,YAAY,CAAC,aAAc,YAC/BC,YAAY,aAEvC,IAAIC,EAAa,IAAIC,QAAQ,CAACC,EAASC,KACrC,IAAIC,EAAUR,EAAe/B,IAAIf,GACjCsD,EAAQC,UAAYC,SACKpD,IAAnBkD,EAAQP,OACVK,EAAQE,EAAQP,OAAOU,SAEvBL,EAAQ,OAGZE,EAAQI,QAAUF,IAChBH,EAAO,mCAADM,OAAoC3D,EAAG,MAAA2D,OAAKH,EAAMI,OAAOC,eAI/DC,QAAcZ,EAClB,GAAc,OAAVY,EACF,OAAOA,CAEX,CAEA,IAAInB,QAAe5C,EAAaC,EAAKC,GASrC,IAAI8D,EAAQnE,EAAYmD,OAAOC,YAAY,CAAC,aAAc,aAKtDgB,EAAM,IAAIb,QAAQ,CAACC,EAASC,KAC9BU,EAAME,WAAcT,IAClBJ,EAAQ,OAEVW,EAAML,QAAWF,IACfH,EAAO,IAAIzC,MAAM,gCAAD+C,OAAiC3D,EAAG,qBAAA2D,OAAoBH,EAAMI,OAAOC,gBAIrFf,EAAiBiB,EAAMd,YAAY,aACnCiB,EAAS,IAAIf,QAAQ,CAACC,EAASC,KACjC,IAAIc,EAAarB,EAAesB,IAAI,CAAEpE,IAAKA,EAAKyD,QAASd,IACzDwB,EAAWZ,UAAYC,IACrBJ,GAAQ,IAEVe,EAAWT,QAAUF,IACnBH,EAAO,IAAIzC,MAAM,mBAAD+C,OAAoB3D,EAAG,qBAAA2D,OAAoBH,EAAMI,OAAOC,gBAO5E,aAFMK,QACAF,EACCrB,CACT,C,wBCvMA,MAAM0B,EAAQ,2CACdvE,eAAewE,EAActE,GAC3B,IAAI2C,QAAe4B,EAAcF,EAAQ,IAAMG,mBAAmBxE,IAClE,OAAO,IAAI0B,WAAWiB,EACxB,CA0BO,SAAS8B,EAAeC,EAAQC,GACrC,GAAKD,EAIL,GAAIE,MAAMC,QAAQH,GAChB,IAAK,MAAMI,KAAWJ,EACpBD,EAAeK,EAASH,QAErB,GAAID,EAAOK,aAAeC,OAC/B,IAAK,MAAOC,EAAKH,KAAYE,OAAOE,QAAQR,GAC1CD,EAAeK,EAASH,QAErB,GAAIQ,YAAYC,OAAOV,GAAS,CACrC,KAAMA,EAAO/B,kBAAkBwC,aAC7B,KAAM,qDAERR,EAAMnD,KAAKkD,EAAO/B,OACpB,CACF,CAEO,SAAS0C,EAAYC,GAC1BtD,YAAY,CACVC,KAAK,GAAD0B,OAAK2B,EAAI,WAEjB,CAEO,SAASC,EAAYD,EAAME,GAChC,GAAmB,oBAARA,EACTxD,YAAY,CACVC,KAAK,GAAD0B,OAAK2B,EAAI,gBAEV,CACL,IAAIG,EAAe,GACnBhB,EAAee,EAAMC,GACrBzD,YACE,CACEC,KAAK,GAAD0B,OAAK2B,EAAI,SACbI,KAAMF,GAERC,EAEJ,CACF,CAEO,SAASE,EAAU1D,EAAM2D,EAAKC,GACnC7D,YAAY,CACVC,KAAK,GAAD0B,OAAK1B,EAAI,UACbyD,KAAM,CACJI,OAAQF,EAAIG,WACZF,MAAOA,IAGb,CA0QO,SAASG,EAAcC,GAC5B,OAAOrB,MAAMC,QAAQoB,IAAQd,YAAYC,OAAOa,EAClD,CAEO,SAASC,EACdD,GAEC,IACGxF,GAFJ,IAAE0F,GAAM,EAAK,OAAEC,GAAS,EAAK,QAAEC,EAAU,MAAMnG,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAG,CAAC,EAGnD,GAAI8F,EAAcC,GAAM,CACtBxF,EAAM6F,EAAAA,GAAsBL,GAC5B,MAAMM,EAAS,IAAIC,IAAIP,GACvBxF,EAAgB,WAAI8F,EAAOE,KAEtBF,EAAOE,MAAQ,GAAML,IAAQ3F,EAAY,OAAI,IAAI8F,GAAQG,QAC1DP,IAAK1F,EAAW,MAAIwF,GAGJ,eAAhBxF,EAAU,MAAsB8F,EAAOE,MAAQ,KAAIhG,EAAU,KAAI,SAE9C,kBAAZ4F,GAAwBA,aAAmBnE,UACpDzB,EAAU,KAAI4F,EAClB,CAEA,OAAO5F,CACT,CAhXA6F,EAAAA,GAA0BK,YAAYrC,GACtCsC,EAAAA,GAAsBtC,GACtBgC,EAAAA,GAA8BK,YAAYrC,GAE1CsC,EAAAA,GAAwB9G,MAAO+G,EAAMlF,EAAOmF,KAC1C,IAAI9G,EAAM4G,EAAAA,KAA2B,IAAMC,EACvCE,EAAO1C,EAAQ,IAAMG,mBAAmBxE,GAC5C,GAAa,MAAT2B,GAAwB,MAAPmF,EAAa,CAChC,IAAInE,QAAe4B,EAAcwC,GACjC,OAAO,IAAIC,SAASrE,EACtB,CACE,OAAOjC,MAAMqG,EAAO,UAAY7E,OAAOP,GAAS,QAAUO,OAAO4E,MAIrEF,EAAAA,GAAmB9G,UACjB,IAAIE,EAAM4G,EAAAA,KAAsB,IAAMC,EAClClE,QAAe4B,EAAcF,EAAQ,IAAMG,mBAAmBxE,IAClE,OAAO,IAAIgH,SAASrE,KAGtBsE,EAAAA,EAA6BC,eAAe5C,GAC5CgC,EAAAA,GAAuC,cAAIW,EAAAA,E,QCiEpC,MAAME,EAAO,wBAyDQ,GAAAxD,OAAMwD,EAAI,cACR,GAAAxD,OAAMwD,EAAI,eC/InB,GAAAxD,OAAMwD,EAAI,cD4HxB,MC3HDC,EAAiB,GAAAzD,OAAMwD,EAAI,eAEjC,IAAIE,EAAa,KACbC,EAAa,CAAC,EACdC,EAAqB,CAAC,EACtBC,EAAU,KACVC,EAAqB,CAAC,EACtBC,EAAyB,KACzBC,EAA2B,KAC3BC,EAAuB,KAE3B,SAASC,EAAcC,GAAwB,IAAlBC,EAAO7H,UAAAC,OAAA,QAAAC,IAAAF,UAAA,IAAAA,UAAA,GAClC,GAAoB,SAAhB4H,EAAKE,OACP,OAAO,IAAI1B,EAAAA,GAAkBwB,EAAKG,GAAIF,EAAUD,EAAKI,QAAU,CAAC,GAC3D,GAAoB,yBAAhBJ,EAAKE,OACd,OAAO,IAAI1B,EAAAA,GACTwB,EAAKK,IACLJ,EAAUD,EAAKI,QAAU,CAAC,GAEvB,GAAoB,qBAAhBJ,EAAKE,OACd,OAAO,IAAI1B,EAAAA,GACTwB,EAAKM,QACL,IAAI9B,EAAAA,GAAkBwB,EAAKO,SAC3BN,EAAUD,EAAKI,QAAU,CAAC,GAG5B,MAAM,IAAItH,MAAM,mBAAqBkH,EAAKE,OAAS,IAEvD,CAEA,SAASM,EAAgBC,EAAST,GAEhC,IAAIU,EAAgB,CAAC,EACrB,IAAK,MAAMC,KAAKF,EAAQG,MAAMC,cAAe,CAC3C,MAAMC,EAAOL,EAAQG,MAAMG,OAAOJ,GAC9BzC,EAAc4C,KAChBJ,EAAcC,GAAKvC,EAAe0C,EAAM,CAAEzC,KAAK,EAAME,QAASoC,IAClE,CACA,IAAIK,EAAW,CACbJ,MAAO,CACLK,QAASP,EACTQ,cAAeT,EAAQG,MAAMO,iBAIjC,GACkB,yBAAhBnB,EAAKE,QACW,qBAAhBF,EAAKE,QAGL,GADAc,EAA4B,kBAAI,CAAC,EAC7B,sBAAuBP,EACzB,IAAK,MAAOE,EAAGS,KAAMlE,OAAOE,QAAQqD,EAAQY,mBAAoB,CAC9D,IAAIC,EAAe,CAAC,EACpB,IAAK,MAAMX,KAAKS,EAAEP,cAAe,CAC/B,MAAMC,EAAOM,EAAEL,OAAOJ,GAClBzC,EAAc4C,KAChBQ,EAAaX,GAAKvC,EAAe0C,EAAM,CAAEzC,KAAK,EAAME,QAASoC,IAEjE,CACAK,EAA4B,kBAAEL,GAAK,CACjCM,QAASK,EACTC,iBAAkBH,EAAED,eACpBK,SAAU1E,MAAMC,QAAQqE,EAAEK,YAE9B,MAEG,CACLT,EAAuB,aAAI,CAAC,EAC5B,IAAIM,EAAe,CAAC,EACpB,IAAK,MAAMX,KAAKF,EAAsB,aAAEI,cAAe,CACrD,MAAMC,EAAOL,EAAsB,aAAEM,OAAOJ,GACxCzC,EAAc4C,KAChBQ,EAAaX,GAAKvC,EAAe0C,EAAM,CAAEzC,KAAK,EAAME,QAASoC,IAEjE,CACAK,EAAuB,aAAI,CACzBC,QAASK,EACTC,iBAAkBd,EAAsB,aAAEU,eAC1CK,SAAU1E,MAAMC,QAAQ0D,EAAsB,aAAEgB,YAEpD,CAYA,MAVoB,SAAhBzB,EAAKE,OACPc,EAA0B,gBAAIP,EAAQiB,gBAEtB,yBAAhB1B,EAAKE,QACW,qBAAhBF,EAAKE,SAELc,EAA+B,qBAAIP,EAAQkB,sBAG7CX,EAASY,wBAA0BnB,EAAQmB,wBACpCZ,CACT,CAEA,SAASa,EAA4BC,EAAYC,GAC/C,IAAIC,EAWJ,OAVMF,KAAcnC,IAClBqC,EAAM,IAAIxD,EAAAA,GACRyD,IACAF,EAAeG,IAAIC,SAGrBH,EAAII,aACJzC,EAAmBmC,GAAcE,GAG5BrC,EAAmBmC,EAC5B,CAEA,MAAMO,EAAiBP,IACrB,IAAmC,IAA/BA,EAAWQ,QAAQ,OAAe,CACpC,IAAIC,EAAST,EAAWU,MAAM,OAC9B,OAAO9C,EAAQkB,MAAMG,OAAOwB,EAAO,IAAIxB,OAAOwB,EAAO,GACvD,CACA,OAAO7C,EAAQkB,MAAMG,OAAOe,IAGxBG,EAAYA,IACTvC,EAAQ+C,OAKjB,IAAIC,EACJC,UAAY,SAAUpI,GACpB,MAAM,KAAEJ,EAAI,QAAEwB,GAAYpB,EAAIqI,KAI9B,IAAI7E,GAAQ,EACZ,GAAa,SAAT5D,EAAiB,CACnB4D,GAAQ,EACR,IAAI8E,EAAWC,KAAKC,MAAuC,EAAhCC,UAAUC,oBAA2B,GAC5DC,EAAY1E,EAAAA,GAAkB,CAAE2E,gBAAiBN,IAEjDO,EAAaF,EAAUG,KAAK,IACvB7E,EAAAA,MAGT4E,EAAWC,KAAMvJ,IACfyF,EAAazF,EACbI,YAAY,CACVC,KAAMA,EACNI,IAAK,sCAIT,IAAI+I,GH/JO,OAATvL,IACFA,EAAO,IAAIsD,QAAQ,CAACC,EAASC,MAE3BzD,EAAcyL,UAAUC,KAAK,cAAe,IAEhCC,gBAAmBC,IAC7B,IAAIC,EAAoBD,EAAE5H,OAAOb,OAIjC,IACE0I,EAAkBC,kBAAkB,YACtC,CAAE,MAAOF,GAAI,CAEbC,EAAkBE,kBAAkB,YAAa,CAAEC,QAAS,SAG9DhM,EAAY2D,UAAY,KACtBH,EAAQ,OAGVxD,EAAY8D,QAAU,KACpBL,EAAO,wCAKNxD,GGqILuL,EACGD,KAAM1J,IACLO,YAAY,CACVC,KAAM,oBACNyD,KAAMjE,EACNY,IAAK,uCAGRwJ,MAAOrJ,IACNsJ,QAAQtJ,MAAMA,GACdR,YAAY,CACVC,KAAM,oBACNI,IAAK,4CAIXmI,EAASrH,QAAQgD,IAAI,CAAC6E,EAAWE,EAAYE,KAG1CD,KAAK,KACJnJ,YAAY,CACVC,KAAMA,EACNI,IAAK,kCAGRwJ,MAAOjG,IACNkG,QAAQtJ,MAAMoD,GACdD,EAAU1D,EAAM2D,EAAKC,IAG3B,MAAO,GAAa,YAAT5D,EACT4D,GAAQ,EACR2E,EACGW,KAAKrL,UACJ,IACIiM,EADStI,EAAQuI,OACFD,MAEnB,GAAc,OAAVA,EAAgB,CAElB,IAAIE,EAAU,CAAC,EACf,IAAK,MAAOxD,EAAGS,KAAMlE,OAAOE,QAAQ6G,GAC9B,QAAS7C,GAAKA,EAAEgD,OAAO5E,IACzBA,EAAW4B,EAAEgD,KAAKC,eACX7E,EAAWmB,IAEpBwD,EAAQxD,GAAKZ,EAAcqB,GAAG,GAC9B+C,EAAQxD,GAAG2D,WAAWlD,EAAEhB,SAG1B,IAAK,MAAOO,EAAGS,KAAMlE,OAAOE,QAAQ+G,GAAU,CAC5CzE,QAAgB0B,EAAEmD,OAELN,EAAMtD,GAAnB,IAEI6D,EAAc,SAClBjH,EAAYiH,GAGZ,IAAIC,EAAkB,CAAC,EACvB,IAAK,MAAM9D,KAAKjB,EAAQkB,MAAMC,cAAe,CAC3C,IAAIC,EAAOpB,EAAQkB,MAAMG,OAAOJ,GAChC,GAAIzC,EAAc4C,GAAO,CACvB,MAAM4D,EAAQtG,EAAe0C,EAAM,CACjCzC,KAAK,EACLC,QAAQ,EACRC,QAASoC,IAEX8D,EAAgB9D,GAAK+D,CACvB,CACF,CAEA,IAAIC,EAAmB,CACrBC,YAAaH,EACbI,MAAO,CAAC,EACRC,UAAWpF,EAAQkB,MAAMO,eACzB4D,UAAW,CAAC,GAGd,IAAK,MAAOpE,EAAGS,KAAMlE,OAAOE,QAAQsC,EAAQsF,UAAW,CACrDL,EAAwB,MAAEhE,GAAK,CAAC,EAChCgE,EAA4B,UAAEhE,GAAKS,EAAED,eACrC,IAAK,MAAMhD,KAAOiD,EAAEP,cAAe,CACjC,IAAIC,EAAOM,EAAEL,OAAO5C,GAChBD,EAAc4C,KAChB6D,EAAwB,MAAEhE,GAAGxC,GAAO2C,EAExC,CAEIM,EAAEK,aACJkD,EAAwB,MAAEhE,GAAa,SAAIS,EAAEK,WAEjD,CACAhE,EAAY+G,EAAaG,GAEzB,IAAIM,EAAa,YACjB1H,EAAY0H,GACZ,IAAIC,EAAkB,CAAC,EAEvB,IAAK,MAAOvE,EAAGS,KAAMlE,OAAOE,QAAQsC,EAAQyF,oBAClB,QAApBxE,EAAEyE,gBACJF,EAAgBvE,GAAK,CACnB7G,EAAGsH,EAAE,GAAGe,QACRkD,EAAGjE,EAAE,GAAGe,UAKd1E,EAAYwH,EAAYC,GAEpBtF,GACFA,EAAuB0F,OAGzB1F,EAAyB,IAAIpB,EAAAA,GAC3BkB,EAAQ+C,OAEZ,CACF,IAEDsB,MAAOjG,IACNkG,QAAQtJ,MAAMoD,GACdD,EAAU1D,EAAM2D,EAAKC,UAGpB,GAAa,oBAAT5D,EACTuI,EACGW,KAAKrL,UACJ,IAAI4F,EAAO,CAAC,EACZ,IAEE,IAAIuG,EAAU,CAAC,EACX1D,EAAU,CAAC,EACf,IAAK,MAAOE,EAAGS,KAAMlE,OAAOE,QAAQzB,EAAQuI,OAAOD,OACjD,GAAI,QAAS7C,EACLA,EAAEgD,OAAO5E,IACbA,EAAW4B,EAAEgD,KAAOrE,EAAcqB,GAClC3B,EAAmB2B,EAAEgD,WAAa5E,EAAW4B,EAAEgD,KAAK3D,WAEtD0D,EAAQxD,GAAKnB,EAAW4B,EAAEgD,KAC1B3D,EAAQE,GAAKH,EAAgBf,EAAmB2B,EAAEgD,KAAMhD,OACnD,CACL,IAAImE,EAAcxF,EAAcqB,GAChC+C,EAAQxD,GAAK4E,EACb9E,EAAQE,GAAKH,EAAgB2D,EAAQxD,GAAIS,EAC3C,CAGFxD,EAAKhD,OAAS,UACdgD,EAAK4H,QAAU/E,CACjB,CAAE,MAAOiD,GACPM,QAAQtJ,MAAMgJ,GACd9F,EAAKhD,OAAS,QACdgD,EAAKI,OAAS0F,EAAEzF,UAClB,CAEA/D,YAAY,CACVC,KAAM,uBACNyD,KAAMA,EACNrD,IAAK,oCAGRwJ,MAAOjG,IACNkG,QAAQtJ,MAAMoD,GACdD,EAAU1D,EAAM2D,EAAKC,UAIpB,GAAa,0BAAT5D,EACTuI,EACGW,KAAMvJ,IACL,IAAI2L,EAAY9J,EAAQ8J,UACpBC,EAAW/J,EAAQ+J,SACnB5D,EAAanG,EAAQmG,WAErBC,EAAiB4D,EAAAA,GAAgBtD,EAAcP,IAG/C8D,EADM/D,EAA4BC,EAAYC,GAChC8D,cAChB9D,EAAe+D,OAAOxD,QAAQ3G,EAAQoK,MACtChE,EAAe+D,OAAOxD,QAAQ3G,EAAQqK,QAEpCpI,EAAOY,EAAAA,GACToH,EAAQK,QAAQP,GAChBE,EAAQG,KACRN,GAGF,IAAIS,EAAgB,GACpBvJ,EAAeiB,EAAMsI,GACrBhM,YACE,CACEC,KAAM,wBACNyD,KAAMA,EACNrD,IAAK,yCAEP2L,KAGHnC,MAAOjG,IACNkG,QAAQtJ,MAAMoD,GACdD,EAAU1D,EAAM2D,EAAKC,UAEpB,GAAa,4BAAT5D,EACTuI,EACGW,KAAMvJ,IACL,IAAI2L,EAAY9J,EAAQ8J,UACpB9M,EAAMiH,EAAuBiG,cAC/BlK,EAAQoK,KACRpK,EAAQqK,OAENpI,EAAOY,EAAAA,GACT7F,EAAa,QAAEgD,EAAQ+J,UACvB/J,EAAQoK,KACRN,GAGF,IAAIS,EAAgB,GACpBvJ,EAAeiB,EAAMsI,GACrBhM,YACE,CACEC,KAAM,0BACNyD,KAAMA,EACNrD,IAAK,2CAEP2L,KAGHnC,MAAOjG,IACNkG,QAAQtJ,MAAMoD,GACdD,EAAU1D,EAAM2D,EAAKC,UAIpB,GAAa,yBAAT5D,EACTuI,EACGW,KAAMvJ,IACL,IAAIqM,EAAUxK,EAAQwK,QAClBV,EAAY9J,EAAQ8J,UACpBC,EAAW/J,EAAQ+J,SACnB5D,EAAanG,EAAQmG,WAErBC,EAAiB4D,EAAAA,GAAgBtD,EAAcP,IAG/C8D,EAFM/D,EAA4BC,EAAYC,GAEhCqE,eAAeV,GAE7B9H,EAAOY,EAAAA,GACToH,EACA7D,EAAe+D,OAAOxD,QAAQ6D,GAC9BV,GAGF,IAAIS,EAAgB,GACpBvJ,EAAeiB,EAAMsI,GACrBhM,YACE,CACEC,KAAM,uBACNyD,KAAMA,EACNrD,IAAK,iCAEP2L,KAGHnC,MAAOjG,IACNkG,QAAQtJ,MAAMoD,GACdD,EAAU1D,EAAM2D,EAAKC,UAEpB,GAAa,sBAAT5D,EACTuI,EACGW,KAAMvJ,IACL,IAAIuM,EAAU1K,EAAQ2K,KAClBZ,EAAW/J,EAAQ+J,SAEvB,IAAIa,EAAM7G,EAAQ+C,OAAOxJ,IAAIyM,GAAUc,IAAIH,GAE3CnM,YACE,CACEC,KAAM,oBACNyD,KAAM,CACJ0I,KAAMD,EACNI,KAAMF,GAERhM,IAAK,qCAEP,CAACgM,EAAI1L,WAGRkJ,MAAOjG,IACNkG,QAAQtJ,MAAMoD,GACdD,EAAU1D,EAAM2D,EAAKC,UAEpB,GAAa,yBAAT5D,EACTuI,EACGW,KAAMvJ,IACL8F,EAAuB8G,aAAa/K,EAAQ5C,GAAI4C,EAAQgL,WACxDzM,YAAY,CACVC,KAAM,uBACNI,IAAK,2CAGRwJ,MAAOjG,IACNkG,QAAQtJ,MAAMoD,GACdD,EAAU1D,EAAM2D,EAAKC,UAEpB,GAAa,2BAAT5D,EACTuI,EACGW,KAAMvJ,IACL,IAAI2L,EAAY9J,EAAQ8J,UAEpBG,EAAUhG,EAAuBwG,aAAazK,EAAQwK,SACxDxK,EAAQ+J,UAEN9H,EAAOY,EAAAA,GAA2BoH,EAAS,EAAGH,GAElD,IAAIS,EAAgB,GACpBvJ,EAAeiB,EAAMsI,GACrBhM,YACE,CACEC,KAAM,+BACNyD,KAAMA,EACNrD,IAAK,iCAEP2L,KAGHnC,MAAOjG,IACNkG,QAAQtJ,MAAMoD,GACdD,EAAU1D,EAAM2D,EAAKC,UAEpB,GAAa,wBAAT5D,EACTuI,EACGW,KAAMvJ,IACL8F,EAAuBgH,gBAAgBjL,EAAQ5C,MAEhDgL,MAAOjG,IACNkG,QAAQtJ,MAAMoD,GACdD,EAAU1D,EAAM2D,EAAKC,UAEpB,GAAa,kBAAT5D,EACTuI,EACGW,KAAMvJ,IACL,IACIyM,EAAK5M,EADLkN,EAAQlL,EAAQmG,WAMpB,GAHAyE,EAAMlE,EAAcwE,GAGhBxJ,YAAYC,OAAOiJ,GACrB5M,EAAS,CACPQ,KAAM,QACN2M,OAAQP,EAAIpE,aAET,CACL,IAAI4E,EAAY,GACZC,EAAW,CAAC,EACZC,EAAU,IAAIC,WAAWX,EAAIlO,QACjCkO,EAAIY,IAAI,CAACrN,EAAGsN,KACJtN,KAAKkN,IACTA,EAASlN,GAAKiN,EAAU1O,OACxB0O,EAAUrN,KAAKI,IAEjBmN,EAAQG,GAAKJ,EAASlN,KAGxBH,EAAS,CACPQ,KAAM,SACNkN,MAAOJ,EACPnB,OAAQiB,EAEZ,CAEA,IAAIO,EAAY,GAChB3K,EAAehD,EAAQ2N,GACvBpN,YACE,CACEC,KAAM,gBACNyD,KAAM,CACJkE,WAAY+E,EACZC,OAAQnN,GAEVY,IAAK,gCAEP+M,KAGHvD,MAAOjG,IACNkG,QAAQtJ,MAAMoD,GACdD,EAAU1D,EAAM2D,EAAKC,UAEpB,GAAa,6BAAT5D,EACTuI,EACGW,KAAKrL,UACJ,IAEI4F,GAFA,WAAEkE,EAAU,UAAE2D,EAAS,QAAEU,EAAO,SAAET,GAAa/J,EAC/C0L,EAAQ5B,EAAUnD,QAAQ,KAG9B,GAAIhD,IAAsBwC,EAAY,CACpC,IAAIyF,EACF3H,EAAuBwG,aAAaD,GAAST,GAE/C7F,EAAyB2H,QAAQnE,KAAMvJ,IACrC8D,EAAOiC,EAAyB4H,kBAC9BF,EACA,EACA9B,EAAUtD,MAAM,EAAGkF,GACnB5B,EAAUtD,MAAMkF,EAAQ,IAE1B5J,EAAY,2BAA4BG,IAE5C,KAAO,CACL,IAAImE,EAAiB4D,EAAAA,GAAgBtD,EAAcP,IAE/CyF,EADM1F,EAA4BC,EAAYC,GAC3BqE,eAAeV,GAEtC7F,EAAyB2H,QAAQnE,KAAMvJ,IACrC8D,EAAOiC,EAAyB4H,kBAC9BF,EACAxF,EAAe+D,OAAOxD,QAAQ6D,GAC9BV,EAAUtD,MAAM,EAAGkF,GACnB5B,EAAUtD,MAAMkF,EAAQ,IAE1B5J,EAAY,2BAA4BG,IAE5C,IAEDmG,MAAOjG,IACNkG,QAAQtJ,MAAMoD,GACdD,EAAU1D,EAAM2D,EAAKC,UAEpB,GAAa,+BAAT5D,EACTuI,EACGW,KAAKrL,UACJ,IAEI4F,GAFA,WAAEkE,EAAU,UAAE2D,EAAS,KAAEM,EAAI,MAAEC,EAAK,SAAEN,GAAa/J,EACnD0L,EAAQ5B,EAAUnD,QAAQ,KAE9B,GAAIhD,IAAsBwC,EAAY,CACpC,IAAIyF,EAAe3H,EAAuBiG,cAAcE,EAAMC,GAE9DnG,EAAyB2H,QAAQnE,KAAMvJ,IACrC8D,EAAOiC,EAAyB4H,kBAC9BF,EAAatB,QAAQP,GACrB,EACAD,EAAUtD,MAAM,EAAGkF,GACnB5B,EAAUtD,MAAMkF,EAAQ,IAE1B5J,EAAY,6BAA8BG,IAE9C,KAAO,CACL,IAAImE,EAAiB4D,EAAAA,GAAgBtD,EAAcP,IAG/C8D,EAFM/D,EAA4BC,EAAYC,GAEhC8D,cAChB9D,EAAe+D,OAAOxD,QAAQ3G,EAAQoK,MACtChE,EAAe+D,OAAOxD,QAAQ3G,EAAQqK,QAGxCnG,EAAyB2H,QAAQnE,KAAMvJ,IACrC8D,EAAOiC,EAAyB4H,kBAC9B7B,EAAQK,QAAQP,GAChBE,EAAQG,KACRN,EAAUtD,MAAM,EAAGkF,GACnB5B,EAAUtD,MAAMkF,EAAQ,IAE1B5J,EAAY,6BAA8BG,IAE9C,IAEDmG,MAAOjG,IACNkG,QAAQtJ,MAAMoD,GACdD,EAAU1D,EAAM2D,EAAKC,UAEpB,GAAa,qBAAT5D,EACTuI,EACGW,KAAMvJ,IACL,IAAI,MAAEuN,GAAU1L,EAGhB8B,EAAY,mBADDoC,EAAyB6H,qBAAqBL,MAG1DtD,MAAOjG,IACNkG,QAAQtJ,MAAMoD,GACdD,EAAU1D,EAAM2D,EAAKC,UAEpB,GAAa,0BAAT5D,EACTuI,EACGW,KAAMvJ,IACL,IAII8L,EAAS+B,GAJT,MAAEN,EAAK,QAAElB,EAAO,WAAErE,EAAU,SAAE4D,EAAQ,UAAED,GAAc9J,EAEtDiC,EAAOiC,EAAyB+H,uBAAuBP,GAI3D,GAAI/H,IAAsBwC,EACxB8D,EAAUhG,EAAuBwG,aAAazK,EAAQwK,SACpDxK,EAAQ+J,UAEViC,EAAcnJ,EAAAA,GACZoH,EACA,EACAjK,EAAQ8J,eAEL,CACL,IAAI1D,EAAiB4D,EAAAA,GAAgBtD,EAAcP,IAGnD8D,EAFU/D,EAA4BC,EAAYC,GAEpCqE,eAAeV,GAG7BiC,EAAcnJ,EAAAA,GACZoH,EACA7D,EAAe+D,OAAOxD,QAAQ6D,GAC9BV,EAEJ,CAEA,IAAIwB,EAAUU,EAAYE,SACvBV,IAAI,CAACrN,EAAGsN,IAAOxJ,EAAKkK,SAAShO,GAAKsN,GAAK,KACvCW,OAAQjO,IAAa,MAAPA,GAEbkO,EAAuB,CAAC,EAC5B,IAAK,MAAOrH,EAAGS,KAAMlE,OAAOE,QAAQuK,GAClCK,EAAqBrH,GAAKS,EACvB+F,IAAI,CAACrN,EAAGsN,IAAOH,EAAQa,SAASV,GAAKtN,GAAK,KAC1CiO,OAAQjO,IAAa,MAAPA,GAGnB2D,EAAY,wBAAyBuK,KAEtCjE,MAAOjG,IACNkG,QAAQtJ,MAAMoD,GACdD,EAAU1D,EAAM2D,EAAKC,UAEpB,GAAa,yBAAT5D,EACTuI,EAAOW,KAAKrL,UACV,IAAI,SAAE0N,GAAa/J,EAEfkE,GACFA,EAAyByF,OAG3BzF,EAA2B,IAAIrB,EAAAA,GAC7BkB,EAAQsF,SAASU,GACjB,CAAEuC,WAAYvI,EAAQ+C,OAAOxJ,IAAIyM,KAGnC7F,EAAyB2H,QAAQnE,KAAMvJ,IACrC,IAAIoO,EAAcrI,EAAyBsI,yBACvCC,EAAOvI,EAAyBwI,kBAUpC5K,EAAY,yBATD,CACTyK,YAAaA,EACbE,KAAM,CACJE,MAAOF,EAAKE,MACZC,aAAcH,EAAKG,aACnBC,MAAOJ,EAAKI,MAAMrG,QAClB+F,YAAaE,EAAKF,YAAY/F,oBAMjC,GAAa,0BAAThI,EAAkC,CAC3C,IAAI,WAAE2H,EAAU,QAAEqE,EAAO,SAAET,GAAa/J,EACpCV,EAAS,CAAEwN,cAAe,CAAC,GAC3BC,EAAU,KACd,GAAIpJ,IAAsBwC,EACxB4G,EAAU9I,EAAuBwG,aAAaD,OACzC,CACL,IACInE,EAAMH,EAA4BC,EADjB6D,EAAAA,GAAgBtD,EAAcP,KAEnD4G,EAAU1G,EAAIoE,cAChB,CACgB,OAAZsC,GAAoBhD,KAAYgD,IACL,OAAzB5I,IACFA,EAAuB,IAAItB,EAAAA,GACzBkB,EAAQsF,SAASU,KAGrB5F,EACG0H,QACAnE,KAAK,KACJpI,EAAS6E,EAAqB6I,cAAcD,EAAQhD,IACpDjI,EAAY,wBAAyBxC,KAEtC8I,MAAOjG,IACNkG,QAAQtJ,MAAMoD,GACdD,EAAU1D,EAAM2D,EAAKC,KAG7B,MACEiG,QAAQtJ,MAAM,4BACdmD,EAAU1D,EAAM,mBAAoB4D,EAExC,C,GCnvBI6K,EAA2B,CAAC,EAGhC,SAASC,EAAoBC,GAE5B,IAAIC,EAAeH,EAAyBE,GAC5C,QAAqBxQ,IAAjByQ,EACH,OAAOA,EAAaC,QAGrB,IAAIC,EAASL,EAAyBE,GAAY,CACjD/P,GAAI+P,EACJpG,QAAQ,EACRsG,QAAS,CAAC,GAUX,OANAE,EAAoBJ,GAAUK,KAAKF,EAAOD,QAASC,EAAQA,EAAOD,QAASH,GAG3EI,EAAOvG,QAAS,EAGTuG,EAAOD,OACf,CAGAH,EAAoBO,EAAIF,EAGxBL,EAAoB/O,EAAI,KAGvB,IAAIuP,EAAsBR,EAAoBS,OAAEhR,EAAW,CAAC,IAAI,IAAI,KAAM,IAAOuQ,EAAoB,OAErG,OADAQ,EAAsBR,EAAoBS,EAAED,I,MCnC7C,IAAIE,EAAW,GACfV,EAAoBS,EAAI,CAACrO,EAAQuO,EAAUC,EAAIC,KAC9C,IAAGF,EAAH,CAMA,IAAIG,EAAeC,IACnB,IAASxC,EAAI,EAAGA,EAAImC,EAASlR,OAAQ+O,IAAK,CACrCoC,EAAWD,EAASnC,GAAG,GACvBqC,EAAKF,EAASnC,GAAG,GACjBsC,EAAWH,EAASnC,GAAG,GAE3B,IAJA,IAGIyC,GAAY,EACPC,EAAI,EAAGA,EAAIN,EAASnR,OAAQyR,MACpB,EAAXJ,GAAsBC,GAAgBD,IAAaxM,OAAO6M,KAAKlB,EAAoBS,GAAGU,MAAO7M,GAAS0L,EAAoBS,EAAEnM,GAAKqM,EAASM,KAC9IN,EAASS,OAAOH,IAAK,IAErBD,GAAY,EACTH,EAAWC,IAAcA,EAAeD,IAG7C,GAAGG,EAAW,CACbN,EAASU,OAAO7C,IAAK,GACrB,IAAI8C,EAAIT,SACEnR,IAAN4R,IAAiBjP,EAASiP,EAC/B,CACD,CACA,OAAOjP,CArBP,CAJCyO,EAAWA,GAAY,EACvB,IAAI,IAAItC,EAAImC,EAASlR,OAAQ+O,EAAI,GAAKmC,EAASnC,EAAI,GAAG,GAAKsC,EAAUtC,IAAKmC,EAASnC,GAAKmC,EAASnC,EAAI,GACrGmC,EAASnC,GAAK,CAACoC,EAAUC,EAAIC,G,KCJ/Bb,EAAoBsB,EAAI,CAACnB,EAASoB,KACjC,IAAI,IAAIjN,KAAOiN,EACXvB,EAAoBwB,EAAED,EAAYjN,KAAS0L,EAAoBwB,EAAErB,EAAS7L,IAC5ED,OAAOoN,eAAetB,EAAS7L,EAAK,CAAEoN,YAAY,EAAMtR,IAAKmR,EAAWjN,MCJ3E0L,EAAoB2B,EAAI,CAAC,EAGzB3B,EAAoBnF,EAAK+G,GACjBpP,QAAQgD,IAAInB,OAAO6M,KAAKlB,EAAoB2B,GAAGE,OAAO,CAACC,EAAUxN,KACvE0L,EAAoB2B,EAAErN,GAAKsN,EAASE,GAC7BA,GACL,KCNJ9B,EAAoB+B,EAAKH,GAEjB,aAAeA,EAAU,IAAM,CAAC,IAAM,WAAW,IAAM,WAAW,IAAM,WAAW,IAAM,WAAW,IAAM,WAAW,IAAM,YAAYA,GAAW,YCF1J5B,EAAoBgC,SAAYJ,MCDhC5B,EAAoBiC,EAAI,WACvB,GAA0B,kBAAfC,WAAyB,OAAOA,WAC3C,IACC,OAAOC,MAAQ,IAAIC,SAAS,cAAb,EAChB,CAAE,MAAOvH,GACR,GAAsB,kBAAXwH,OAAqB,OAAOA,MACxC,CACA,CAPuB,GCAxBrC,EAAoBwB,EAAI,CAACc,EAAKC,IAAUlO,OAAOmO,UAAUC,eAAenC,KAAKgC,EAAKC,GCAlFvC,EAAoB0C,IAAOtC,IAC1BA,EAAOuC,MAAQ,GACVvC,EAAOwC,WAAUxC,EAAOwC,SAAW,IACjCxC,GCHRJ,EAAoB6C,EAAI,S,MCAxB7C,EAAoB8C,EAAIC,KAAKC,SAAW,aAIxC,IAAIC,EAAkB,CACrB,IAAK,GAkBNjD,EAAoB2B,EAAEpD,EAAI,CAACqD,EAASE,KAE/BmB,EAAgBrB,IAElBsB,cAAclD,EAAoB6C,EAAI7C,EAAoB+B,EAAEH,KAK/D,IAAIuB,EAAqBJ,KAAuB,iBAAIA,KAAuB,kBAAK,GAC5EK,EAA6BD,EAAmBtS,KAAKwS,KAAKF,GAC9DA,EAAmBtS,KAzBCkJ,IACnB,IAAI4G,EAAW5G,EAAK,GAChBuJ,EAAcvJ,EAAK,GACnBwJ,EAAUxJ,EAAK,GACnB,IAAI,IAAIkG,KAAYqD,EAChBtD,EAAoBwB,EAAE8B,EAAarD,KACrCD,EAAoBO,EAAEN,GAAYqD,EAAYrD,IAIhD,IADGsD,GAASA,EAAQvD,GACdW,EAASnR,QACdyT,EAAgBtC,EAAS6C,OAAS,EACnCJ,EAA2BrJ,G,WCrB5B,IAAI0J,EAAOzD,EAAoB/O,EAC/B+O,EAAoB/O,EAAI,IAChBuB,QAAQgD,IAAI,CAAC,IAAI,IAAI,KAAK8I,IAAI0B,EAAoBnF,EAAGmF,IAAsBxF,KAAKiJ,E,KCD9DzD,EAAoB/O,G","sources":["workers/DownloadsDBHandler.js","workers/helpers.js","utils/utils.js","workers/explorer.worker.js","../webpack/bootstrap","../webpack/runtime/chunk loaded","../webpack/runtime/define property getters","../webpack/runtime/ensure chunk","../webpack/runtime/get javascript chunk filename","../webpack/runtime/get mini-css chunk filename","../webpack/runtime/global","../webpack/runtime/hasOwnProperty shorthand","../webpack/runtime/node module decorator","../webpack/runtime/publicPath","../webpack/runtime/importScripts chunk loading","../webpack/runtime/startup chunk dependencies","../webpack/startup"],"sourcesContent":["var DownloadsDB;\nvar init = null;\n\nexport function initialize() {\n  if (init === null) {\n    init = new Promise((resolve, reject) => {\n      // initialize database on worker creation\n      DownloadsDB = indexedDB.open(\"DownloadsDB\", 3);\n\n      DownloadsDB.onupgradeneeded = (e) => {\n        var DownloadsDBClient = e.target.result;\n\n        // Currently purging all existing stores when the version is updated.\n        // At some point we may add a more sophisticated upgrade mechanism.\n        try {\n          DownloadsDBClient.deleteObjectStore(\"downloads\");\n        } catch (e) {}\n\n        DownloadsDBClient.createObjectStore(\"downloads\", { keyPath: \"url\" });\n      };\n\n      DownloadsDB.onsuccess = () => {\n        resolve(null);\n      };\n\n      DownloadsDB.onerror = () => {\n        reject(\"failed to initialize DownloadsDB\");\n      };\n    });\n  }\n\n  return init;\n}\n\nasync function fetchWithProgress(url, startFun, iterFun, endFun, params=null) {\n  let res;\n  if (params == null) {\n    res = await fetch(url);\n  } else {\n    res = await fetch(url, params);\n  }\n\n  if (!res.ok) {\n    throw new Error(\"oops, failed to download '\" + url + \"'\");\n  }\n\n  const cl = res.headers.get(\"content-length\"); // WARNING: this might be NULL!\n  const id = startFun(cl);\n\n  const reader = res.body.getReader();\n  const chunks = [];\n  let total = 0;\n\n  while (true) {\n    const { done, value } = await reader.read();\n    if (done) {\n      break;\n    }\n    chunks.push(value);\n    total += value.length;\n    iterFun(id, total);\n  }\n\n  let output = new Uint8Array(total);\n  let start = 0;\n  for (const x of chunks) {\n    output.set(x, start);\n    start += x.length;\n  }\n\n  endFun(id, total);\n  return output;\n}\n\nasync function fetchWrapper(url, params = null) {\n  try {\n    const out = await fetchWithProgress(\n      url,\n      (cl) => {\n        postMessage({\n          type: `DOWNLOAD for url: ` + String(url),\n          download: \"START\",\n          url: String(url),\n          total_bytes: String(cl),\n          msg: \"Total size is \" + String(cl) + \" bytes!\",\n        });\n        return url;\n      },\n      (id, sofar) => {\n        postMessage({\n          type: `DOWNLOAD for url: ` + String(url),\n          download: \"PROGRESS\",\n          url: String(url),\n          downloaded_bytes: String(sofar),\n          msg: \"Progress so far, got \" + String(sofar) + \" bytes!\",\n        });\n      },\n      (id, total) => {\n        postMessage({\n          type: `DOWNLOAD for url: ` + String(url),\n          download: \"COMPLETE\",\n          url: String(url),\n          msg: \"Finished, got \" + String(total) + \" bytes!\",\n        });\n      },\n      params\n    );\n\n    return out;\n  } catch (error) {\n    // console.log(\"oops error\", error)\n    postMessage({\n      type: `DOWNLOAD for url: ` + String(url),\n      download: \"START\",\n      url: String(url),\n      total_bytes: 100,\n    });\n\n    let req;\n    if (params == null) {\n      req = fetch(url);\n    } else {\n      req = fetch(url, params);\n    }\n\n    var res = await req;\n    if (!res.ok) {\n      throw new Error(\"failed to download '\" + url + \"' (\" + res.status + \")\");\n    }\n    var buffer = await res.arrayBuffer();\n\n    postMessage({\n      type: `DOWNLOAD for url: ` + String(url),\n      download: \"COMPLETE\",\n      url: String(url),\n    });\n    return new Uint8Array(buffer);\n  }\n}\n\nexport async function get(url, params = null, force = false) {\n  await init;\n\n  if (!force) {\n    let trans = DownloadsDB.result.transaction([\"downloads\"], \"readonly\");\n    let download_store = trans.objectStore(\"downloads\");\n\n    var data_check = new Promise((resolve, reject) => {\n      var already = download_store.get(url);\n      already.onsuccess = event => {\n        if (already.result !== undefined) {\n          resolve(already.result.payload);\n        } else {\n          resolve(null);\n        }\n      };\n      already.onerror = event => {\n        reject(`failed to query DownloadsDB for ${url}: ${event.target.errorCode}`);\n      };\n    });\n\n    var found = await data_check;\n    if (found !== null) {\n      return found;\n    }\n  }\n\n  var buffer = await fetchWrapper(url, params)\n\n  // Technically, this isn't quite right, because we need to close the read\n  // transaction before opening the write transaction; multiple queries to\n  // the same URL from different workers could cause multiple downloads if\n  // they each miss each other's read check. But oh well; the auto-commit\n  // of IDB transactions means that it's hard to do any better. (Specifically,\n  // we can't do an async fetch while the transaction is still open, because\n  // it just closes before the fetch is done.)\n  let trans = DownloadsDB.result.transaction([\"downloads\"], \"readwrite\");\n\n  // The Promise's function should evaluate immediately\n  // (see https://stackoverflow.com/questions/35177230/are-promises-lazily-evaluated) \n  // so the callbacks should be attached to the transaction before we return to the event loop.\n  let fin = new Promise((resolve, reject) => {\n    trans.oncomplete = (event) => {\n      resolve(null);\n    };\n    trans.onerror = (event) => {\n      reject(new Error(`transaction error for saving ${url} in DownloadsDB: ${event.target.errorCode}`));\n    };\n  });\n\n  let download_store = trans.objectStore(\"downloads\");\n  let saving = new Promise((resolve, reject) => {\n    var putrequest = download_store.put({ url: url, payload: buffer });\n    putrequest.onsuccess = event => {\n      resolve(true);\n    };\n    putrequest.onerror = event => {\n      reject(new Error(`failed to cache ${url} in DownloadsDB: ${event.target.errorCode}`));\n    };\n  });\n\n  // Stack all awaits here, AFTER event handlers have been attached.\n  await saving;\n  await fin;\n  return buffer;\n}\n\nexport async function remove(url) {\n  await init;\n  let trans = DownloadsDB.result.transaction([\"downloads\"], \"readwrite\");\n  let fin = new Promise((resolve, reject) => {\n    trans.oncomplete = (event) => {\n      resolve(null);\n    };\n    trans.onerror = (event) => {\n      reject(new Error(`transaction error for removing ${url} in DownloadsDB: ${event.target.errorCode}`));\n    };\n  });\n\n  let download_store = trans.objectStore(\"downloads\")\n  let removal = new Promise((resolve, reject) => {\n    let request = download_store.delete(url);\n    request.onsuccess = event => {\n      resolve(true);\n    };\n    request.onerror = event => {\n      reject(new Error(`failed to remove ${url} from DownloadsDB: ${event.target.errorCode}`));\n    };\n  });\n\n  // Only await after attaching event handlers.\n  await removal;\n  await fin;\n  return;\n}\n","import * as bakana from \"bakana\";\nimport * as gesel from \"gesel\";\nimport * as remotes from \"bakana-remotes\";\nimport * as downloads from \"./DownloadsDBHandler.js\";\n\n// Evade CORS problems and enable caching.\nconst proxy = \"https://cors-proxy.aaron-lun.workers.dev\";\nasync function proxyAndCache(url) {\n  let buffer = await downloads.get(proxy + \"/\" + encodeURIComponent(url));\n  return new Uint8Array(buffer);\n}\n\nbakana.CellLabellingState.setDownload(proxyAndCache);\ngesel.setGeneDownload(proxyAndCache);\nbakana.RnaQualityControlState.setDownload(proxyAndCache);\n\ngesel.referenceDownload(async (file, start, end) => {\n  let url = gesel.referenceBaseUrl() + \"/\" + file;\n  let full = proxy + \"/\" + encodeURIComponent(url);\n  if (start == null && end == null) {\n    let buffer = await downloads.get(full);\n    return new Response(buffer);\n  } else {\n    return fetch(full + \"?start=\" + String(start) + \"&end=\" + String(end));\n  }\n});\n\ngesel.geneDownload(async (file) => {\n  let url = gesel.geneBaseUrl() + \"/\" + file;\n  let buffer = await downloads.get(proxy + \"/\" + encodeURIComponent(url));\n  return new Response(buffer);\n});\n\nremotes.ExperimentHubDataset.setDownloadFun(proxyAndCache);\nbakana.availableReaders[\"ExperimentHub\"] = remotes.ExperimentHubDataset;\n\nexport function extractBuffers(object, store) {\n  if (!object) {\n    return;\n  }\n\n  if (Array.isArray(object)) {\n    for (const element of object) {\n      extractBuffers(element, store);\n    }\n  } else if (object.constructor == Object) {\n    for (const [key, element] of Object.entries(object)) {\n      extractBuffers(element, store);\n    }\n  } else if (ArrayBuffer.isView(object)) {\n    if (!(object.buffer instanceof ArrayBuffer)) {\n      throw \"only ArrayBuffers should be in the message payload\";\n    }\n    store.push(object.buffer);\n  }\n}\n\nexport function postAttempt(step) {\n  postMessage({\n    type: `${step}_START`,\n  });\n}\n\nexport function postSuccess(step, info) {\n  if (typeof info == \"undefined\") {\n    postMessage({\n      type: `${step}_CACHE`,\n    });\n  } else {\n    var transferable = [];\n    extractBuffers(info, transferable);\n    postMessage(\n      {\n        type: `${step}_DATA`,\n        resp: info,\n      },\n      transferable\n    );\n  }\n}\n\nexport function postError(type, err, fatal) {\n  postMessage({\n    type: `${type}_ERROR`,\n    resp: {\n      reason: err.toString(),\n      fatal: fatal,\n    },\n  });\n}\n\nexport function splitMetricsByBlock(metrics, blockLevels, blockIds) {\n  var output = {};\n  var blocks = blockIds.slice();\n  for (var b = 0; b < blockLevels.length; b++) {\n    let current = {};\n    for (const [key, val] of Object.entries(metrics)) {\n      current[key] = val.slice().filter((x, i) => blocks[i] == b);\n    }\n    output[blockLevels[b]] = current;\n  }\n  return output;\n}\n\nexport function splitThresholdsByBlock(thresholds, blockLevels) {\n  var output = {};\n  for (const x of blockLevels) {\n    output[x] = {};\n  }\n\n  for (const [key, val] of Object.entries(thresholds)) {\n    for (var b = 0; b < blockLevels.length; b++) {\n      output[blockLevels[b]][key] = val[b];\n    }\n  }\n\n  return output;\n}\n\nexport async function fetchStepSummary(state, step) {\n  // do not send any response to UI if they have not changed\n  if (!state[step].changed) {\n    return undefined;\n  }\n\n  if (step === \"inputs\") {\n    let output = {};\n\n    let ngenes = {};\n    for (const a of state[step].fetchCountMatrix().available()) {\n      ngenes[a] = state[step].fetchCountMatrix().get(a).numberOfRows();\n    }\n\n    let gene_info = {};\n    for (const [k, v] of Object.entries(\n      state[step].fetchFeatureAnnotations()\n    )) {\n      let info = {};\n      for (const c of v.columnNames()) {\n        let col = v.column(c);\n        if (Array.isArray(col)) {\n          info[c] = col;\n        }\n      }\n\n      if (Array.isArray(v.rowNames())) {\n        info[\"rownames\"] = v.rowNames();\n      }\n\n      gene_info[k] = info;\n    }\n\n    let cell_info = {};\n    for (const c of state[step].fetchCellAnnotations().columnNames()) {\n      let col = state[step].fetchCellAnnotations().column(c);\n      if (isArrayOrView(col)) {\n        const ksumm = describeColumn(col, {\n          all: false,\n          unique: true,\n          colname: c,\n        });\n        cell_info[c] = ksumm;\n      }\n    }\n\n    var blocks = state[step].fetchBlockLevels();\n    if (blocks !== null) {\n      const col = state[step].fetchBlock().slice();\n      if (isArrayOrView(col)) {\n        const ksumm = describeColumn(col, {\n          all: false,\n          unique: true,\n          colname: \"__batch__\",\n        });\n        cell_info[\"__batch__\"] = ksumm;\n      }\n    }\n\n    output = {\n      num_cells: state[step].fetchCountMatrix().numberOfColumns(),\n      num_genes: ngenes,\n      genes: gene_info,\n      annotations: cell_info,\n    };\n\n    return output;\n  } else if (step === \"rna_quality_control\") {\n    let metrics = {\n      sums: state[step].fetchMetrics().sums(),\n      detected: state[step].fetchMetrics().detected(),\n      proportion: state[step].fetchMetrics().subsetProportions(0),\n    };\n\n    let output = {};\n    var blocks = state[\"inputs\"].fetchBlockLevels();\n\n    if (blocks === null) {\n      blocks = [\"default\"];\n      output.data = { default: metrics };\n    } else {\n      let bids = state[\"inputs\"].fetchBlock();\n      output.data = splitMetricsByBlock(metrics, blocks, bids);\n    }\n\n    let listed = {\n      sums: state[step].fetchFilters().thresholdsSums(),\n      detected: state[step].fetchFilters().thresholdsDetected(),\n      proportion: state[step].fetchFilters().thresholdsSubsetProportions(0),\n    };\n    output.thresholds = splitThresholdsByBlock(listed, blocks);\n\n    return output;\n  } else if (step === \"adt_quality_control\") {\n    let metrics = {\n      sums: state[step].fetchMetrics().sums(),\n      detected: state[step].fetchMetrics().detected(),\n      proportion: state[step].fetchMetrics().subsetTotals(0),\n    };\n\n    var output = {};\n    var blocks = state[\"inputs\"].fetchBlockLevels();\n    if (blocks === null) {\n      blocks = [\"default\"];\n      output.data = { default: metrics };\n    } else {\n      let bids = state[\"inputs\"].fetchBlock();\n      output.data = splitMetricsByBlock(metrics, blocks, bids);\n    }\n\n    let listed = {\n      detected: state[step].fetchFilters().thresholdsDetected(),\n      proportion: state[step].fetchFilters().thresholdsSubsetTotals(0),\n    };\n    output.thresholds = splitThresholdsByBlock(listed, blocks);\n\n    // We don't use sums for filtering but we do report it in the metrics,\n    // so we just add some NaNs to the thresholds for consistency.\n    for (const [k, v] of Object.entries(output.thresholds)) {\n      v.sums = NaN;\n    }\n\n    return output;\n  } else if (step === \"crispr_quality_control\") {\n    let metrics = {\n      sums: state[step].fetchMetrics().sums(),\n      detected: state[step].fetchMetrics().detected(),\n      proportion: state[step].fetchMetrics().maxProportions(),\n    };\n\n    let output = {};\n    var blocks = state[\"inputs\"].fetchBlockLevels();\n    if (blocks === null) {\n      blocks = [\"default\"];\n      output.data = { default: metrics };\n    } else {\n      let bids = state[\"inputs\"].fetchBlock();\n      output.data = splitMetricsByBlock(metrics, blocks, bids);\n    }\n\n    let listed = {\n      count: state[step].fetchFilters().thresholdsMaxCount(0),\n    };\n    output.thresholds = splitThresholdsByBlock(listed, blocks);\n\n    return output;\n  } else if (step === \"cell_filtering\") {\n    let remaining = 0,\n      discard_vec = null;\n    const discardBuff = state[step].fetchDiscards();\n    if (discardBuff) {\n      discardBuff.forEach((x) => {\n        remaining += x == 0;\n      });\n      discard_vec = discardBuff.slice();\n    } else {\n      remaining = state.inputs.fetchCountMatrix().numberOfColumns();\n    }\n    let output = { retained: remaining, discard: discard_vec };\n    return output;\n  } else if (step === \"rna_normalization\") {\n    return {};\n  } else if (step === \"adt_normalization\") {\n    return {};\n  } else if (step === \"crispr_normalization\") {\n    return {};\n  } else if (step === \"feature_selection\") {\n    let output = {\n      means: state[step].fetchResults().means(),\n      vars: state[step].fetchResults().variances(),\n      fitted: state[step].fetchResults().fitted(),\n      resids: state[step].fetchResults().residuals(),\n    };\n    return output;\n  } else if (\n    step === \"rna_pca\" ||\n    step === \"adt_pca\" ||\n    step === \"crispr_pca\"\n  ) {\n    let pcs = state[step].fetchPCs();\n    var var_exp = pcs.varianceExplained();\n    var total_var = pcs.totalVariance();\n    var_exp.forEach((x, i) => {\n      var_exp[i] = x / total_var;\n    });\n    return {\n      var_exp: var_exp,\n    };\n  } else if (step === \"combine_embeddings\") {\n    return {};\n  } else if (step === \"batch_correction\") {\n    return {};\n  } else if (step === \"neighbor_index\") {\n    return {};\n  } else if (step === \"tsne\" || step === \"umap\") {\n    return await state[step].fetchResults();\n  } else if (step === \"kmeans_cluster\") {\n    return {};\n  } else if (step === \"snn_graph_cluster\") {\n    return {};\n  } else if (step === \"choose_clustering\") {\n    var clusters = state[step].fetchClusters();\n    return { clusters: clusters.slice() };\n  } else if (step === \"marker_detection\") {\n    return {};\n  } else if (step === \"cell_labelling\") {\n    let markers = state.marker_detection.fetchResults();\n    if (\"RNA\" in markers) {\n      let results = state[step].computeLabels(markers.RNA);\n      // for (const [k, v] of Object.entries(results.per_reference)) { // TODO: return scores.\n      //   results.per_reference[k] = v.map(x => x.best);\n      // }\n      // if (\"integrated\" in results) {\n      //   results.integrated = results.integrated.map(x => x.best);\n      // }\n      return results;\n    } else {\n      return { per_reference: {} };\n    }\n  } else if (step === \"custom_selections\") {\n    return {};\n  } else if (step === \"feature_set_enrichment\") {\n    let collections = state.feature_set_enrichment.fetchCollectionDetails();\n    let sets = state.feature_set_enrichment.fetchSetDetails();\n    return {\n      collections: collections,\n      sets: {\n        names: sets.names,\n        descriptions: sets.descriptions,\n        sizes: sets.sizes.slice(),\n        collections: sets.collections.slice(),\n      },\n    };\n  }\n}\n\nexport function isArrayOrView(col) {\n  return Array.isArray(col) || ArrayBuffer.isView(col);\n}\n\nexport function describeColumn(\n  col,\n  { all = false, unique = false, colname = null } = {}\n) {\n  let res;\n  if (isArrayOrView(col)) {\n    res = bakana.summarizeArray(col);\n    const uqVals = new Set(col);\n    res[\"num_unique\"] = uqVals.size;\n\n    if ((uqVals.size <= 50) & unique) res[\"values\"] = [...uqVals].sort();\n    if (all) res[\"_all_\"] = col;\n\n    // if type is continous and unique values is less than 50, type is both\n    if (res[\"type\"] === \"continuous\" && uqVals.size <= 50) res[\"type\"] = \"both\";\n\n    if (typeof colname === \"string\" || colname instanceof String)\n      res[\"name\"] = colname;\n  }\n\n  return res;\n}\n","import { randomColor } from \"randomcolor\";\n\nexport const getColors = (data) => {\n  const palette = {\n    1: [\"#1b9e77\"],\n    2: [\"#1b9e77\", \"#d95f02\"],\n    3: [\"#1b9e77\", \"#d95f02\", \"#7570b3\"],\n    4: [\"#1b9e77\", \"#d95f02\", \"#7570b3\", \"#e7298a\"],\n    5: [\"#1b9e77\", \"#d95f02\", \"#7570b3\", \"#e7298a\", \"#66a61e\"],\n    6: [\"#1b9e77\", \"#d95f02\", \"#7570b3\", \"#e7298a\", \"#66a61e\", \"#e6ab02\"],\n    7: [\n      \"#1b9e77\",\n      \"#d95f02\",\n      \"#7570b3\",\n      \"#e7298a\",\n      \"#66a61e\",\n      \"#e6ab02\",\n      \"#a6761d\",\n    ],\n    8: [\n      \"#1b9e77\",\n      \"#d95f02\",\n      \"#7570b3\",\n      \"#e7298a\",\n      \"#66a61e\",\n      \"#e6ab02\",\n      \"#a6761d\",\n      \"#666666\",\n    ],\n    9: [\n      \"#a6cee3\",\n      \"#1f78b4\",\n      \"#b2df8a\",\n      \"#33a02c\",\n      \"#fb9a99\",\n      \"#e31a1c\",\n      \"#fdbf6f\",\n      \"#ff7f00\",\n      \"#cab2d6\",\n    ],\n    10: [\n      \"#a6cee3\",\n      \"#1f78b4\",\n      \"#b2df8a\",\n      \"#33a02c\",\n      \"#fb9a99\",\n      \"#e31a1c\",\n      \"#fdbf6f\",\n      \"#ff7f00\",\n      \"#cab2d6\",\n      \"#6a3d9a\",\n    ],\n    11: [\n      \"#a6cee3\",\n      \"#1f78b4\",\n      \"#b2df8a\",\n      \"#33a02c\",\n      \"#fb9a99\",\n      \"#e31a1c\",\n      \"#fdbf6f\",\n      \"#ff7f00\",\n      \"#cab2d6\",\n      \"#6a3d9a\",\n      \"#ffff99\",\n    ],\n    12: [\n      \"#a6cee3\",\n      \"#1f78b4\",\n      \"#b2df8a\",\n      \"#33a02c\",\n      \"#fb9a99\",\n      \"#e31a1c\",\n      \"#fdbf6f\",\n      \"#ff7f00\",\n      \"#cab2d6\",\n      \"#6a3d9a\",\n      \"#ffff99\",\n      \"#b15928\",\n    ],\n  };\n\n  let cluster_count = Math.max(...data) + 1;\n  let cluster_colors = null;\n  if (cluster_count > Object.keys(palette).length) {\n    cluster_colors = randomColor({\n      luminosity: \"dark\",\n      count: cluster_count + 1,\n    });\n  } else {\n    cluster_colors = palette[cluster_count.toString()];\n  }\n\n  return cluster_colors;\n};\n\nexport function isObject(object) {\n  return typeof object === \"object\" && Array.isArray(object) === false;\n}\n\nexport const code = \"K@𝜂a#$c3ll\";\n\n// this function is from https://developer.mozilla.org/en-US/docs/Glossary/Base64\nexport function utf8_to_b64(str) {\n  return window.btoa(unescape(encodeURIComponent(str)));\n}\n\nexport function generateUID(resource) {\n  let base = `${resource.format}`;\n  switch (resource.format) {\n    case \"SummarizedExperiment\":\n      base += `::${resource.rds.name}::${resource.rds.lastModified}::${resource.rds.size}`;\n      return utf8_to_b64(base);\n    case \"MatrixMarket\":\n      for (let key of [\"genes\", \"mtx\", \"annotations\"]) {\n        if (resource[key]) {\n          base += `::${resource[key].name}::${resource[key].lastModified}::${resource[key].size}`;\n        }\n      }\n      return utf8_to_b64(base);\n    case \"10X\":\n    case \"H5AD\":\n      base += `::${resource.h5.name}::${resource.h5.lastModified}::${resource.h5.size}`;\n      return utf8_to_b64(base);\n    case \"ExperimentHub\":\n      base += `::${resource.id}`;\n      return utf8_to_b64(base);\n    case \"ZippedArtifactdb\":\n      base += `::${resource.zipname}::${resource.zipfile}`;\n      return utf8_to_b64(base);\n    case \"ZippedADB\":\n      base += `::${resource.zipname}::${resource.zipfile}`;\n      return utf8_to_b64(base);\n    default:\n      throw Error(`format: ${resource.format} does not exist`);\n      break;\n  }\n}\n\nexport const MODALITIES = [\"RNA\", \"ADT\", \"CRISPR\"];\n\nexport const getMinMax = (arr) => {\n  var max = -Number.MAX_VALUE,\n    min = Number.MAX_VALUE;\n  arr.forEach(function (x) {\n    if (max < x) {\n      max = x;\n    }\n    if (min > x) {\n      min = x;\n    }\n  });\n  return [min, max];\n};\n\nexport const defaultColor = \"#5F6B7C\";\n\nexport const default_cluster = `${code}::CLUSTERS`;\nexport const default_selection = `${code}::SELECTION`;\n\nexport const getComputedCols = (cols) => {\n  return Object.keys(cols)\n    .filter(\n      (x) =>\n        cols[x].name === default_cluster ||\n        ((cols[x].name.startsWith(code) || cols[x].name === \"__batch__\") &&\n          cols[x].type !== \"continuous\" &&\n          (cols[x][\"type\"] === \"both\" ||\n            (cols[x][\"type\"] === \"categorical\" &&\n              cols[x][\"truncated\"] === false)))\n    )\n    .filter((x) => !cols[x].name.replace(`${code}::`, \"\").startsWith(\"QC\"));\n};\n\nexport const showComputedSection = (cols, custom) => {\n  return getComputedCols(cols).length > 0 || Object.keys(custom).length > 0;\n};\n\nexport const getSuppliedCols = (cols) => {\n  return Object.keys(cols).filter(\n    (x) =>\n      !cols[x].name.startsWith(code) &&\n      cols[x].name !== \"__batch__\" &&\n      cols[x].type !== \"continuous\" &&\n      (cols[x][\"type\"] === \"both\" ||\n        (cols[x][\"type\"] === \"categorical\" && cols[x][\"truncated\"] === false))\n  );\n};\n\nexport const resetApp = () => {\n  window.location.reload();\n};\n","import * as bakana from \"bakana\";\nimport * as scran from \"scran.js\";\nimport * as downloads from \"./DownloadsDBHandler.js\";\nimport {\n  extractBuffers,\n  postAttempt,\n  postSuccess,\n  postError,\n  describeColumn,\n  isArrayOrView,\n} from \"./helpers.js\";\nimport { code } from \"../utils/utils.js\";\n/***************************************/\n\nconst default_cluster = `${code}::CLUSTERS`;\nconst default_selection = `${code}::SELECTION`;\n\nlet superstate = null;\nlet preflights = {};\nlet preflights_summary = {};\nlet dataset = null;\nlet cache_anno_markers = {};\nlet custom_selection_state = null;\nlet feature_set_enrich_state = null;\nlet cell_labelling_state = null;\n\nfunction createDataset(args, setOpts = false) {\n  if (args.format === \"H5AD\") {\n    return new bakana.H5adResult(args.h5, setOpts ? args.options : {});\n  } else if (args.format === \"SummarizedExperiment\") {\n    return new bakana.SummarizedExperimentResult(\n      args.rds,\n      setOpts ? args.options : {}\n    );\n  } else if (args.format === \"ZippedArtifactdb\") {\n    return new bakana.ZippedArtifactdbResult(\n      args.zipname,\n      new bakana.SimpleFile(args.zipfile),\n      setOpts ? args.options : {}\n    );\n  } else {\n    throw new Error(\"unknown format '\" + args.format + \"'\");\n  }\n}\n\nfunction summarizeResult(summary, args) {\n  // TODO: figure out a way to deal with nested objects later\n  let cells_summary = {};\n  for (const k of summary.cells.columnNames()) {\n    const kcol = summary.cells.column(k);\n    if (isArrayOrView(kcol))\n      cells_summary[k] = describeColumn(kcol, { all: true, colname: k });\n  }\n  let tmp_meta = {\n    cells: {\n      columns: cells_summary,\n      numberOfCells: summary.cells.numberOfRows(),\n    },\n  };\n\n  if (\n    args.format === \"SummarizedExperiment\" ||\n    args.format === \"ZippedArtifactdb\"\n  ) {\n    tmp_meta[\"modality_features\"] = {};\n    if (\"modality_features\" in summary) {\n      for (const [k, v] of Object.entries(summary.modality_features)) {\n        let tmod_summary = {};\n        for (const k of v.columnNames()) {\n          const kcol = v.column(k);\n          if (isArrayOrView(kcol)) {\n            tmod_summary[k] = describeColumn(kcol, { all: true, colname: k });\n          }\n        }\n        tmp_meta[\"modality_features\"][k] = {\n          columns: tmod_summary,\n          numberOfFeatures: v.numberOfRows(),\n          rownames: Array.isArray(v.rowNames()),\n        };\n      }\n    }\n  } else {\n    tmp_meta[\"all_features\"] = {};\n    let tmod_summary = {};\n    for (const k of summary[\"all_features\"].columnNames()) {\n      const kcol = summary[\"all_features\"].column(k);\n      if (isArrayOrView(kcol)) {\n        tmod_summary[k] = describeColumn(kcol, { all: true, colname: k });\n      }\n    }\n    tmp_meta[\"all_features\"] = {\n      columns: tmod_summary,\n      numberOfFeatures: summary[\"all_features\"].numberOfRows(),\n      rownames: Array.isArray(summary[\"all_features\"].rowNames()),\n    };\n  }\n\n  if (args.format === \"H5AD\") {\n    tmp_meta[\"all_assay_names\"] = summary.all_assay_names;\n  } else if (\n    args.format === \"SummarizedExperiment\" ||\n    args.format === \"ZippedArtifactdb\"\n  ) {\n    tmp_meta[\"modality_assay_names\"] = summary.modality_assay_names;\n  }\n\n  tmp_meta.reduced_dimension_names = summary.reduced_dimension_names;\n  return tmp_meta;\n}\n\nfunction getMarkerStandAloneForAnnot(annotation, annotation_vec) {\n  let mds;\n  if (!(annotation in cache_anno_markers)) {\n    mds = new bakana.MarkerDetectionStandalone(\n      getMatrix(),\n      annotation_vec.ids.slice()\n    );\n\n    mds.computeAll();\n    cache_anno_markers[annotation] = mds;\n  }\n\n  return cache_anno_markers[annotation];\n}\n\nconst getAnnotation = (annotation) => {\n  if (annotation.indexOf(\":::\") !== -1) {\n    let splits = annotation.split(\":::\");\n    return dataset.cells.column(splits[0]).column(splits[1]);\n  }\n  return dataset.cells.column(annotation);\n};\n\nconst getMatrix = () => {\n  return dataset.matrix;\n};\n\n/***************************************/\n\nvar loaded;\nonmessage = function (msg) {\n  const { type, payload } = msg.data;\n\n  // console.log(\"EXPLORE WORKER::RCV::\", type, payload);\n\n  let fatal = false;\n  if (type === \"INIT\") {\n    fatal = true;\n    let nthreads = Math.round((navigator.hardwareConcurrency * 2) / 3);\n    let back_init = bakana.initialize({ numberOfThreads: nthreads });\n\n    let state_init = back_init.then(() => {\n      return bakana.createAnalysis();\n    });\n\n    state_init.then((x) => {\n      superstate = x;\n      postMessage({\n        type: type,\n        msg: \"Success: analysis state created\",\n      });\n    });\n\n    let down_init = downloads.initialize();\n    down_init\n      .then((output) => {\n        postMessage({\n          type: \"DownloadsDB_store\",\n          resp: output,\n          msg: \"Success: DownloadsDB initialized\",\n        });\n      })\n      .catch((error) => {\n        console.error(error);\n        postMessage({\n          type: \"DownloadsDB_ERROR\",\n          msg: \"Error: Cannot initialize DownloadsDB\",\n        });\n      });\n\n    loaded = Promise.all([back_init, state_init, down_init]);\n\n    loaded\n      .then(() => {\n        postMessage({\n          type: type,\n          msg: \"Success: bakana initialized\",\n        });\n      })\n      .catch((err) => {\n        console.error(err);\n        postError(type, err, fatal);\n      });\n    /**************** EXPLORE AN ANALYSIS *******************/\n  } else if (type === \"EXPLORE\") {\n    fatal = true;\n    loaded\n      .then(async (x) => {\n        let inputs = payload.inputs;\n        let files = inputs.files;\n\n        if (files !== null) {\n          // Extracting existing datasets from the preflights.\n          let current = {};\n          for (const [k, v] of Object.entries(files)) {\n            if (\"uid\" in v && v.uid in preflights) {\n              preflights[v.uid].clear();\n              delete preflights[k];\n            }\n            current[k] = createDataset(v, true);\n            current[k].setOptions(v.options);\n          }\n\n          for (const [k, v] of Object.entries(current)) {\n            dataset = await v.load();\n\n            let finput = files[k];\n\n            let step_inputs = \"inputs\";\n            postAttempt(step_inputs);\n\n            // extract cell annotations\n            let annotation_keys = {};\n            for (const k of dataset.cells.columnNames()) {\n              let kcol = dataset.cells.column(k);\n              if (isArrayOrView(kcol)) {\n                const ksumm = describeColumn(kcol, {\n                  all: false,\n                  unique: true,\n                  colname: k,\n                });\n                annotation_keys[k] = ksumm;\n              }\n            }\n\n            let step_inputs_resp = {\n              annotations: annotation_keys,\n              genes: {},\n              num_cells: dataset.cells.numberOfRows(),\n              num_genes: {},\n            };\n\n            for (const [k, v] of Object.entries(dataset.features)) {\n              step_inputs_resp[\"genes\"][k] = {};\n              step_inputs_resp[\"num_genes\"][k] = v.numberOfRows();\n              for (const col of v.columnNames()) {\n                let kcol = v.column(col);\n                if (isArrayOrView(kcol)) {\n                  step_inputs_resp[\"genes\"][k][col] = kcol;\n                }\n              }\n\n              if (v.rowNames()) {\n                step_inputs_resp[\"genes\"][k][\"rowNames\"] = v.rowNames();\n              }\n            }\n            postSuccess(step_inputs, step_inputs_resp);\n\n            let step_embed = \"embedding\";\n            postAttempt(step_embed);\n            let step_embed_resp = {};\n\n            for (const [k, v] of Object.entries(dataset.reduced_dimensions)) {\n              if (k.toLowerCase() !== \"pca\") {\n                step_embed_resp[k] = {\n                  x: v[0].slice(),\n                  y: v[1].slice(),\n                };\n              }\n            }\n\n            postSuccess(step_embed, step_embed_resp);\n\n            if (custom_selection_state) {\n              custom_selection_state.free();\n            }\n\n            custom_selection_state = new bakana.CustomSelectionsStandalone(\n              dataset.matrix\n            );\n          }\n        }\n      })\n      .catch((err) => {\n        console.error(err);\n        postError(type, err, fatal);\n      });\n    /**************** LOADING EXISTING ANALYSES *******************/\n  } else if (type === \"PREFLIGHT_INPUT\") {\n    loaded\n      .then(async (x) => {\n        let resp = {};\n        try {\n          // Registering the UIDs of each new dataset.\n          let current = {};\n          let summary = {};\n          for (const [k, v] of Object.entries(payload.inputs.files)) {\n            if (\"uid\" in v) {\n              if (!(v.uid in preflights)) {\n                preflights[v.uid] = createDataset(v);\n                preflights_summary[v.uid] = await preflights[v.uid].summary();\n              }\n              current[k] = preflights[v.uid];\n              summary[k] = summarizeResult(preflights_summary[v.uid], v);\n            } else {\n              let tmp_dataset = createDataset(v);\n              current[k] = tmp_dataset;\n              summary[k] = summarizeResult(current[k], v);\n            }\n          }\n\n          resp.status = \"SUCCESS\";\n          resp.details = summary;\n        } catch (e) {\n          console.error(e);\n          resp.status = \"ERROR\";\n          resp.reason = e.toString();\n        }\n\n        postMessage({\n          type: \"PREFLIGHT_INPUT_DATA\",\n          resp: resp,\n          msg: \"Success: PREFLIGHT_INPUT done\",\n        });\n      })\n      .catch((err) => {\n        console.error(err);\n        postError(type, err, fatal);\n      });\n\n    /**************** VERSUS MODE *******************/\n  } else if (type === \"computeVersusClusters\") {\n    loaded\n      .then((x) => {\n        let rank_type = payload.rank_type;\n        let modality = payload.modality;\n        let annotation = payload.annotation;\n\n        let annotation_vec = scran.factorize(getAnnotation(annotation));\n\n        let mds = getMarkerStandAloneForAnnot(annotation, annotation_vec);\n        let raw_res = mds.computeVersus(\n          annotation_vec.levels.indexOf(payload.left),\n          annotation_vec.levels.indexOf(payload.right)\n        );\n        let resp = bakana.formatMarkerResults(\n          raw_res.results[modality],\n          raw_res.left,\n          rank_type\n        );\n\n        var transferrable = [];\n        extractBuffers(resp, transferrable);\n        postMessage(\n          {\n            type: \"computeVersusClusters\",\n            resp: resp,\n            msg: \"Success: COMPUTE_VERSUS_CLUSTERS done\",\n          },\n          transferrable\n        );\n      })\n      .catch((err) => {\n        console.error(err);\n        postError(type, err, fatal);\n      });\n  } else if (type === \"computeVersusSelections\") {\n    loaded\n      .then((x) => {\n        let rank_type = payload.rank_type;\n        let res = custom_selection_state.computeVersus(\n          payload.left,\n          payload.right\n        );\n        let resp = bakana.formatMarkerResults(\n          res[\"results\"][payload.modality],\n          payload.left,\n          rank_type\n        );\n\n        var transferrable = [];\n        extractBuffers(resp, transferrable);\n        postMessage(\n          {\n            type: \"computeVersusSelections\",\n            resp: resp,\n            msg: \"Success: COMPUTE_VERSUS_SELECTIONS done\",\n          },\n          transferrable\n        );\n      })\n      .catch((err) => {\n        console.error(err);\n        postError(type, err, fatal);\n      });\n\n    //   /**************** OTHER EVENTS FROM UI *******************/\n  } else if (type === \"getMarkersForCluster\") {\n    loaded\n      .then((x) => {\n        let cluster = payload.cluster;\n        let rank_type = payload.rank_type;\n        let modality = payload.modality;\n        let annotation = payload.annotation;\n\n        let annotation_vec = scran.factorize(getAnnotation(annotation));\n        let mds = getMarkerStandAloneForAnnot(annotation, annotation_vec);\n\n        let raw_res = mds.fetchResults()[modality];\n\n        let resp = bakana.formatMarkerResults(\n          raw_res,\n          annotation_vec.levels.indexOf(cluster),\n          rank_type\n        );\n\n        var transferrable = [];\n        extractBuffers(resp, transferrable);\n        postMessage(\n          {\n            type: \"setMarkersForCluster\",\n            resp: resp,\n            msg: \"Success: GET_MARKER_GENE done\",\n          },\n          transferrable\n        );\n      })\n      .catch((err) => {\n        console.error(err);\n        postError(type, err, fatal);\n      });\n  } else if (type === \"getGeneExpression\") {\n    loaded\n      .then((x) => {\n        let row_idx = payload.gene;\n        let modality = payload.modality;\n\n        var vec = dataset.matrix.get(modality).row(row_idx);\n\n        postMessage(\n          {\n            type: \"setGeneExpression\",\n            resp: {\n              gene: row_idx,\n              expr: vec,\n            },\n            msg: \"Success: GET_GENE_EXPRESSION done\",\n          },\n          [vec.buffer]\n        );\n      })\n      .catch((err) => {\n        console.error(err);\n        postError(type, err, fatal);\n      });\n  } else if (type === \"computeCustomMarkers\") {\n    loaded\n      .then((x) => {\n        custom_selection_state.addSelection(payload.id, payload.selection);\n        postMessage({\n          type: \"computeCustomMarkers\",\n          msg: \"Success: COMPUTE_CUSTOM_MARKERS done\",\n        });\n      })\n      .catch((err) => {\n        console.error(err);\n        postError(type, err, fatal);\n      });\n  } else if (type === \"getMarkersForSelection\") {\n    loaded\n      .then((x) => {\n        let rank_type = payload.rank_type;\n\n        let raw_res = custom_selection_state.fetchResults(payload.cluster)[\n          payload.modality\n        ];\n        let resp = bakana.formatMarkerResults(raw_res, 1, rank_type);\n\n        var transferrable = [];\n        extractBuffers(resp, transferrable);\n        postMessage(\n          {\n            type: \"setMarkersForCustomSelection\",\n            resp: resp,\n            msg: \"Success: GET_MARKER_GENE done\",\n          },\n          transferrable\n        );\n      })\n      .catch((err) => {\n        console.error(err);\n        postError(type, err, fatal);\n      });\n  } else if (type === \"removeCustomMarkers\") {\n    loaded\n      .then((x) => {\n        custom_selection_state.removeSelection(payload.id);\n      })\n      .catch((err) => {\n        console.error(err);\n        postError(type, err, fatal);\n      });\n  } else if (type === \"getAnnotation\") {\n    loaded\n      .then((x) => {\n        let annot = payload.annotation;\n        let vec, output;\n\n        vec = getAnnotation(annot);\n        // dataset.cells.column(annot);\n\n        if (ArrayBuffer.isView(vec)) {\n          output = {\n            type: \"array\",\n            values: vec.slice(),\n          };\n        } else {\n          let uniq_vals = [];\n          let uniq_map = {};\n          let indices = new Int32Array(vec.length);\n          vec.map((x, i) => {\n            if (!(x in uniq_map)) {\n              uniq_map[x] = uniq_vals.length;\n              uniq_vals.push(x);\n            }\n            indices[i] = uniq_map[x];\n          });\n\n          output = {\n            type: \"factor\",\n            index: indices,\n            levels: uniq_vals,\n          };\n        }\n\n        let extracted = [];\n        extractBuffers(output, extracted);\n        postMessage(\n          {\n            type: \"setAnnotation\",\n            resp: {\n              annotation: annot,\n              values: output,\n            },\n            msg: \"Success: GET_ANNOTATION done\",\n          },\n          extracted\n        );\n      })\n      .catch((err) => {\n        console.error(err);\n        postError(type, err, fatal);\n      });\n  } else if (type === \"computeFeaturesetSummary\") {\n    loaded\n      .then(async (x) => {\n        let { annotation, rank_type, cluster, modality } = payload;\n        let index = rank_type.indexOf(\"-\");\n        let resp;\n\n        if (default_selection === annotation) {\n          let anno_markers =\n            custom_selection_state.fetchResults(cluster)[modality];\n\n          feature_set_enrich_state.ready().then((x) => {\n            resp = feature_set_enrich_state.computeEnrichment(\n              anno_markers,\n              1,\n              rank_type.slice(0, index),\n              rank_type.slice(index + 1)\n            );\n            postSuccess(\"computeFeaturesetSummary\", resp);\n          });\n        } else {\n          let annotation_vec = scran.factorize(getAnnotation(annotation));\n          let mds = getMarkerStandAloneForAnnot(annotation, annotation_vec);\n          let anno_markers = mds.fetchResults()[modality];\n\n          feature_set_enrich_state.ready().then((x) => {\n            resp = feature_set_enrich_state.computeEnrichment(\n              anno_markers,\n              annotation_vec.levels.indexOf(cluster),\n              rank_type.slice(0, index),\n              rank_type.slice(index + 1)\n            );\n            postSuccess(\"computeFeaturesetSummary\", resp);\n          });\n        }\n      })\n      .catch((err) => {\n        console.error(err);\n        postError(type, err, fatal);\n      });\n  } else if (type === \"computeFeaturesetVSSummary\") {\n    loaded\n      .then(async (x) => {\n        let { annotation, rank_type, left, right, modality } = payload;\n        let index = rank_type.indexOf(\"-\");\n        let resp;\n        if (default_selection === annotation) {\n          let anno_markers = custom_selection_state.computeVersus(left, right);\n\n          feature_set_enrich_state.ready().then((x) => {\n            resp = feature_set_enrich_state.computeEnrichment(\n              anno_markers.results[modality],\n              0,\n              rank_type.slice(0, index),\n              rank_type.slice(index + 1)\n            );\n            postSuccess(\"computeFeaturesetVSSummary\", resp);\n          });\n        } else {\n          let annotation_vec = scran.factorize(getAnnotation(annotation));\n          let mds = getMarkerStandAloneForAnnot(annotation, annotation_vec);\n\n          let raw_res = mds.computeVersus(\n            annotation_vec.levels.indexOf(payload.left),\n            annotation_vec.levels.indexOf(payload.right)\n          );\n\n          feature_set_enrich_state.ready().then((x) => {\n            resp = feature_set_enrich_state.computeEnrichment(\n              raw_res.results[modality],\n              raw_res.left,\n              rank_type.slice(0, index),\n              rank_type.slice(index + 1)\n            );\n            postSuccess(\"computeFeaturesetVSSummary\", resp);\n          });\n        }\n      })\n      .catch((err) => {\n        console.error(err);\n        postError(type, err, fatal);\n      });\n  } else if (type === \"getFeatureScores\") {\n    loaded\n      .then((x) => {\n        let { index } = payload;\n\n        let resp = feature_set_enrich_state.computePerCellScores(index);\n        postSuccess(\"setFeatureScores\", resp);\n      })\n      .catch((err) => {\n        console.error(err);\n        postError(type, err, fatal);\n      });\n  } else if (type === \"getFeatureGeneIndices\") {\n    loaded\n      .then((x) => {\n        let { index, cluster, annotation, modality, rank_type } = payload;\n\n        let resp = feature_set_enrich_state.fetchFeatureSetIndices(index);\n\n        let raw_res, marker_resp;\n\n        if (default_selection === annotation) {\n          raw_res = custom_selection_state.fetchResults(payload.cluster)[\n            payload.modality\n          ];\n          marker_resp = bakana.formatMarkerResults(\n            raw_res,\n            1,\n            payload.rank_type\n          );\n        } else {\n          let annotation_vec = scran.factorize(getAnnotation(annotation));\n          let mds = getMarkerStandAloneForAnnot(annotation, annotation_vec);\n\n          raw_res = mds.fetchResults()[modality];\n          // cache_anno_markers[annotation][modality];\n\n          marker_resp = bakana.formatMarkerResults(\n            raw_res,\n            annotation_vec.levels.indexOf(cluster),\n            rank_type\n          );\n        }\n\n        let indices = marker_resp.ordering\n          .map((x, i) => (resp.includes(x) ? i : -100))\n          .filter((x) => x !== -100);\n\n        let filtered_marker_resp = {};\n        for (const [k, v] of Object.entries(marker_resp)) {\n          filtered_marker_resp[k] = v\n            .map((x, i) => (indices.includes(i) ? x : -100))\n            .filter((x) => x !== -100);\n        }\n\n        postSuccess(\"setFeatureGeneIndices\", filtered_marker_resp);\n      })\n      .catch((err) => {\n        console.error(err);\n        postError(type, err, fatal);\n      });\n  } else if (type === \"initFeaturesetEnrich\") {\n    loaded.then(async (x) => {\n      let { modality } = payload;\n\n      if (feature_set_enrich_state) {\n        feature_set_enrich_state.free();\n      }\n\n      feature_set_enrich_state = new bakana.FeatureSetEnrichmentStandalone(\n        dataset.features[modality],\n        { normalized: dataset.matrix.get(modality) }\n      );\n\n      feature_set_enrich_state.ready().then((x) => {\n        let collections = feature_set_enrich_state.fetchCollectionDetails();\n        let sets = feature_set_enrich_state.fetchSetDetails();\n        let resp = {\n          collections: collections,\n          sets: {\n            names: sets.names,\n            descriptions: sets.descriptions,\n            sizes: sets.sizes.slice(),\n            collections: sets.collections.slice(),\n          },\n        };\n        postSuccess(\"feature_set_enrichment\", resp);\n      });\n    });\n  } else if (type === \"computeCellAnnotation\") {\n    let { annotation, cluster, modality } = payload;\n    let result = { per_reference: {} };\n    let markers = null;\n    if (default_selection === annotation) {\n      markers = custom_selection_state.fetchResults(cluster);\n    } else {\n      let annotation_vec = scran.factorize(getAnnotation(annotation));\n      let mds = getMarkerStandAloneForAnnot(annotation, annotation_vec);\n      markers = mds.fetchResults();\n    }\n    if (markers !== null && modality in markers) {\n      if (cell_labelling_state === null) {\n        cell_labelling_state = new bakana.CellLabellingStandalone(\n          dataset.features[modality]\n        );\n      }\n      cell_labelling_state\n        .ready()\n        .then(() => {\n          result = cell_labelling_state.computeLabels(markers[modality]);\n          postSuccess(\"computeCellAnnotation\", result);\n        })\n        .catch((err) => {\n          console.error(err);\n          postError(type, err, fatal);\n        });\n    }\n  } else {\n    console.error(\"MIM:::msg type incorrect\");\n    postError(type, \"Type not defined\", fatal);\n  }\n};\n","// The module cache\nvar __webpack_module_cache__ = {};\n\n// The require function\nfunction __webpack_require__(moduleId) {\n\t// Check if module is in cache\n\tvar cachedModule = __webpack_module_cache__[moduleId];\n\tif (cachedModule !== undefined) {\n\t\treturn cachedModule.exports;\n\t}\n\t// Create a new module (and put it into the cache)\n\tvar module = __webpack_module_cache__[moduleId] = {\n\t\tid: moduleId,\n\t\tloaded: false,\n\t\texports: {}\n\t};\n\n\t// Execute the module function\n\t__webpack_modules__[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n\t// Flag the module as loaded\n\tmodule.loaded = true;\n\n\t// Return the exports of the module\n\treturn module.exports;\n}\n\n// expose the modules object (__webpack_modules__)\n__webpack_require__.m = __webpack_modules__;\n\n// the startup function\n__webpack_require__.x = () => {\n\t// Load entry module and return exports\n\t// This entry module depends on other loaded chunks and execution need to be delayed\n\tvar __webpack_exports__ = __webpack_require__.O(undefined, [764,705,141], () => (__webpack_require__(2418)))\n\t__webpack_exports__ = __webpack_require__.O(__webpack_exports__);\n\treturn __webpack_exports__;\n};\n\n","var deferred = [];\n__webpack_require__.O = (result, chunkIds, fn, priority) => {\n\tif(chunkIds) {\n\t\tpriority = priority || 0;\n\t\tfor(var i = deferred.length; i > 0 && deferred[i - 1][2] > priority; i--) deferred[i] = deferred[i - 1];\n\t\tdeferred[i] = [chunkIds, fn, priority];\n\t\treturn;\n\t}\n\tvar notFulfilled = Infinity;\n\tfor (var i = 0; i < deferred.length; i++) {\n\t\tvar chunkIds = deferred[i][0];\n\t\tvar fn = deferred[i][1];\n\t\tvar priority = deferred[i][2];\n\t\tvar fulfilled = true;\n\t\tfor (var j = 0; j < chunkIds.length; j++) {\n\t\t\tif ((priority & 1 === 0 || notFulfilled >= priority) && Object.keys(__webpack_require__.O).every((key) => (__webpack_require__.O[key](chunkIds[j])))) {\n\t\t\t\tchunkIds.splice(j--, 1);\n\t\t\t} else {\n\t\t\t\tfulfilled = false;\n\t\t\t\tif(priority < notFulfilled) notFulfilled = priority;\n\t\t\t}\n\t\t}\n\t\tif(fulfilled) {\n\t\t\tdeferred.splice(i--, 1)\n\t\t\tvar r = fn();\n\t\t\tif (r !== undefined) result = r;\n\t\t}\n\t}\n\treturn result;\n};","// define getter functions for harmony exports\n__webpack_require__.d = (exports, definition) => {\n\tfor(var key in definition) {\n\t\tif(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {\n\t\t\tObject.defineProperty(exports, key, { enumerable: true, get: definition[key] });\n\t\t}\n\t}\n};","__webpack_require__.f = {};\n// This file contains only the entry chunk.\n// The chunk loading function for additional chunks\n__webpack_require__.e = (chunkId) => {\n\treturn Promise.all(Object.keys(__webpack_require__.f).reduce((promises, key) => {\n\t\t__webpack_require__.f[key](chunkId, promises);\n\t\treturn promises;\n\t}, []));\n};","// This function allow to reference async chunks and sibling chunks for the entrypoint\n__webpack_require__.u = (chunkId) => {\n\t// return url for filenames based on template\n\treturn \"static/js/\" + chunkId + \".\" + {\"141\":\"2a0a3483\",\"343\":\"efff4f3e\",\"433\":\"af90bd70\",\"705\":\"de34064b\",\"764\":\"2cfcca9d\",\"814\":\"24fa2c52\"}[chunkId] + \".chunk.js\";\n};","// This function allow to reference async chunks and sibling chunks for the entrypoint\n__webpack_require__.miniCssF = (chunkId) => {\n\t// return url for filenames based on template\n\treturn undefined;\n};","__webpack_require__.g = (function() {\n\tif (typeof globalThis === 'object') return globalThis;\n\ttry {\n\t\treturn this || new Function('return this')();\n\t} catch (e) {\n\t\tif (typeof window === 'object') return window;\n\t}\n})();","__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))","__webpack_require__.nmd = (module) => {\n\tmodule.paths = [];\n\tif (!module.children) module.children = [];\n\treturn module;\n};","__webpack_require__.p = \"/kana/\";","__webpack_require__.b = self.location + \"/../../../\";\n\n// object to store loaded chunks\n// \"1\" means \"already loaded\"\nvar installedChunks = {\n\t418: 1\n};\n\n// importScripts chunk loading\nvar installChunk = (data) => {\n\tvar chunkIds = data[0];\n\tvar moreModules = data[1];\n\tvar runtime = data[2];\n\tfor(var moduleId in moreModules) {\n\t\tif(__webpack_require__.o(moreModules, moduleId)) {\n\t\t\t__webpack_require__.m[moduleId] = moreModules[moduleId];\n\t\t}\n\t}\n\tif(runtime) runtime(__webpack_require__);\n\twhile(chunkIds.length)\n\t\tinstalledChunks[chunkIds.pop()] = 1;\n\tparentChunkLoadingFunction(data);\n};\n__webpack_require__.f.i = (chunkId, promises) => {\n\t// \"1\" is the signal for \"already loaded\"\n\tif(!installedChunks[chunkId]) {\n\t\tif(true) { // all chunks have JS\n\t\t\timportScripts(__webpack_require__.p + __webpack_require__.u(chunkId));\n\t\t}\n\t}\n};\n\nvar chunkLoadingGlobal = self[\"webpackChunkkana\"] = self[\"webpackChunkkana\"] || [];\nvar parentChunkLoadingFunction = chunkLoadingGlobal.push.bind(chunkLoadingGlobal);\nchunkLoadingGlobal.push = installChunk;\n\n// no HMR\n\n// no HMR manifest","var next = __webpack_require__.x;\n__webpack_require__.x = () => {\n\treturn Promise.all([764,705,141].map(__webpack_require__.e, __webpack_require__)).then(next);\n};","// run startup\nvar __webpack_exports__ = __webpack_require__.x();\n"],"names":["DownloadsDB","init","async","fetchWrapper","url","params","arguments","length","undefined","out","startFun","iterFun","endFun","res","fetch","ok","Error","id","headers","get","reader","body","getReader","chunks","total","done","value","read","push","output","Uint8Array","start","x","set","fetchWithProgress","cl","postMessage","type","String","download","total_bytes","msg","sofar","downloaded_bytes","error","req","status","buffer","arrayBuffer","force","download_store","result","transaction","objectStore","data_check","Promise","resolve","reject","already","onsuccess","event","payload","onerror","concat","target","errorCode","found","trans","fin","oncomplete","saving","putrequest","put","proxy","proxyAndCache","downloads","encodeURIComponent","extractBuffers","object","store","Array","isArray","element","constructor","Object","key","entries","ArrayBuffer","isView","postAttempt","step","postSuccess","info","transferable","resp","postError","err","fatal","reason","toString","isArrayOrView","col","describeColumn","all","unique","colname","bakana","uqVals","Set","size","sort","setDownload","gesel","file","end","full","Response","remotes","setDownloadFun","code","default_selection","superstate","preflights","preflights_summary","dataset","cache_anno_markers","custom_selection_state","feature_set_enrich_state","cell_labelling_state","createDataset","args","setOpts","format","h5","options","rds","zipname","zipfile","summarizeResult","summary","cells_summary","k","cells","columnNames","kcol","column","tmp_meta","columns","numberOfCells","numberOfRows","v","modality_features","tmod_summary","numberOfFeatures","rownames","rowNames","all_assay_names","modality_assay_names","reduced_dimension_names","getMarkerStandAloneForAnnot","annotation","annotation_vec","mds","getMatrix","ids","slice","computeAll","getAnnotation","indexOf","splits","split","matrix","loaded","onmessage","data","nthreads","Math","round","navigator","hardwareConcurrency","back_init","numberOfThreads","state_init","then","down_init","indexedDB","open","onupgradeneeded","e","DownloadsDBClient","deleteObjectStore","createObjectStore","keyPath","catch","console","files","inputs","current","uid","clear","setOptions","load","step_inputs","annotation_keys","ksumm","step_inputs_resp","annotations","genes","num_cells","num_genes","features","step_embed","step_embed_resp","reduced_dimensions","toLowerCase","y","free","tmp_dataset","details","rank_type","modality","scran","raw_res","computeVersus","levels","left","right","results","transferrable","cluster","fetchResults","row_idx","gene","vec","row","expr","addSelection","selection","removeSelection","annot","values","uniq_vals","uniq_map","indices","Int32Array","map","i","index","extracted","anno_markers","ready","computeEnrichment","computePerCellScores","marker_resp","fetchFeatureSetIndices","ordering","includes","filter","filtered_marker_resp","normalized","collections","fetchCollectionDetails","sets","fetchSetDetails","names","descriptions","sizes","per_reference","markers","computeLabels","__webpack_module_cache__","__webpack_require__","moduleId","cachedModule","exports","module","__webpack_modules__","call","m","__webpack_exports__","O","deferred","chunkIds","fn","priority","notFulfilled","Infinity","fulfilled","j","keys","every","splice","r","d","definition","o","defineProperty","enumerable","f","chunkId","reduce","promises","u","miniCssF","g","globalThis","this","Function","window","obj","prop","prototype","hasOwnProperty","nmd","paths","children","p","b","self","location","installedChunks","importScripts","chunkLoadingGlobal","parentChunkLoadingFunction","bind","moreModules","runtime","pop","next"],"sourceRoot":""}